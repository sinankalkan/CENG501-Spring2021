{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet18_cifar100_MBN_ipynb_submitted.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "240eGBNsHFH7"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import sys\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "import time   \n",
        "\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cg9oDp-IEwZD"
      },
      "source": [
        "### 1.1 Enable GPU\n",
        "\n",
        "From \"Edit -> Notebook Settings -> Hardware accelerator\" select GPU. With the following we will specify to PyTorch that we want to use the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tNnBZeMvvoZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7860299a-2e1f-4236-8ead-a218f7e171ce"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  print(\"Cuda (GPU support) is available and enabled!\")\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  print(\"Cuda (GPU support) is not available :(\")\n",
        "  device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda (GPU support) is available and enabled!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_h9IIGnFb-k"
      },
      "source": [
        "### 2 Model Definition\n",
        "\n",
        "\n",
        "In the original paper there are two different frameworks; ResNet and VGG. In this section, different models for different frameworks are created. However, in the original paper different normalization methods are applied in these frameworks and as mentioned the authors of the paper propose a new method which is called momentum Batch Normalization. In ResNet and VGG frameworks a naive batch normalization block is used and modified according to the proposed Momentum Batch Normalization method. On the other hand, Pytorch functions are used directly for other normalization methods such as Group Normalization, Layer Normalization, Instance Normalization and Batch Normalization for ResNet. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ltsl0oRWgpCX"
      },
      "source": [
        "### 2.1 Momentum Batch Normalization\n",
        "\n",
        "In the original paper a novel method is proposed called Momentum Batch Normalization. In this section, naive batch normalization implementation is taken from Dive Into Deep Learning book and it is modified according to the original paper. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "micNIpitgmhe"
      },
      "source": [
        "def batch_norm(X, gamma, beta, moving_mean, moving_var, moving_mean_inf, moving_var_inf, momentum, momentum_inf, eps):\n",
        "    # Use `is_grad_enabled` to determine whether the current mode is training\n",
        "    # mode or prediction mode\n",
        "    if not torch.is_grad_enabled():\n",
        "        # If it is prediction mode, directly use the mean and variance\n",
        "        # obtained by moving average\n",
        "        X_hat = (X - moving_mean_inf) / torch.sqrt(moving_var_inf + eps)\n",
        "        Y = gamma * X_hat + beta\n",
        "    else:\n",
        "        assert len(X.shape) in (2, 4)\n",
        "        if len(X.shape) == 2:\n",
        "            # When using a fully-connected layer, calculate the mean and\n",
        "            # variance on the feature dimension\n",
        "            mean = X.mean(dim=0)\n",
        "            var = ((X - mean)**2).mean(dim=0)\n",
        "        else:\n",
        "            # When using a two-dimensional convolutional layer, calculate the\n",
        "            # mean and variance on the channel dimension (axis=1). Here we\n",
        "            # need to maintain the shape of `X`, so that the broadcasting\n",
        "            # operation can be carried out later\n",
        "            mean = X.mean(dim=(0, 2, 3), keepdim=True)\n",
        "            var = ((X - mean)**2).mean(dim=(0, 2, 3), keepdim=True)\n",
        "\n",
        "        \n",
        "        # Update the mean and variance using moving average\n",
        "        moving_mean = momentum * moving_mean + (1.0 - momentum) * mean\n",
        "        moving_var = momentum * moving_var + (1.0 - momentum) * var\n",
        "        # In training mode, the updated moving mean and updated moving variance are used for the\n",
        "        # standardization\n",
        "        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)\n",
        "        Y = gamma * X_hat + beta  # Scale and shift\n",
        "        moving_mean_inf = momentum_inf * moving_mean_inf + (1.0 - momentum_inf) * mean\n",
        "        moving_var_inf = momentum_inf * moving_var_inf + (1.0 - momentum_inf) * var \n",
        "    return Y, moving_mean.data, moving_var.data, moving_mean_inf.data, moving_var_inf.data\n",
        "\n",
        "class BatchNorm(nn.Module):\n",
        "    # `num_features`: the number of outputs for a fully-connected layer\n",
        "    # or the number of output channels for a convolutional layer. `num_dims`:\n",
        "    # 2 for a fully-connected layer and 4 for a convolutional layer\n",
        "    def __init__(self, num_features, num_dims, batch_size):\n",
        "        super().__init__()\n",
        "        #num_features=64\n",
        "        if num_dims == 2:\n",
        "            shape = (1, num_features)\n",
        "        else:\n",
        "            shape = (1, num_features, 1, 1)\n",
        "        # The scale parameter and the shift parameter (model parameters) are\n",
        "        # initialized to 1 and 0, respectively\n",
        "        self.gamma = nn.Parameter(torch.ones(shape))\n",
        "        self.beta = nn.Parameter(torch.zeros(shape))\n",
        "        # The variables that are not model parameters are initialized to 0 and 1\n",
        "        self.moving_mean = torch.zeros(shape)\n",
        "        self.moving_var = torch.ones(shape)\n",
        "        self.moving_mean_inf = torch.zeros(shape)\n",
        "        self.moving_var_inf = torch.ones(shape)\n",
        "        self.batch_size = batch_size\n",
        "        self.momentum_inf = 0.85**(batch_size/4 / 32)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # If `X` is not on the main memory, copy `moving_mean` and\n",
        "        # `moving_var` to the device where `X` is located\n",
        "        if self.moving_mean.device != x.device:\n",
        "            self.moving_mean = self.moving_mean.to(x.device)\n",
        "            self.moving_var = self.moving_var.to(x.device)\n",
        "            self.moving_mean_inf = self.moving_mean_inf.to(x.device)\n",
        "            self.moving_var_inf = self.moving_var_inf.to(x.device)\n",
        "        # Save the updated `moving_mean` and `moving_var`\n",
        "        ro = min(self.batch_size / 32 , 1)**(1 / epoch_number)\n",
        "        momentum = ro**((epoch_number)/(epoch_number - 1)*max((epoch_number - epoch), 0))- ro**epoch_number\n",
        "        momentum=max(0,momentum)\n",
        "        #print('Momentum:',momentum)\n",
        "        Y, self.moving_mean, self.moving_var, self.moving_mean_inf, self.moving_var_inf = batch_norm(\n",
        "            x, self.gamma, self.beta, self.moving_mean, self.moving_var, \n",
        "            self.moving_mean_inf, self.moving_var_inf, momentum, self.momentum_inf,\n",
        "            eps=1e-5)\n",
        "        return Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DBPPzmN_PEQ"
      },
      "source": [
        "### 2.2 ResNet\n",
        "\n",
        "ResNet18, ResNet34 and ResNet50 architectures are defined according to the original paper as folllows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH1akIYwtvKE"
      },
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, batch_size, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = BatchNorm(planes, 4, batch_size)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = BatchNorm(planes, 4, batch_size)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                BatchNorm(self.expansion*planes, 4, batch_size)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, batch_size, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = BatchNorm(planes, 4, batch_size)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = BatchNorm(planes, 4, batch_size)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = BatchNorm(self.expansion*planes, 4, batch_size)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                BatchNorm(self.expansion*planes, 4, batch_size)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, batch_size, num_classes=100):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "        self.batch_size = batch_size\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = BatchNorm(64, 4, batch_size)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, self.batch_size, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18(batch_size):\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], batch_size)\n",
        "\n",
        "\n",
        "def ResNet34(batch_size):\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3], batch_size)\n",
        "\n",
        "\n",
        "def ResNet50(batch_size):\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3], batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjIf8a4L_zwT"
      },
      "source": [
        "### 2.3 VGG\n",
        "\n",
        "VGG11 and VGG16 architectures are defined according to the original paper as folllows.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DikohAmZGQtx"
      },
      "source": [
        "configuration = {\n",
        "    'VGG11': [64, 'pool', 128, 'pool', 256, 256, 'pool', 512, 512, 'pool', 512, 512, 'pool'],\n",
        "    'VGG16': [64, 64, 'pool', 128, 128, 'pool', 256, 256, 256, 'pool', 512, 512, 512, 'pool', 512, 512, 512, 'pool']\n",
        "}\n",
        "\n",
        "\n",
        "class VGG(nn.Module):\n",
        "    def __init__(self, vgg_name,batch_size):\n",
        "        super(VGG, self).__init__()\n",
        "        self.features = self._make_layers(cfg[vgg_name])\n",
        "        self.classifier = nn.Linear(512, 100)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "    def _make_layers(self, cfg):\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for x in cfg:\n",
        "            if x == 'pool':\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            else:\n",
        "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
        "                           BatchNorm(x, 4, batch_size),\n",
        "                           nn.ReLU(inplace=True)]\n",
        "                in_channels = x\n",
        "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
        "        return nn.Sequential(*layers)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Bp01CBRE91M"
      },
      "source": [
        "## 3 The Dataset\n",
        "\n",
        "In the original paper authors used CIFAR10 and CIFAR100 datasets. In this section torchvision function is used to load train/test datasets;  \n",
        "\n",
        "*   There are 50000 training images and 10000 test images for  10 different classes for CIFAR10\n",
        "*   There are 50000 training images and 10000 test images for 100 different classes for CIFAR100.\n",
        "\n",
        "In the original paper, authors mentions standard data augmentation and preprocessing techniques are used but any specific parameters were not given in the paper or in the supplementary material of the paper. Therefore, data augmentation and preprocessing techniques are taken from the literature and applied to the datasets. \n",
        "\n",
        "In the original paper batch size is set to 8, 16 and 32. It can be changed in this section for different experiments.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2onI3bMcLy8e",
        "outputId": "e3a7977f-86ba-4f95-c712-1487ba0fec51"
      },
      "source": [
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0, 0, 0), (1, 1, 1)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0, 0, 0), (1, 1, 1)),\n",
        "])\n",
        "\n",
        "###################\n",
        "batch_size=32 #batch size (2 per gpu)\n",
        "m0=32 #ideal batch size\n",
        "######################\n",
        "\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=batch_size, shuffle=True, num_workers=2) # 4 gpu\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=batch_size, shuffle=False, num_workers=2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPbSc-a2Aeva"
      },
      "source": [
        "### 4 Define and Train Model\n",
        "In this section user can choose the model between the ResNet18, ResNet34, ResNet50, VGG11 and VGG16 frameworks. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfC6tcf1igI_"
      },
      "source": [
        "### 4.1 Define Loss Function and the Optimizer\n",
        "\n",
        "Instance is created for the model based on the choice.\n",
        "\n",
        "In the original paper authors used Stochastic Gradient Descent for the optimization with the momentum 0.9 and weight decay 0.0001 paramaeters set. In the experiments these parameters and optimization method from the paper are preserved.\n",
        "\n",
        "Since the criterion for the loss function is not specified exactly in the original paper Cross-Entropy Loss method is chosen in the experiments.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twExnQMrR3Hb",
        "outputId": "572db146-167d-45a1-af3a-2d7b2380333d"
      },
      "source": [
        "sys.argv=['']\n",
        "del sys\n",
        "\n",
        "\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 1  \n",
        "\n",
        "\n",
        "# Model\n",
        "print('==> Building model..')\n",
        "\n",
        "#net = VGG('VGG11',batch_size)\n",
        "# net = VGG('VGG16',batch_size)\n",
        "net = ResNet18(trainloader.batch_size)\n",
        "# net = ResNet34(trainloader.batch_size)\n",
        "# net = ResNet50(trainloader.batch_size)\n",
        "\n",
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.1*batch_size/64,\n",
        "                      momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60, 120, 180], gamma=0.1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Building model..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JlyKsFGiCZl"
      },
      "source": [
        "### 4.2 Train the Model\n",
        "\n",
        "In the original paper, authors propose a new method in order to train large datasets with small batch-sizes for insufficient memory resources. Therefore, in the experiments considerably smaller batch sizes are used and it extends the training times. In order to overcome high training times problem GPU usage becomes a necessity and cuda is used in the experiments with Colab Pro.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmmPWjZ3KaH0"
      },
      "source": [
        "# Training and Accuracy Calculation\n",
        "def train(verbose=True):\n",
        "    \n",
        "    loss_history=[]\n",
        "    net.train()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    #for epoch in range(start_epoch, start_epoch+epoch_number):\n",
        "    \n",
        "    \n",
        "    start = time.time()\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        loss_history.append(loss.item()) \n",
        "\n",
        "    end = time.time()\n",
        "    if verbose: print(f'Epoch {epoch} / {epoch_number}: avg. loss of last 5 iterations {np.sum(loss_history[:-6:-1])/5} , Time : {end - start} seconds')            \n",
        "\n",
        "    global best_acc\n",
        "    global test_loss\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)  \n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()       \n",
        "\n",
        "\n",
        "    acc = 100.*correct/total\n",
        "    historyy.append(acc)\n",
        "\n",
        "    print('acc:',acc,'best_acc:',best_acc)\n",
        "    if acc > best_acc:\n",
        "        print('Saving..' )\n",
        "        \n",
        "        state = {\n",
        "            'net': net.state_dict(),\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        best_acc = acc\n",
        "        \n",
        "    print('\\n\\n') \n",
        "    scheduler.step() \n",
        "    return loss_history      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu5lXdfLt-hQ",
        "outputId": "9e8be638-79a6-4afb-e236-62f0bde83bd5"
      },
      "source": [
        "epoch_number=5\n",
        "historyy=[]\n",
        "losses=[]\n",
        "\n",
        "for epoch in range(start_epoch, start_epoch+epoch_number):\n",
        "  loss_history=train()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 / 5: avg. loss of last 5 iterations 1.587316918373108 , Time : 90.7494797706604 seconds\n",
            "acc: 36.78 best_acc: 0\n",
            "Saving..\n",
            "\n",
            "\n",
            "\n",
            "Epoch 2 / 5: avg. loss of last 5 iterations 1.1108572721481322 , Time : 89.7955482006073 seconds\n",
            "acc: 53.65 best_acc: 36.78\n",
            "Saving..\n",
            "\n",
            "\n",
            "\n",
            "Epoch 3 / 5: avg. loss of last 5 iterations 0.9818734765052796 , Time : 90.17288827896118 seconds\n",
            "acc: 67.83 best_acc: 53.65\n",
            "Saving..\n",
            "\n",
            "\n",
            "\n",
            "Epoch 4 / 5: avg. loss of last 5 iterations 0.6967864632606506 , Time : 90.01660299301147 seconds\n",
            "acc: 71.26 best_acc: 67.83\n",
            "Saving..\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnaT7_kfGxie"
      },
      "source": [
        "### 4.3 The Loss Curve\n",
        "Loss curve is visualized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fbhdotYius9"
      },
      "source": [
        "plt.plot(loss_history)\n",
        "plt.xlabel('Iteration number')\n",
        "plt.ylabel('Loss value')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSvgOaIUzWCk"
      },
      "source": [
        "### 4.4 Quantitative Analysis\n",
        "\n",
        "We can analyze the accuracy of the predictions as follows. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kghpVDAly9Kf"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = net(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwEmxNBOgQsD"
      },
      "source": [
        "print('saving' ,'acc:',best_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1fPq-45BI_8"
      },
      "source": [
        "### 5 Results\n",
        "\n",
        "Accuracy vs epoch is plotted according to the test results. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9j3BViCkt5r"
      },
      "source": [
        "plt.plot(historyy)\n",
        "plt.xlabel('Epoch number')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "print(historyy)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}