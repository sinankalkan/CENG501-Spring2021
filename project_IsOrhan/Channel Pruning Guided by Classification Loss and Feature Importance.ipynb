{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Channel Pruning Guided by Classification Loss and Feature Importance.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6118d7535a474c748e2c82e3be36e22f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_40ca9b555a5e455d91debd483326c7c9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eb929d14e65344e9863aa70e989c9716",
              "IPY_MODEL_9d54bded9a2e4b26b2ca888454ed5117"
            ]
          }
        },
        "40ca9b555a5e455d91debd483326c7c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eb929d14e65344e9863aa70e989c9716": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7351a49a45514d1689544c47571780d0",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 532199577,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 532199577,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a417dce44a449beba6127fca10bda60"
          }
        },
        "9d54bded9a2e4b26b2ca888454ed5117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f29ded0c77e54266afa7a7df0e362f14",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 508M/508M [00:07&lt;00:00, 73.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5ab4fff37a3043b29604436f22250513"
          }
        },
        "7351a49a45514d1689544c47571780d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a417dce44a449beba6127fca10bda60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f29ded0c77e54266afa7a7df0e362f14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5ab4fff37a3043b29604436f22250513": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "033bf53c6aae446ba3878dee444fc8c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9468825bab134e9aa49f61ad88517754",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d4f892a0b66b496287e727ab6ba3e107",
              "IPY_MODEL_e2db7517c0f840f391a24716131e80b3"
            ]
          }
        },
        "9468825bab134e9aa49f61ad88517754": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d4f892a0b66b496287e727ab6ba3e107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_36363fd62ed141479565deac035a4f39",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e592b2efdfe2447ebb13e00ea51ae916"
          }
        },
        "e2db7517c0f840f391a24716131e80b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_79e1411400784d329a78cf3c897a0af2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:41&lt;00:00, 4100846.57it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fe91be1e68ec4af980dc38b239916b62"
          }
        },
        "36363fd62ed141479565deac035a4f39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e592b2efdfe2447ebb13e00ea51ae916": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "79e1411400784d329a78cf3c897a0af2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fe91be1e68ec4af980dc38b239916b62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nazimorhan/Channel-Pruning-Guided-by-Classification-Loss-and-Feature-Importance/blob/master/Channel%20Pruning%20Guided%20by%20Classification%20Loss%20and%20Feature%20Importance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZD8-z3zW2Zz"
      },
      "source": [
        "# 1 Import Required Modules"
      ],
      "id": "RZD8-z3zW2Zz"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f526f2f2",
        "outputId": "c1982e84-8647-41cd-8612-e360b0f9b08f"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "import numpy as np              \n",
        "import time                     \n",
        "import random                   \n",
        "import copy\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = [12, 8]\n",
        "plt.rcParams['figure.dpi'] = 100 # 200 e.g. is really fine, but slower\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "id": "f526f2f2",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.5.2-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXAeXYQmPyVO"
      },
      "source": [
        "# 2 Prepare Data\n",
        "\n",
        "We will use CIFAR-10 dataset in order to test CPLI method which can be read from [here](https://arxiv.org/pdf/2003.06757.pdf). In the original paper, batch size is mentioned as 256. So we will use this values as batch size. But firstly a function for creating batches for a certain batch_size will be defined. "
      ],
      "id": "UXAeXYQmPyVO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ig0yz3kPQLB4"
      },
      "source": [
        "def create_batches(batchSize):\n",
        "  # Make required transformation which is necessary for the inputs to VGG13 network\n",
        "  # Further info can be accessed from https://pytorch.org/hub/pytorch_vision_vgg/ \n",
        "  TF = transforms.Compose([\n",
        "      transforms.Resize(256),\n",
        "      transforms.CenterCrop(224),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "  ])\n",
        "\n",
        "  trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=TF)\n",
        "  trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchSize,\n",
        "                                            shuffle=True, num_workers=2)\n",
        "\n",
        "  testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=TF)\n",
        "  testloader = torch.utils.data.DataLoader(testset, batch_size=batchSize,\n",
        "                                          shuffle=False, num_workers=2)\n",
        "  return trainloader, testloader\n",
        "\n",
        "CIFAR10_classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "id": "ig0yz3kPQLB4",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RibBOJszZsjQ"
      },
      "source": [
        "## 2.1 Enable GPU\n",
        "\n",
        "From \"Edit -> Notebook Settings -> Hardware accelerator\" select GPU. With the following we will specify to PyTorch that we want to use the GPU."
      ],
      "id": "RibBOJszZsjQ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj0eJQBJZv8i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dace086f-0594-4b9a-c5d6-e00dad0fe497"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  print(\"Cuda (GPU support) is available and enabled!\")\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  print(\"Cuda (GPU support) is not available :(\")\n",
        "  device = torch.device(\"cpu\")"
      ],
      "id": "Yj0eJQBJZv8i",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda (GPU support) is available and enabled!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYTUTso7ai_E"
      },
      "source": [
        "# 3 Download, Finetune and Test Original Pretrained VGG13"
      ],
      "id": "bYTUTso7ai_E"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnOk7c2Ma-Yk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746,
          "referenced_widgets": [
            "6118d7535a474c748e2c82e3be36e22f",
            "40ca9b555a5e455d91debd483326c7c9",
            "eb929d14e65344e9863aa70e989c9716",
            "9d54bded9a2e4b26b2ca888454ed5117",
            "7351a49a45514d1689544c47571780d0",
            "3a417dce44a449beba6127fca10bda60",
            "f29ded0c77e54266afa7a7df0e362f14",
            "5ab4fff37a3043b29604436f22250513"
          ]
        },
        "outputId": "36b3501c-72c2-4c67-87b0-f00793f3f8e0"
      },
      "source": [
        "# Create an instance of original pretrained VGG13\n",
        "origVGG = torchvision.models.vgg13(pretrained=True)\n",
        "# Visualize the network.\n",
        "print(origVGG)"
      ],
      "id": "vnOk7c2Ma-Yk",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg13-19584684.pth\" to /root/.cache/torch/hub/checkpoints/vgg13-19584684.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6118d7535a474c748e2c82e3be36e22f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=532199577.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (20): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): ReLU(inplace=True)\n",
            "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (23): ReLU(inplace=True)\n",
            "    (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-5ycTV0bsjO"
      },
      "source": [
        "## 3.1 Finetune Pre-Trained VGG13 on CIFAR-10\n",
        "\n",
        "Since VGG13 is pretrained on ImageNet dataset, we have to finetune the network for CIFAR-10."
      ],
      "id": "l-5ycTV0bsjO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj2M_FPdpJ7p"
      },
      "source": [
        "# Freeze the layers by setting requires_grad parameter to False.\n",
        "newVGG = copy.deepcopy(origVGG)\n",
        "for param in newVGG.parameters():\n",
        "  param.requires_grad = False"
      ],
      "id": "Bj2M_FPdpJ7p",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvxEBc2iqw41"
      },
      "source": [
        "newVGG.classifier[6] = None\n",
        "newVGG.classifier[6] = nn.Linear(4096, 10)\n",
        "for i,layer in enumerate(newVGG.classifier):\n",
        "  if i in [0,3,6]:\n",
        "    for param in layer.parameters():\n",
        "        param.requires_grad=True\n",
        "for param in newVGG.parameters():\n",
        "  print(param.requires_grad)"
      ],
      "id": "zvxEBc2iqw41",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkCHIUkWqzFQ"
      },
      "source": [
        "Define a $\\textbf{train}$ function in order to train the network"
      ],
      "id": "JkCHIUkWqzFQ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQxlCIC-sBUJ"
      },
      "source": [
        "def train(model, criterion, optimizer, epochs, dataloader, scheduler=None, verbose=True):\n",
        "  \"\"\"\n",
        "    Define the trainer function. We can use this for training any model.\n",
        "    The parameter names are self-explanatory.\n",
        "\n",
        "    Returns: the loss history.\n",
        "  \"\"\"\n",
        "  loss_history = [] \n",
        "  for epoch in range(epochs):\n",
        "    for i, data in enumerate(dataloader, 0):    \n",
        "      \n",
        "      # Our batch:\n",
        "      inputs, labels = data\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # zero the gradients as PyTorch accumulates them\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Obtain the scores\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      # Calculate loss\n",
        "      loss = criterion(outputs.to(device), labels)\n",
        "\n",
        "      # Backpropagate\n",
        "      loss.backward()\n",
        "\n",
        "      # Update the weights\n",
        "      optimizer.step()\n",
        "\n",
        "      loss_history.append(loss.item())\n",
        "    if scheduler:\n",
        "      scheduler.step()\n",
        "    \n",
        "    if verbose: print(f'Epoch {epoch} / {epochs}: avg. loss of last 5 iterations {np.sum(loss_history[:-6:-1])/5}')\n",
        "\n",
        "  return loss_history"
      ],
      "id": "ZQxlCIC-sBUJ",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bygF59c9uDZE"
      },
      "source": [
        "Create the learnable parameters and make those the parameter of SGD optimizer. Also create the instances of loss function and send the model to GPU."
      ],
      "id": "bygF59c9uDZE"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnLs78vmuehd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df2d1a1d-3fb2-45de-fb1f-4bce1adc1839"
      },
      "source": [
        "def get_learnable_parameters(model):\n",
        "    params_to_update = []\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "    return params_to_update\n",
        "\n",
        "batch_finetune = 128\n",
        "trainloader, testloader = create_batches(batch_finetune)\n",
        "weight_decay = 0.0001\n",
        "newVGG = newVGG.to(device)\n",
        "parameters_to_update = get_learnable_parameters(newVGG)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(parameters_to_update, lr=0.001, weight_decay=weight_decay)\n",
        "# scheduler = optim.lr_scheduler.StepLR(optimizer,1)\n",
        "\n",
        "epochs = 10\n",
        "loss_history = train(newVGG, criterion, optimizer, epochs, trainloader)"
      ],
      "id": "fnLs78vmuehd",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 / 10: avg. loss of last 5 iterations 0.6314053654670715\n",
            "Epoch 1 / 10: avg. loss of last 5 iterations 0.43111336827278135\n",
            "Epoch 2 / 10: avg. loss of last 5 iterations 0.42029619216918945\n",
            "Epoch 3 / 10: avg. loss of last 5 iterations 0.3807760089635849\n",
            "Epoch 4 / 10: avg. loss of last 5 iterations 0.2698207378387451\n",
            "Epoch 5 / 10: avg. loss of last 5 iterations 0.36090603470802307\n",
            "Epoch 6 / 10: avg. loss of last 5 iterations 0.2832304984331131\n",
            "Epoch 7 / 10: avg. loss of last 5 iterations 0.27426413595676424\n",
            "Epoch 8 / 10: avg. loss of last 5 iterations 0.21089504063129424\n",
            "Epoch 9 / 10: avg. loss of last 5 iterations 0.26213362216949465\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwq-aYt4Oz4H"
      },
      "source": [
        "Create train and test batches."
      ],
      "id": "uwq-aYt4Oz4H"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKGijZh8Ol4S",
        "outputId": "0e48c119-ce8a-44fd-9a27-62ff622b0ce5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "033bf53c6aae446ba3878dee444fc8c9",
            "9468825bab134e9aa49f61ad88517754",
            "d4f892a0b66b496287e727ab6ba3e107",
            "e2db7517c0f840f391a24716131e80b3",
            "36363fd62ed141479565deac035a4f39",
            "e592b2efdfe2447ebb13e00ea51ae916",
            "79e1411400784d329a78cf3c897a0af2",
            "fe91be1e68ec4af980dc38b239916b62"
          ]
        }
      },
      "source": [
        "batch_size = 256\n",
        "trainloader, testloader = create_batches(batch_size)"
      ],
      "id": "gKGijZh8Ol4S",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "033bf53c6aae446ba3878dee444fc8c9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYbnqITwnpPK"
      },
      "source": [
        "# testiter = iter(testloader)\n",
        "# data, label = next(testiter)\n",
        "# output = newVGG(data.to(device))\n",
        "# print(output.data)\n",
        "# torch.save(newVGG.state_dict(), './parameters')\n"
      ],
      "id": "SYbnqITwnpPK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPvzQ4BNRhyT"
      },
      "source": [
        "We had a validation accuracy of 85% for the finetuned model. We will investigate CPLI method from this accuracy value. Since we worked on Google Colab, we upload fine-tuned model parameters to google drive and it is required to be downloaded from here."
      ],
      "id": "EPvzQ4BNRhyT"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-9-lc10MoJH",
        "outputId": "6b1aff61-a079-419b-86ef-c8e7d83736cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "id": "e-9-lc10MoJH",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zMREiobPPHZ"
      },
      "source": [
        "Load the state dict obtained from finetuning."
      ],
      "id": "_zMREiobPPHZ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pw1zfrGKLAJC",
        "outputId": "d03134fa-10a6-4bc9-dc91-f0e1f9354edd"
      },
      "source": [
        "model = torchvision.models.vgg13()\n",
        "model.classifier[6]=None\n",
        "model.classifier[6]=nn.Linear(4096, 10)\n",
        "model.load_state_dict(torch.load('/content/gdrive/MyDrive/parameters.zip'))"
      ],
      "id": "Pw1zfrGKLAJC",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtobbOsfR0Z3"
      },
      "source": [
        "It seems there exists no problem with fine-tuned model parameters. We were to have 85% validation accuracy when we tested our model. Let's see again if there exists any differences/errors with the downloaded parameters."
      ],
      "id": "xtobbOsfR0Z3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icnBCYMWPncH",
        "outputId": "d2d049b3-ee7b-4613-85a4-4d6aafd79f9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "model.to(device)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "id": "icnBCYMWPncH",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 85 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bw9YN1H4SaET"
      },
      "source": [
        "Again we have 85% validation accuracy with our fine-tuned model, so we can go on to investigate CPLI method. First, we should extract output features in the fine-tuned model for each layer"
      ],
      "id": "Bw9YN1H4SaET"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AN8XT6USgxV"
      },
      "source": [
        "testiter = iter(testloader)\n",
        "data, label = next(testiter)\n",
        "output = newVGG(data.to(device))"
      ],
      "id": "1AN8XT6USgxV",
      "execution_count": null,
      "outputs": []
    }
  ]
}