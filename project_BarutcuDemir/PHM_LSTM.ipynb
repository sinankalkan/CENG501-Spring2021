{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PHM-LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0UizaC77Owb"
      },
      "source": [
        "This is the Colab to reproduce our reproduction of the Natural Language Inference task on MNLI dataset with 300d GloVe embeddings in Beyond Fully Connected Layers with Quaternions: Parametrization of Hypercomplex Multiplications with 1/n Parameters. We implemented here PHM-LSTM version of the model as stated in paper. Due to limited paralelizablility of LSTM's and limited memory and gpu usage in colab, we would not able to finish the whole training process. Extensive research can be made with sufficient memory and gpu time. You can find the detailed explanation [here](https://github.com/sinankalkan/CENG501-Spring2021/blob/main/project_BarutcuDemir/readme.md)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zahXHJP-8xCR"
      },
      "source": [
        "# Install & Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivMqsZ7Oyf-G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b39e14a-b2f9-4fe8-a601-c4071efca173"
      },
      "source": [
        "!pip install torchinfo\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "from torchinfo import summary\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.7/dist-packages (1.5.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQgOBDWf9B-1"
      },
      "source": [
        "# Connect to GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Jmy2NS1yq5Q",
        "outputId": "8f003e6b-abf6-42f5-894d-8cf9dd15723c"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  print(\"Cuda (GPU support) is available and enabled!\")\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  print(\"Cuda (GPU support) is not available :(\")\n",
        "  device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda (GPU support) is not available :(\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2dVxiKm9HJy"
      },
      "source": [
        "# Install Glove Embeddings\n",
        "We used glove embedding to convert words in MNLI dataset to 300-dimensional vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EAxCDHyyy6s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7e6ad92-9238-47f1-a95d-5a055ed5b1b2"
      },
      "source": [
        "# Get pretrained glove for word embedding\n",
        "!wget http://nlp.stanford.edu/data/glove.42B.300d.zip\n",
        "!unzip -q glove.42B.300d.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-23 16:14:25--  http://nlp.stanford.edu/data/glove.42B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.42B.300d.zip [following]\n",
            "--2021-07-23 16:14:25--  https://nlp.stanford.edu/data/glove.42B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.42B.300d.zip [following]\n",
            "--2021-07-23 16:14:25--  http://downloads.cs.stanford.edu/nlp/data/glove.42B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1877800501 (1.7G) [application/zip]\n",
            "Saving to: ‘glove.42B.300d.zip.1’\n",
            "\n",
            "glove.42B.300d.zip. 100%[===================>]   1.75G  5.05MB/s    in 5m 54s  \n",
            "\n",
            "2021-07-23 16:20:19 (5.06 MB/s) - ‘glove.42B.300d.zip.1’ saved [1877800501/1877800501]\n",
            "\n",
            "replace glove.42B.300d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-Qe5A5s9xMo"
      },
      "source": [
        "# Load Dataset\n",
        "We used dataset library to get MNLI dataset. \"validation matched\" and \"validation mismatched\" are selected as validation, test data respectively. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzZ8J7W6y5y-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d415e138-3ec1-4842-c270-9f9bf201c5bb"
      },
      "source": [
        "# Load MNLI dataset\n",
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "train_ds, valid_ds, test_ds = load_dataset('multi_nli',split=['train','validation_matched','validation_mismatched'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.10.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.6.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.42 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.61.2)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.14)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.7.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset multi_nli (/root/.cache/huggingface/datasets/multi_nli/default/0.0.0/591f72eb6263d1ab527561777936b199b714cda156d35716881158a2bd144f39)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcufm18-y96U"
      },
      "source": [
        "# Convert dataset to dataframe\n",
        "train_df = train_ds.to_pandas()\n",
        "valid_df = train_ds.to_pandas()\n",
        "test_df = test_ds.to_pandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-eUwLBB-hS5"
      },
      "source": [
        "# Converting Glove to dictionary\n",
        "We store the words as key values in the corpus and 300-d vector represantations as values. This process allocates 2 gb in ram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlXD1DE_y2hj"
      },
      "source": [
        "# Convert Glove to dictionary\n",
        "embeddings_dict = {}\n",
        "with open(\"glove.42B.300d.txt\", 'r') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], \"float32\")\n",
        "        embeddings_dict[word] = vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILysIfnPzAiX"
      },
      "source": [
        "train_df = train_df[['premise','hypothesis','label']]\n",
        "valid_df = valid_df[['premise','hypothesis','label']]\n",
        "test_df = test_df[['premise','hypothesis','label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZmqmV9w_L6I"
      },
      "source": [
        "# Loading the Data\n",
        "Since converting the all words to embedding vectors before training requires 70 gb memory, we defined a \"DataLoader\" class to convert each training and validation instances into vector embeddings in batches at training time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak6L_wiAzOwU"
      },
      "source": [
        "class DataLoader:\n",
        "  def __init__(self, embedding_dict,train_df, val_df,batch_size):\n",
        "\n",
        "    self.MAX_LEN = 256\n",
        "    self.batch_size = batch_size\n",
        "    self.embedding_dict = embeddings_dict\n",
        "    self.train_df = train_df\n",
        "    self.val_df = val_df\n",
        "    self.tokenizer = WordPunctTokenizer()\n",
        "\n",
        "  def padding(self,word_list):\n",
        "    return word_list + ['0']*(self.MAX_LEN-len(word_list)) if len(word_list) <= self.MAX_LEN else word_list[:self.MAX_LEN]\n",
        "\n",
        "  def sample_data(self,df):\n",
        "    df_train = self.train_df.sample(n=self.batch_size)\n",
        "    df_valid = self.val_df.sample(n=self.batch_size)\n",
        "    return df_train,df_valid\n",
        "\n",
        "  def load_data(self, df,mode='train'):\n",
        "\n",
        "    if mode == 'train':\n",
        "      df,_ = self.sample_data(df)\n",
        "    else:\n",
        "      _,df = self.sample_data(df)\n",
        "\n",
        "    premise_embedding = []\n",
        "    hypothesis_embedding = []\n",
        "    labels = []\n",
        "\n",
        "    premise_list = df['premise'].to_list()\n",
        "    hypothesis_list = df['hypothesis'].to_list()\n",
        "    label_list = df['label'].to_list()\n",
        "\n",
        "    for (premise, hypothesis,label) in zip(premise_list, hypothesis_list,label_list):\n",
        "\n",
        "      premise_token = self.padding(self.tokenizer.tokenize((premise.lower())))\n",
        "      hypothesis_token = self.padding(self.tokenizer.tokenize((hypothesis.lower())))\n",
        "      try:\n",
        "        premise_embed = [self.embedding_dict[x] for x in premise_token]\n",
        "        hypothesis_embed = [self.embedding_dict[x] for x in hypothesis_token]\n",
        "        \n",
        "        premise_embedding.append(premise_embed)\n",
        "        hypothesis_embedding.append(hypothesis_embed)\n",
        "        labels.append(label)\n",
        "      except KeyError:\n",
        "        pass\n",
        "\n",
        "    premise_embedding = torch.tensor(premise_embedding)\n",
        "    hypothesis_embedding = torch.tensor(hypothesis_embedding)\n",
        "    labels = torch.tensor(labels)  #.reshape((len(labels),1))\n",
        "    return premise_embedding,hypothesis_embedding,labels\n",
        "\n",
        "  def get_train(self):\n",
        "    return self.load_data(self.train_df)\n",
        "\n",
        "  def get_valid(self):\n",
        "    return self.load_data(self.val_df,mode='valid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HGH9JfTAUDK"
      },
      "source": [
        "# Measure Vector Embedding Process Time\n",
        "Vector embedding process takes 4.5 seconds with truncation point is restricted with 256 characters. Process time changes linearly with truncation point and batch size. Since we convert those words in training time, this leads to longer iteration times in training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8itcncAfGpt",
        "outputId": "3e327786-52a1-4892-f22a-298b87dd5d1e"
      },
      "source": [
        "import time\n",
        "data = DataLoader(embeddings_dict,train_df,valid_df,128)\n",
        "t0= time.process_time()\n",
        "data.get_train()\n",
        "t1 = time.process_time()\n",
        "print(t1-t0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.582791444999998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1-3ghdRBal_"
      },
      "source": [
        "# PHM-LSTM Module\n",
        "We replaced standard unidirectional LSTM with PHM implementation by using kronecker product property, as stated in [paper](https://openreview.net/pdf?id=rcQdycl0zyk). Detailed explanation can be found  [here](https://github.com/sinankalkan/CENG501-Spring2021/blob/main/project_BarutcuDemir/readme.md)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZGZ7keozdkS"
      },
      "source": [
        "class PHMLSTM(torch.nn.Module):\n",
        "    def __init__(self,n, input_size, hidden_size):\n",
        "        \"\"\"\n",
        "          input_size: the size of the input at a time step.\n",
        "          hidden_size: the number of neurons in the hidden state.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.n = n\n",
        "        self.inp = input_size\n",
        "        self.hid = hidden_size\n",
        "\n",
        "        self.a_f = nn.Parameter(nn.init.xavier_uniform_(torch.zeros((self.n, self.n, self.n))))\n",
        "        self.s_f = nn.Parameter(nn.init.xavier_uniform_(torch.zeros((self.n, self.inp//self.n, self.hid//self.n))))\n",
        "\n",
        "        self.au_f = nn.Parameter(nn.init.xavier_uniform_(torch.zeros((self.n, self.n, self.n))))\n",
        "        self.su_f = nn.Parameter(nn.init.xavier_uniform_(torch.zeros((self.n, self.hid//n, self.hid//n))))\n",
        "\n",
        "        self.b_f = nn.Parameter(torch.zeros(self.hid))\n",
        "\n",
        "        self.a_i = nn.Parameter(nn.init.xavier_uniform_(torch.zeros((self.n, self.n, self.n))))\n",
        "        self.s_i = nn.Parameter(nn.init.xavier_uniform_(torch.zeros((self.n, self.inp//n, self.hid//n))))\n",
        "\n",
        "        self.au_i =  nn.Parameter(nn.init.xavier_uniform_(torch.zeros((n, n, n))))\n",
        "        self.su_i = nn.Parameter(nn.init.xavier_uniform_(torch.zeros((n, self.hid//n, self.hid//n))))\n",
        "\n",
        "        self.b_i = nn.Parameter(torch.zeros(self.hid))\n",
        "\n",
        "        self.a_o = nn.Parameter(nn.init.xavier_uniform_(torch.zeros((n, n, n))))\n",
        "        self.s_o = nn.Parameter(nn.init.xavier_uniform_(torch.zeros((n, self.inp//n, self.hid//n))))\n",
        "\n",
        "        self.au_o = nn.Parameter(nn.init.xavier_uniform_(torch.zeros((n, n, n))))\n",
        "        self.su_o = nn.Parameter(nn.init.xavier_uniform_(torch.zeros((n, self.hid//n, self.hid//n))))\n",
        "\n",
        "        self.b_o = nn.Parameter(torch.zeros(self.hid))\n",
        "\n",
        "        self.a_c = nn.Parameter(nn.init.xavier_uniform_(torch.zeros((n, n, n))))\n",
        "        self.s_c = nn.Parameter(nn.init.xavier_uniform_(torch.zeros((n, self.inp//n, self.hid//n))))\n",
        "\n",
        "        self.au_c = nn.Parameter(nn.init.xavier_uniform_(torch.zeros((n, n, n))))\n",
        "        self.su_c = nn.Parameter(nn.init.xavier_uniform_(torch.zeros((n, self.hid//n, self.hid//n))))\n",
        "\n",
        "        self.b_c = nn.Parameter(torch.zeros(self.hid))\n",
        "\n",
        "\n",
        "    def kronecker_product1(self, a, b):\n",
        "      siz1 = torch.Size(torch.tensor(a.shape[-2:]) * torch.tensor(b.shape[-2:]))\n",
        "      res = a.unsqueeze(-1).unsqueeze(-3) * b.unsqueeze(-2).unsqueeze(-4)\n",
        "      siz0 = res.shape[:-4]\n",
        "      out = res.reshape(siz0 + siz1)\n",
        "      return out\n",
        "    \n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "          X: An input that has L time steps and for each time step, it has \n",
        "          input_size many elements. Has shape (B, L, input_size) with B being \n",
        "          the batch size.\n",
        "\n",
        "          Output: Tuple (h, c) where h is the tensor holding the hidden state for L\n",
        "          time steps, and c is the tensor holding the memory state for L time steps. \n",
        "          Both have shape (B, L, hidden_size).\n",
        "        \"\"\"\n",
        "\n",
        "        B,L,inp_size = X.shape\n",
        "\n",
        "        self.W_f = torch.sum(self.kronecker_product1(self.a_f,self.s_f),dim=0)\n",
        "        self.U_f = torch.sum(self.kronecker_product1(self.au_f,self.su_f),dim=0)\n",
        "\n",
        "        self.W_i = torch.sum(self.kronecker_product1(self.a_i,self.s_i),dim=0)\n",
        "        self.U_i = torch.sum(self.kronecker_product1(self.au_i,self.su_i),dim=0)\n",
        "\n",
        "        self.W_o = torch.sum(self.kronecker_product1(self.a_o,self.s_o),dim=0)\n",
        "        self.U_o = torch.sum(self.kronecker_product1(self.au_o,self.su_o),dim=0)\n",
        "\n",
        "        self.W_c = torch.sum(self.kronecker_product1(self.a_c,self.s_c),dim=0)\n",
        "        self.U_c = torch.sum(self.kronecker_product1(self.au_c,self.su_c),dim=0)\n",
        "\n",
        "        self.h_prev = torch.zeros((B,self.hid)).to(device)\n",
        "        self.c_prev = torch.zeros((B,self.hid)).to(device)\n",
        "        \n",
        "        h = torch.zeros((B,L,self.hid)).to(device)\n",
        "        c = torch.zeros((B,L,self.hid)).to(device)\n",
        "\n",
        "        for t in range(L):\n",
        "          f = torch.sigmoid(torch.matmul(X[:,t,:],self.W_f) + torch.matmul(self.h_prev,self.U_f)+ self.b_f)\n",
        "          i = torch.sigmoid(torch.matmul(X[:,t,:],self.W_i) + torch.matmul(self.h_prev,self.U_i) + self.b_i)\n",
        "          o = torch.sigmoid(torch.matmul(X[:,t,:],self.W_o) + torch.matmul(self.h_prev,self.U_o) + self.b_o)\n",
        "          c_cap = torch.tanh(torch.matmul(X[:,t,:],self.W_c) + torch.matmul(self.h_prev,self.U_c) + self.b_c)\n",
        "          c[:,t,:] = f*self.c_prev + i*c_cap\n",
        "          h[:,t,:] = o*torch.sigmoid(c[:,t,:])\n",
        "          self.h_prev = h[:,t,:].clone()\n",
        "          self.c_prev = c[:,t,:].clone()\n",
        "        return (h,c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKzSBYmBFSDr"
      },
      "source": [
        "# Define The Network\n",
        "We implemented PHM-LSTM module following with concatenation process of premise and hypothesis hidden outputs and MLP with tanh activation function. Concatenation process is explained at [GitHub](https://github.com/sinankalkan/CENG501-Spring2021/blob/main/project_BarutcuDemir/readme.md) repository. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgdeHnzfznyh"
      },
      "source": [
        "class PHMModule(torch.nn.Module):\n",
        "\n",
        "    def __init__(self,n, input_dim, hidden_dim,max_len):\n",
        "        super().__init__()\n",
        "        \n",
        "        random.seed(501)\n",
        "        np.random.seed(501)\n",
        "        torch.manual_seed(501)\n",
        "\n",
        "        self.LSTM = PHMLSTM(n,input_dim,hidden_dim)\n",
        "        self.Linear1 = nn.Linear(max_len*4,100)\n",
        "        self.Linear2 = nn.Linear(100,3)\n",
        "\n",
        "    def forward(self, premise,hyphothesis):\n",
        "\n",
        "        h_premise,c_premise = self.LSTM(premise)\n",
        "        h_hypothesis,c_hypothesis = self.LSTM(hyphothesis)\n",
        "\n",
        "        hp_average = torch.mean(h_premise,2)\n",
        "        hp_max = torch.max(h_premise,2).values\n",
        "\n",
        "        hh_average = torch.mean(h_hypothesis,2)\n",
        "        hh_max = torch.max(h_hypothesis,2).values\n",
        "\n",
        "        v = torch.cat((hp_average,hp_max,hh_average,hh_max),1)\n",
        "\n",
        "        v = self.Linear1(v)\n",
        "        v = torch.tanh(v)\n",
        "        v = self.Linear2(v)\n",
        "        v = F.softmax(v,dim=1)\n",
        "        return v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbULk9Y87L00"
      },
      "source": [
        "# Training Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZdDWpkhzxDG"
      },
      "source": [
        "def train(model, criterion, optimizer, epochs, train_df,valid_df,embed_dict,batch_size,verbose_it=True,verbose=True):\n",
        "  \"\"\"\n",
        "    Define the trainer function. We can use this for training any model.\n",
        "    The parameter names are self-explanatory.\n",
        "\n",
        "    Returns: the loss history.\n",
        "  \"\"\"\n",
        "  data = DataLoader(embed_dict,train_df,valid_df,batch_size)\n",
        "  num_train = len(train_df)\n",
        "  loss_history = []\n",
        "  valid_loss = [] \n",
        "  for epoch in range(epochs):  \n",
        "    for it in range(int(num_train/batch_size)):\n",
        "      model.train()    \n",
        "\n",
        "      # Our batch:\n",
        "      premise,hypothesis, labels = data.get_train()\n",
        "      premise = premise.to(device)\n",
        "      hypothesis = hypothesis.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # zero the gradients as PyTorch accumulates them\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Obtain the scores\n",
        "      outputs = model(premise,hypothesis)\n",
        "\n",
        "      # Calculate loss\n",
        "      loss = criterion(outputs.to(device), labels)\n",
        "\n",
        "      # Backpropagate\n",
        "      loss.backward()\n",
        "\n",
        "      # Update the weights\n",
        "      optimizer.step()\n",
        "\n",
        "      loss_history.append(loss.item())\n",
        "      with torch.no_grad():\n",
        "\n",
        "        # Calculate validation loss in batches.\n",
        "\n",
        "        model.eval()\n",
        "        v_premise,v_hypothesis, v_labels = data.get_valid()\n",
        "        v_premise = v_premise.to(device)\n",
        "        v_hypothesis = v_hypothesis.to(device)\n",
        "        v_labels = v_labels.to(device)\n",
        "        v_outputs = model(v_premise,v_hypothesis)\n",
        "        v_loss = criterion(v_outputs.to(device), v_labels)\n",
        "        valid_loss.append(v_loss)\n",
        "        \n",
        "      if verbose_it: print(f'Train Loss at iteration {it+1}: {loss_history[-1]} | Validation Loss: {valid_loss[-1]}')\n",
        "      \n",
        "    if verbose: print(f'Epoch {epoch+1} / {epochs}: Avg. Train loss of last 5 iterations {np.sum(loss_history[:-6:-1])/5} | Validation Loss {np.sum(valid_loss[:-6:-1])/5} ')  \n",
        "  return loss_history,valid_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZA7oVf1GfKg"
      },
      "source": [
        "# Define The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfR_YGarzto5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb6514c0-0ba3-4490-98f2-0c76f9dc95a1"
      },
      "source": [
        "epochs = 10\n",
        "lr = 0.0004\n",
        "batch_size = 256\n",
        "hidden = 300\n",
        "max_len = 256\n",
        "input_size = 300\n",
        "n = 10\n",
        "\n",
        "model = PHMModule(n,input_size,hidden,max_len)\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "summary(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "PHMModule                                --\n",
              "├─PHMLSTM: 1-1                           81,200\n",
              "├─Linear: 1-2                            102,500\n",
              "├─Linear: 1-3                            303\n",
              "=================================================================\n",
              "Total params: 184,003\n",
              "Trainable params: 184,003\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVUQR7tHGlyX"
      },
      "source": [
        "# Train The Model\n",
        "Due to limited runtime of Colab, we were able to train the model with 857 iterations in 3 hours. Though model is not fully trained, we showed that both train and validation values are decreasing over iterations, thus model is learning with PHM implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM0vUxwG1tyg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3342ccdb-9393-4805-f9c3-c34cef3b57f4"
      },
      "source": [
        "train_loss,validation_loss = train(model, criterion, optimizer, epochs, train_df,valid_df,embeddings_dict,batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Loss at iteration 1: 1.0985090732574463 | Validation Loss: 1.102396845817566\n",
            "Train Loss at iteration 2: 1.0911962985992432 | Validation Loss: 1.1048578023910522\n",
            "Train Loss at iteration 3: 1.1106410026550293 | Validation Loss: 1.125192403793335\n",
            "Train Loss at iteration 4: 1.1193898916244507 | Validation Loss: 1.1178134679794312\n",
            "Train Loss at iteration 5: 1.110683560371399 | Validation Loss: 1.089297890663147\n",
            "Train Loss at iteration 6: 1.1067328453063965 | Validation Loss: 1.0998872518539429\n",
            "Train Loss at iteration 7: 1.09945547580719 | Validation Loss: 1.1015677452087402\n",
            "Train Loss at iteration 8: 1.1018390655517578 | Validation Loss: 1.0983408689498901\n",
            "Train Loss at iteration 9: 1.1089692115783691 | Validation Loss: 1.1009223461151123\n",
            "Train Loss at iteration 10: 1.1052794456481934 | Validation Loss: 1.101319432258606\n",
            "Train Loss at iteration 11: 1.0924773216247559 | Validation Loss: 1.1011736392974854\n",
            "Train Loss at iteration 12: 1.0983141660690308 | Validation Loss: 1.1079963445663452\n",
            "Train Loss at iteration 13: 1.1017986536026 | Validation Loss: 1.1080131530761719\n",
            "Train Loss at iteration 14: 1.1012736558914185 | Validation Loss: 1.1044048070907593\n",
            "Train Loss at iteration 15: 1.1076078414916992 | Validation Loss: 1.1068496704101562\n",
            "Train Loss at iteration 16: 1.1024231910705566 | Validation Loss: 1.105641484260559\n",
            "Train Loss at iteration 17: 1.104353427886963 | Validation Loss: 1.099273920059204\n",
            "Train Loss at iteration 18: 1.1028724908828735 | Validation Loss: 1.0984102487564087\n",
            "Train Loss at iteration 19: 1.0989619493484497 | Validation Loss: 1.0978751182556152\n",
            "Train Loss at iteration 20: 1.0968708992004395 | Validation Loss: 1.1070562601089478\n",
            "Train Loss at iteration 21: 1.1014093160629272 | Validation Loss: 1.1004979610443115\n",
            "Train Loss at iteration 22: 1.1147326231002808 | Validation Loss: 1.1034226417541504\n",
            "Train Loss at iteration 23: 1.0934373140335083 | Validation Loss: 1.0985515117645264\n",
            "Train Loss at iteration 24: 1.0977790355682373 | Validation Loss: 1.1223102807998657\n",
            "Train Loss at iteration 25: 1.1023210287094116 | Validation Loss: 1.1150273084640503\n",
            "Train Loss at iteration 26: 1.1104038953781128 | Validation Loss: 1.091515302658081\n",
            "Train Loss at iteration 27: 1.1093493700027466 | Validation Loss: 1.119964361190796\n",
            "Train Loss at iteration 28: 1.1088835000991821 | Validation Loss: 1.1048599481582642\n",
            "Train Loss at iteration 29: 1.1092416048049927 | Validation Loss: 1.0961697101593018\n",
            "Train Loss at iteration 30: 1.0992757081985474 | Validation Loss: 1.099259853363037\n",
            "Train Loss at iteration 31: 1.0958995819091797 | Validation Loss: 1.0986132621765137\n",
            "Train Loss at iteration 32: 1.0990060567855835 | Validation Loss: 1.099724531173706\n",
            "Train Loss at iteration 33: 1.0991536378860474 | Validation Loss: 1.0982533693313599\n",
            "Train Loss at iteration 34: 1.101563572883606 | Validation Loss: 1.1025876998901367\n",
            "Train Loss at iteration 35: 1.0967084169387817 | Validation Loss: 1.096970796585083\n",
            "Train Loss at iteration 36: 1.0952941179275513 | Validation Loss: 1.0987427234649658\n",
            "Train Loss at iteration 37: 1.1024326086044312 | Validation Loss: 1.0982675552368164\n",
            "Train Loss at iteration 38: 1.1016348600387573 | Validation Loss: 1.1090558767318726\n",
            "Train Loss at iteration 39: 1.100813388824463 | Validation Loss: 1.0943199396133423\n",
            "Train Loss at iteration 40: 1.1005054712295532 | Validation Loss: 1.0878746509552002\n",
            "Train Loss at iteration 41: 1.098305106163025 | Validation Loss: 1.1067383289337158\n",
            "Train Loss at iteration 42: 1.099095106124878 | Validation Loss: 1.1013957262039185\n",
            "Train Loss at iteration 43: 1.095078945159912 | Validation Loss: 1.0997192859649658\n",
            "Train Loss at iteration 44: 1.1051850318908691 | Validation Loss: 1.1000211238861084\n",
            "Train Loss at iteration 45: 1.1008617877960205 | Validation Loss: 1.0981459617614746\n",
            "Train Loss at iteration 46: 1.1006042957305908 | Validation Loss: 1.0974422693252563\n",
            "Train Loss at iteration 47: 1.0986586809158325 | Validation Loss: 1.0986955165863037\n",
            "Train Loss at iteration 48: 1.101440668106079 | Validation Loss: 1.099212884902954\n",
            "Train Loss at iteration 49: 1.100083827972412 | Validation Loss: 1.097523808479309\n",
            "Train Loss at iteration 50: 1.0984439849853516 | Validation Loss: 1.0956735610961914\n",
            "Train Loss at iteration 51: 1.099043369293213 | Validation Loss: 1.098357081413269\n",
            "Train Loss at iteration 52: 1.1016908884048462 | Validation Loss: 1.0958378314971924\n",
            "Train Loss at iteration 53: 1.1009955406188965 | Validation Loss: 1.1021348237991333\n",
            "Train Loss at iteration 54: 1.0979002714157104 | Validation Loss: 1.0993871688842773\n",
            "Train Loss at iteration 55: 1.0976351499557495 | Validation Loss: 1.1045128107070923\n",
            "Train Loss at iteration 56: 1.0988084077835083 | Validation Loss: 1.0999305248260498\n",
            "Train Loss at iteration 57: 1.103034496307373 | Validation Loss: 1.0972630977630615\n",
            "Train Loss at iteration 58: 1.0935131311416626 | Validation Loss: 1.0989513397216797\n",
            "Train Loss at iteration 59: 1.100576400756836 | Validation Loss: 1.097088098526001\n",
            "Train Loss at iteration 60: 1.099947214126587 | Validation Loss: 1.1018904447555542\n",
            "Train Loss at iteration 61: 1.100195288658142 | Validation Loss: 1.0977554321289062\n",
            "Train Loss at iteration 62: 1.097731351852417 | Validation Loss: 1.0979236364364624\n",
            "Train Loss at iteration 63: 1.1027837991714478 | Validation Loss: 1.095848560333252\n",
            "Train Loss at iteration 64: 1.1034244298934937 | Validation Loss: 1.096659541130066\n",
            "Train Loss at iteration 65: 1.102687120437622 | Validation Loss: 1.0980842113494873\n",
            "Train Loss at iteration 66: 1.0982849597930908 | Validation Loss: 1.0981976985931396\n",
            "Train Loss at iteration 67: 1.0973654985427856 | Validation Loss: 1.0999692678451538\n",
            "Train Loss at iteration 68: 1.0972970724105835 | Validation Loss: 1.1021398305892944\n",
            "Train Loss at iteration 69: 1.1002147197723389 | Validation Loss: 1.1023671627044678\n",
            "Train Loss at iteration 70: 1.098699688911438 | Validation Loss: 1.0980654954910278\n",
            "Train Loss at iteration 71: 1.0981521606445312 | Validation Loss: 1.0994123220443726\n",
            "Train Loss at iteration 72: 1.1006656885147095 | Validation Loss: 1.1056923866271973\n",
            "Train Loss at iteration 73: 1.0961350202560425 | Validation Loss: 1.1020852327346802\n",
            "Train Loss at iteration 74: 1.0971535444259644 | Validation Loss: 1.1054474115371704\n",
            "Train Loss at iteration 75: 1.1024521589279175 | Validation Loss: 1.105957269668579\n",
            "Train Loss at iteration 76: 1.093037486076355 | Validation Loss: 1.1016007661819458\n",
            "Train Loss at iteration 77: 1.1074292659759521 | Validation Loss: 1.0917768478393555\n",
            "Train Loss at iteration 78: 1.097105860710144 | Validation Loss: 1.1051526069641113\n",
            "Train Loss at iteration 79: 1.101989507675171 | Validation Loss: 1.1094969511032104\n",
            "Train Loss at iteration 80: 1.1046353578567505 | Validation Loss: 1.1157758235931396\n",
            "Train Loss at iteration 81: 1.1034057140350342 | Validation Loss: 1.105089545249939\n",
            "Train Loss at iteration 82: 1.106160044670105 | Validation Loss: 1.0976279973983765\n",
            "Train Loss at iteration 83: 1.0932508707046509 | Validation Loss: 1.090835452079773\n",
            "Train Loss at iteration 84: 1.1024856567382812 | Validation Loss: 1.0975208282470703\n",
            "Train Loss at iteration 85: 1.1030741930007935 | Validation Loss: 1.0975327491760254\n",
            "Train Loss at iteration 86: 1.0970475673675537 | Validation Loss: 1.0955278873443604\n",
            "Train Loss at iteration 87: 1.098484992980957 | Validation Loss: 1.0976649522781372\n",
            "Train Loss at iteration 88: 1.0989431142807007 | Validation Loss: 1.1028369665145874\n",
            "Train Loss at iteration 89: 1.09889817237854 | Validation Loss: 1.1006852388381958\n",
            "Train Loss at iteration 90: 1.0991694927215576 | Validation Loss: 1.1025017499923706\n",
            "Train Loss at iteration 91: 1.097342848777771 | Validation Loss: 1.1027339696884155\n",
            "Train Loss at iteration 92: 1.101226568222046 | Validation Loss: 1.108465552330017\n",
            "Train Loss at iteration 93: 1.103384256362915 | Validation Loss: 1.105068325996399\n",
            "Train Loss at iteration 94: 1.1100382804870605 | Validation Loss: 1.0992062091827393\n",
            "Train Loss at iteration 95: 1.1018680334091187 | Validation Loss: 1.1002066135406494\n",
            "Train Loss at iteration 96: 1.0957443714141846 | Validation Loss: 1.098991870880127\n",
            "Train Loss at iteration 97: 1.100555181503296 | Validation Loss: 1.0994665622711182\n",
            "Train Loss at iteration 98: 1.0989601612091064 | Validation Loss: 1.099833369255066\n",
            "Train Loss at iteration 99: 1.0954161882400513 | Validation Loss: 1.1024260520935059\n",
            "Train Loss at iteration 100: 1.0975710153579712 | Validation Loss: 1.1050920486450195\n",
            "Train Loss at iteration 101: 1.098902702331543 | Validation Loss: 1.1036630868911743\n",
            "Train Loss at iteration 102: 1.0971121788024902 | Validation Loss: 1.1030734777450562\n",
            "Train Loss at iteration 103: 1.1071703433990479 | Validation Loss: 1.101773738861084\n",
            "Train Loss at iteration 104: 1.1002932786941528 | Validation Loss: 1.098942756652832\n",
            "Train Loss at iteration 105: 1.100930094718933 | Validation Loss: 1.1004817485809326\n",
            "Train Loss at iteration 106: 1.0984116792678833 | Validation Loss: 1.0966895818710327\n",
            "Train Loss at iteration 107: 1.097328782081604 | Validation Loss: 1.0973683595657349\n",
            "Train Loss at iteration 108: 1.0986350774765015 | Validation Loss: 1.095888376235962\n",
            "Train Loss at iteration 109: 1.1004024744033813 | Validation Loss: 1.0982621908187866\n",
            "Train Loss at iteration 110: 1.09915292263031 | Validation Loss: 1.0981738567352295\n",
            "Train Loss at iteration 111: 1.0977108478546143 | Validation Loss: 1.0978691577911377\n",
            "Train Loss at iteration 112: 1.098369836807251 | Validation Loss: 1.0990664958953857\n",
            "Train Loss at iteration 113: 1.0991512537002563 | Validation Loss: 1.0993268489837646\n",
            "Train Loss at iteration 114: 1.0986461639404297 | Validation Loss: 1.0986440181732178\n",
            "Train Loss at iteration 115: 1.0987845659255981 | Validation Loss: 1.0986818075180054\n",
            "Train Loss at iteration 116: 1.097997784614563 | Validation Loss: 1.0987739562988281\n",
            "Train Loss at iteration 117: 1.0979996919631958 | Validation Loss: 1.0974032878875732\n",
            "Train Loss at iteration 118: 1.0994017124176025 | Validation Loss: 1.1005594730377197\n",
            "Train Loss at iteration 119: 1.1010093688964844 | Validation Loss: 1.0990771055221558\n",
            "Train Loss at iteration 120: 1.098053216934204 | Validation Loss: 1.0986073017120361\n",
            "Train Loss at iteration 121: 1.1003631353378296 | Validation Loss: 1.0982444286346436\n",
            "Train Loss at iteration 122: 1.0987168550491333 | Validation Loss: 1.0986120700836182\n",
            "Train Loss at iteration 123: 1.0979188680648804 | Validation Loss: 1.0981560945510864\n",
            "Train Loss at iteration 124: 1.0985757112503052 | Validation Loss: 1.0984289646148682\n",
            "Train Loss at iteration 125: 1.0982400178909302 | Validation Loss: 1.0995103120803833\n",
            "Train Loss at iteration 126: 1.099021315574646 | Validation Loss: 1.0976635217666626\n",
            "Train Loss at iteration 127: 1.0975518226623535 | Validation Loss: 1.0999739170074463\n",
            "Train Loss at iteration 128: 1.0992541313171387 | Validation Loss: 1.0981037616729736\n",
            "Train Loss at iteration 129: 1.0989890098571777 | Validation Loss: 1.1006131172180176\n",
            "Train Loss at iteration 130: 1.0988271236419678 | Validation Loss: 1.0998413562774658\n",
            "Train Loss at iteration 131: 1.0981138944625854 | Validation Loss: 1.1006616353988647\n",
            "Train Loss at iteration 132: 1.100045084953308 | Validation Loss: 1.1001358032226562\n",
            "Train Loss at iteration 133: 1.0971759557724 | Validation Loss: 1.097514033317566\n",
            "Train Loss at iteration 134: 1.09843111038208 | Validation Loss: 1.0964068174362183\n",
            "Train Loss at iteration 135: 1.0990445613861084 | Validation Loss: 1.0990725755691528\n",
            "Train Loss at iteration 136: 1.098059892654419 | Validation Loss: 1.097582221031189\n",
            "Train Loss at iteration 137: 1.0957238674163818 | Validation Loss: 1.0960088968276978\n",
            "Train Loss at iteration 138: 1.0984114408493042 | Validation Loss: 1.1018126010894775\n",
            "Train Loss at iteration 139: 1.0980899333953857 | Validation Loss: 1.0992472171783447\n",
            "Train Loss at iteration 140: 1.0994174480438232 | Validation Loss: 1.1077369451522827\n",
            "Train Loss at iteration 141: 1.092414140701294 | Validation Loss: 1.1043447256088257\n",
            "Train Loss at iteration 142: 1.102806806564331 | Validation Loss: 1.0956555604934692\n",
            "Train Loss at iteration 143: 1.104148030281067 | Validation Loss: 1.09872305393219\n",
            "Train Loss at iteration 144: 1.1004856824874878 | Validation Loss: 1.1024303436279297\n",
            "Train Loss at iteration 145: 1.098061442375183 | Validation Loss: 1.093825340270996\n",
            "Train Loss at iteration 146: 1.1029139757156372 | Validation Loss: 1.0984885692596436\n",
            "Train Loss at iteration 147: 1.0997554063796997 | Validation Loss: 1.09860098361969\n",
            "Train Loss at iteration 148: 1.0977060794830322 | Validation Loss: 1.10025155544281\n",
            "Train Loss at iteration 149: 1.0991097688674927 | Validation Loss: 1.0989936590194702\n",
            "Train Loss at iteration 150: 1.098280906677246 | Validation Loss: 1.09952974319458\n",
            "Train Loss at iteration 151: 1.098951816558838 | Validation Loss: 1.1000585556030273\n",
            "Train Loss at iteration 152: 1.0974326133728027 | Validation Loss: 1.1014841794967651\n",
            "Train Loss at iteration 153: 1.1062337160110474 | Validation Loss: 1.0985889434814453\n",
            "Train Loss at iteration 154: 1.102609634399414 | Validation Loss: 1.0993908643722534\n",
            "Train Loss at iteration 155: 1.102738857269287 | Validation Loss: 1.1027765274047852\n",
            "Train Loss at iteration 156: 1.097447395324707 | Validation Loss: 1.0985300540924072\n",
            "Train Loss at iteration 157: 1.1012715101242065 | Validation Loss: 1.0979975461959839\n",
            "Train Loss at iteration 158: 1.09843111038208 | Validation Loss: 1.0992491245269775\n",
            "Train Loss at iteration 159: 1.0978599786758423 | Validation Loss: 1.0996111631393433\n",
            "Train Loss at iteration 160: 1.1008884906768799 | Validation Loss: 1.0990110635757446\n",
            "Train Loss at iteration 161: 1.1005253791809082 | Validation Loss: 1.0975570678710938\n",
            "Train Loss at iteration 162: 1.09902822971344 | Validation Loss: 1.0985914468765259\n",
            "Train Loss at iteration 163: 1.101078987121582 | Validation Loss: 1.0977181196212769\n",
            "Train Loss at iteration 164: 1.0958348512649536 | Validation Loss: 1.0988411903381348\n",
            "Train Loss at iteration 165: 1.0989151000976562 | Validation Loss: 1.0991274118423462\n",
            "Train Loss at iteration 166: 1.0963387489318848 | Validation Loss: 1.0986037254333496\n",
            "Train Loss at iteration 167: 1.0945881605148315 | Validation Loss: 1.0958983898162842\n",
            "Train Loss at iteration 168: 1.0985019207000732 | Validation Loss: 1.102554202079773\n",
            "Train Loss at iteration 169: 1.0992927551269531 | Validation Loss: 1.0988211631774902\n",
            "Train Loss at iteration 170: 1.100695252418518 | Validation Loss: 1.0965015888214111\n",
            "Train Loss at iteration 171: 1.0983281135559082 | Validation Loss: 1.1072181463241577\n",
            "Train Loss at iteration 172: 1.0980746746063232 | Validation Loss: 1.10575532913208\n",
            "Train Loss at iteration 173: 1.10220205783844 | Validation Loss: 1.1025868654251099\n",
            "Train Loss at iteration 174: 1.09889817237854 | Validation Loss: 1.0966250896453857\n",
            "Train Loss at iteration 175: 1.090898036956787 | Validation Loss: 1.1007426977157593\n",
            "Train Loss at iteration 176: 1.1005131006240845 | Validation Loss: 1.0946073532104492\n",
            "Train Loss at iteration 177: 1.1014446020126343 | Validation Loss: 1.0981894731521606\n",
            "Train Loss at iteration 178: 1.1019889116287231 | Validation Loss: 1.102362871170044\n",
            "Train Loss at iteration 179: 1.1007038354873657 | Validation Loss: 1.0990413427352905\n",
            "Train Loss at iteration 180: 1.0981253385543823 | Validation Loss: 1.0983359813690186\n",
            "Train Loss at iteration 181: 1.0988012552261353 | Validation Loss: 1.0985194444656372\n",
            "Train Loss at iteration 182: 1.0980304479599 | Validation Loss: 1.1019721031188965\n",
            "Train Loss at iteration 183: 1.0960396528244019 | Validation Loss: 1.1036102771759033\n",
            "Train Loss at iteration 184: 1.1007481813430786 | Validation Loss: 1.1051974296569824\n",
            "Train Loss at iteration 185: 1.100773572921753 | Validation Loss: 1.101279616355896\n",
            "Train Loss at iteration 186: 1.0947071313858032 | Validation Loss: 1.1032384634017944\n",
            "Train Loss at iteration 187: 1.100296139717102 | Validation Loss: 1.1012850999832153\n",
            "Train Loss at iteration 188: 1.101542592048645 | Validation Loss: 1.1059684753417969\n",
            "Train Loss at iteration 189: 1.1137953996658325 | Validation Loss: 1.0906093120574951\n",
            "Train Loss at iteration 190: 1.1035224199295044 | Validation Loss: 1.1075037717819214\n",
            "Train Loss at iteration 191: 1.100906491279602 | Validation Loss: 1.096091389656067\n",
            "Train Loss at iteration 192: 1.102872371673584 | Validation Loss: 1.0996421575546265\n",
            "Train Loss at iteration 193: 1.097100019454956 | Validation Loss: 1.0987993478775024\n",
            "Train Loss at iteration 194: 1.101875901222229 | Validation Loss: 1.0956002473831177\n",
            "Train Loss at iteration 195: 1.0963584184646606 | Validation Loss: 1.0980968475341797\n",
            "Train Loss at iteration 196: 1.0957602262496948 | Validation Loss: 1.099993348121643\n",
            "Train Loss at iteration 197: 1.0960924625396729 | Validation Loss: 1.0998142957687378\n",
            "Train Loss at iteration 198: 1.098497986793518 | Validation Loss: 1.0940409898757935\n",
            "Train Loss at iteration 199: 1.099521517753601 | Validation Loss: 1.1012054681777954\n",
            "Train Loss at iteration 200: 1.095283031463623 | Validation Loss: 1.1007437705993652\n",
            "Train Loss at iteration 201: 1.0984605550765991 | Validation Loss: 1.0983620882034302\n",
            "Train Loss at iteration 202: 1.0997381210327148 | Validation Loss: 1.0991504192352295\n",
            "Train Loss at iteration 203: 1.1085580587387085 | Validation Loss: 1.0934187173843384\n",
            "Train Loss at iteration 204: 1.0956205129623413 | Validation Loss: 1.1031595468521118\n",
            "Train Loss at iteration 205: 1.1003365516662598 | Validation Loss: 1.0972825288772583\n",
            "Train Loss at iteration 206: 1.0982043743133545 | Validation Loss: 1.1053974628448486\n",
            "Train Loss at iteration 207: 1.0989145040512085 | Validation Loss: 1.0967899560928345\n",
            "Train Loss at iteration 208: 1.106842279434204 | Validation Loss: 1.1166070699691772\n",
            "Train Loss at iteration 209: 1.103409767150879 | Validation Loss: 1.0928218364715576\n",
            "Train Loss at iteration 210: 1.1000657081604004 | Validation Loss: 1.0974093675613403\n",
            "Train Loss at iteration 211: 1.1003435850143433 | Validation Loss: 1.1038998365402222\n",
            "Train Loss at iteration 212: 1.1033543348312378 | Validation Loss: 1.1028916835784912\n",
            "Train Loss at iteration 213: 1.1013585329055786 | Validation Loss: 1.0968496799468994\n",
            "Train Loss at iteration 214: 1.096339464187622 | Validation Loss: 1.0982959270477295\n",
            "Train Loss at iteration 215: 1.0973246097564697 | Validation Loss: 1.0988914966583252\n",
            "Train Loss at iteration 216: 1.0985350608825684 | Validation Loss: 1.0985815525054932\n",
            "Train Loss at iteration 217: 1.0973467826843262 | Validation Loss: 1.0974828004837036\n",
            "Train Loss at iteration 218: 1.0994943380355835 | Validation Loss: 1.0958912372589111\n",
            "Train Loss at iteration 219: 1.0969007015228271 | Validation Loss: 1.1007553339004517\n",
            "Train Loss at iteration 220: 1.1000194549560547 | Validation Loss: 1.103675365447998\n",
            "Train Loss at iteration 221: 1.0972768068313599 | Validation Loss: 1.1009974479675293\n",
            "Train Loss at iteration 222: 1.0985127687454224 | Validation Loss: 1.0992350578308105\n",
            "Train Loss at iteration 223: 1.1036823987960815 | Validation Loss: 1.099397897720337\n",
            "Train Loss at iteration 224: 1.0968961715698242 | Validation Loss: 1.1057796478271484\n",
            "Train Loss at iteration 225: 1.097069501876831 | Validation Loss: 1.0983887910842896\n",
            "Train Loss at iteration 226: 1.1025220155715942 | Validation Loss: 1.0978020429611206\n",
            "Train Loss at iteration 227: 1.1028603315353394 | Validation Loss: 1.0980851650238037\n",
            "Train Loss at iteration 228: 1.0997287034988403 | Validation Loss: 1.097122073173523\n",
            "Train Loss at iteration 229: 1.096666932106018 | Validation Loss: 1.0955647230148315\n",
            "Train Loss at iteration 230: 1.0969595909118652 | Validation Loss: 1.0973609685897827\n",
            "Train Loss at iteration 231: 1.0989117622375488 | Validation Loss: 1.095593810081482\n",
            "Train Loss at iteration 232: 1.0978890657424927 | Validation Loss: 1.0968703031539917\n",
            "Train Loss at iteration 233: 1.09768807888031 | Validation Loss: 1.0967317819595337\n",
            "Train Loss at iteration 234: 1.0975884199142456 | Validation Loss: 1.0975340604782104\n",
            "Train Loss at iteration 235: 1.0985157489776611 | Validation Loss: 1.0975620746612549\n",
            "Train Loss at iteration 236: 1.0971852540969849 | Validation Loss: 1.0976464748382568\n",
            "Train Loss at iteration 237: 1.0981180667877197 | Validation Loss: 1.098648190498352\n",
            "Train Loss at iteration 238: 1.0984814167022705 | Validation Loss: 1.0983549356460571\n",
            "Train Loss at iteration 239: 1.097694754600525 | Validation Loss: 1.0993887186050415\n",
            "Train Loss at iteration 240: 1.097081184387207 | Validation Loss: 1.096491813659668\n",
            "Train Loss at iteration 241: 1.098164439201355 | Validation Loss: 1.096623182296753\n",
            "Train Loss at iteration 242: 1.0961432456970215 | Validation Loss: 1.0961138010025024\n",
            "Train Loss at iteration 243: 1.0971927642822266 | Validation Loss: 1.0990521907806396\n",
            "Train Loss at iteration 244: 1.0950335264205933 | Validation Loss: 1.0988224744796753\n",
            "Train Loss at iteration 245: 1.09540593624115 | Validation Loss: 1.0982848405838013\n",
            "Train Loss at iteration 246: 1.0968583822250366 | Validation Loss: 1.0939191579818726\n",
            "Train Loss at iteration 247: 1.095323085784912 | Validation Loss: 1.0961847305297852\n",
            "Train Loss at iteration 248: 1.0968022346496582 | Validation Loss: 1.0965940952301025\n",
            "Train Loss at iteration 249: 1.0971730947494507 | Validation Loss: 1.0949043035507202\n",
            "Train Loss at iteration 250: 1.1004444360733032 | Validation Loss: 1.0978116989135742\n",
            "Train Loss at iteration 251: 1.0990493297576904 | Validation Loss: 1.0987590551376343\n",
            "Train Loss at iteration 252: 1.0985987186431885 | Validation Loss: 1.096502661705017\n",
            "Train Loss at iteration 253: 1.0966174602508545 | Validation Loss: 1.0962713956832886\n",
            "Train Loss at iteration 254: 1.0966758728027344 | Validation Loss: 1.095137119293213\n",
            "Train Loss at iteration 255: 1.095484972000122 | Validation Loss: 1.0973036289215088\n",
            "Train Loss at iteration 256: 1.093281626701355 | Validation Loss: 1.0960980653762817\n",
            "Train Loss at iteration 257: 1.0983752012252808 | Validation Loss: 1.0954018831253052\n",
            "Train Loss at iteration 258: 1.0968197584152222 | Validation Loss: 1.1001869440078735\n",
            "Train Loss at iteration 259: 1.0974888801574707 | Validation Loss: 1.098454475402832\n",
            "Train Loss at iteration 260: 1.091374158859253 | Validation Loss: 1.0919533967971802\n",
            "Train Loss at iteration 261: 1.0953742265701294 | Validation Loss: 1.097941517829895\n",
            "Train Loss at iteration 262: 1.097656488418579 | Validation Loss: 1.0940673351287842\n",
            "Train Loss at iteration 263: 1.1002426147460938 | Validation Loss: 1.0914595127105713\n",
            "Train Loss at iteration 264: 1.0886733531951904 | Validation Loss: 1.103230595588684\n",
            "Train Loss at iteration 265: 1.0992956161499023 | Validation Loss: 1.1010627746582031\n",
            "Train Loss at iteration 266: 1.0959208011627197 | Validation Loss: 1.0924323797225952\n",
            "Train Loss at iteration 267: 1.0932223796844482 | Validation Loss: 1.0953646898269653\n",
            "Train Loss at iteration 268: 1.093740463256836 | Validation Loss: 1.0918567180633545\n",
            "Train Loss at iteration 269: 1.0964891910552979 | Validation Loss: 1.0966172218322754\n",
            "Train Loss at iteration 270: 1.0950350761413574 | Validation Loss: 1.094617486000061\n",
            "Train Loss at iteration 271: 1.0928783416748047 | Validation Loss: 1.0938886404037476\n",
            "Train Loss at iteration 272: 1.0933830738067627 | Validation Loss: 1.0977776050567627\n",
            "Train Loss at iteration 273: 1.0960333347320557 | Validation Loss: 1.0947052240371704\n",
            "Train Loss at iteration 274: 1.0948740243911743 | Validation Loss: 1.092298150062561\n",
            "Train Loss at iteration 275: 1.0951426029205322 | Validation Loss: 1.0979437828063965\n",
            "Train Loss at iteration 276: 1.097214698791504 | Validation Loss: 1.0949137210845947\n",
            "Train Loss at iteration 277: 1.0905512571334839 | Validation Loss: 1.090628743171692\n",
            "Train Loss at iteration 278: 1.0933468341827393 | Validation Loss: 1.100523829460144\n",
            "Train Loss at iteration 279: 1.0960954427719116 | Validation Loss: 1.0929956436157227\n",
            "Train Loss at iteration 280: 1.0890063047409058 | Validation Loss: 1.0909712314605713\n",
            "Train Loss at iteration 281: 1.090553641319275 | Validation Loss: 1.096418857574463\n",
            "Train Loss at iteration 282: 1.0939877033233643 | Validation Loss: 1.0954793691635132\n",
            "Train Loss at iteration 283: 1.0923731327056885 | Validation Loss: 1.095028042793274\n",
            "Train Loss at iteration 284: 1.100155234336853 | Validation Loss: 1.0955549478530884\n",
            "Train Loss at iteration 285: 1.0996192693710327 | Validation Loss: 1.094887614250183\n",
            "Train Loss at iteration 286: 1.089585781097412 | Validation Loss: 1.0883044004440308\n",
            "Train Loss at iteration 287: 1.0918207168579102 | Validation Loss: 1.0965834856033325\n",
            "Train Loss at iteration 288: 1.0925170183181763 | Validation Loss: 1.092212200164795\n",
            "Train Loss at iteration 289: 1.082066297531128 | Validation Loss: 1.0930246114730835\n",
            "Train Loss at iteration 290: 1.0904488563537598 | Validation Loss: 1.0947916507720947\n",
            "Train Loss at iteration 291: 1.0918211936950684 | Validation Loss: 1.0933794975280762\n",
            "Train Loss at iteration 292: 1.0925074815750122 | Validation Loss: 1.0928423404693604\n",
            "Train Loss at iteration 293: 1.093795895576477 | Validation Loss: 1.0972391366958618\n",
            "Train Loss at iteration 294: 1.0910319089889526 | Validation Loss: 1.0871373414993286\n",
            "Train Loss at iteration 295: 1.0917590856552124 | Validation Loss: 1.0871472358703613\n",
            "Train Loss at iteration 296: 1.0924267768859863 | Validation Loss: 1.100975513458252\n",
            "Train Loss at iteration 297: 1.0876727104187012 | Validation Loss: 1.087421178817749\n",
            "Train Loss at iteration 298: 1.0950618982315063 | Validation Loss: 1.0896803140640259\n",
            "Train Loss at iteration 299: 1.0932778120040894 | Validation Loss: 1.0901386737823486\n",
            "Train Loss at iteration 300: 1.0883327722549438 | Validation Loss: 1.088194727897644\n",
            "Train Loss at iteration 301: 1.093211054801941 | Validation Loss: 1.0894701480865479\n",
            "Train Loss at iteration 302: 1.0938608646392822 | Validation Loss: 1.0991803407669067\n",
            "Train Loss at iteration 303: 1.095265507698059 | Validation Loss: 1.0903764963150024\n",
            "Train Loss at iteration 304: 1.0875414609909058 | Validation Loss: 1.0940736532211304\n",
            "Train Loss at iteration 305: 1.0921305418014526 | Validation Loss: 1.0869169235229492\n",
            "Train Loss at iteration 306: 1.08724045753479 | Validation Loss: 1.0959950685501099\n",
            "Train Loss at iteration 307: 1.0948799848556519 | Validation Loss: 1.0931665897369385\n",
            "Train Loss at iteration 308: 1.0944325923919678 | Validation Loss: 1.091138482093811\n",
            "Train Loss at iteration 309: 1.0886788368225098 | Validation Loss: 1.0842944383621216\n",
            "Train Loss at iteration 310: 1.0871177911758423 | Validation Loss: 1.0908939838409424\n",
            "Train Loss at iteration 311: 1.0857324600219727 | Validation Loss: 1.091369390487671\n",
            "Train Loss at iteration 312: 1.084876537322998 | Validation Loss: 1.0849018096923828\n",
            "Train Loss at iteration 313: 1.0915085077285767 | Validation Loss: 1.0867661237716675\n",
            "Train Loss at iteration 314: 1.1030453443527222 | Validation Loss: 1.0794364213943481\n",
            "Train Loss at iteration 315: 1.0880498886108398 | Validation Loss: 1.08235502243042\n",
            "Train Loss at iteration 316: 1.0844454765319824 | Validation Loss: 1.0871764421463013\n",
            "Train Loss at iteration 317: 1.0887597799301147 | Validation Loss: 1.0968132019042969\n",
            "Train Loss at iteration 318: 1.0778985023498535 | Validation Loss: 1.0949374437332153\n",
            "Train Loss at iteration 319: 1.083465814590454 | Validation Loss: 1.0813506841659546\n",
            "Train Loss at iteration 320: 1.085157036781311 | Validation Loss: 1.0892236232757568\n",
            "Train Loss at iteration 321: 1.0841455459594727 | Validation Loss: 1.0897115468978882\n",
            "Train Loss at iteration 322: 1.0922315120697021 | Validation Loss: 1.0931718349456787\n",
            "Train Loss at iteration 323: 1.0950325727462769 | Validation Loss: 1.0710124969482422\n",
            "Train Loss at iteration 324: 1.0846880674362183 | Validation Loss: 1.0957003831863403\n",
            "Train Loss at iteration 325: 1.0850404500961304 | Validation Loss: 1.0818796157836914\n",
            "Train Loss at iteration 326: 1.0916576385498047 | Validation Loss: 1.1005135774612427\n",
            "Train Loss at iteration 327: 1.0877676010131836 | Validation Loss: 1.0796986818313599\n",
            "Train Loss at iteration 328: 1.077871561050415 | Validation Loss: 1.09005606174469\n",
            "Train Loss at iteration 329: 1.0818017721176147 | Validation Loss: 1.092218279838562\n",
            "Train Loss at iteration 330: 1.0939732789993286 | Validation Loss: 1.0805130004882812\n",
            "Train Loss at iteration 331: 1.0786479711532593 | Validation Loss: 1.0824098587036133\n",
            "Train Loss at iteration 332: 1.0946049690246582 | Validation Loss: 1.0885059833526611\n",
            "Train Loss at iteration 333: 1.0847989320755005 | Validation Loss: 1.0799736976623535\n",
            "Train Loss at iteration 334: 1.0782471895217896 | Validation Loss: 1.0849210023880005\n",
            "Train Loss at iteration 335: 1.083901286125183 | Validation Loss: 1.0725775957107544\n",
            "Train Loss at iteration 336: 1.0819956064224243 | Validation Loss: 1.0846138000488281\n",
            "Train Loss at iteration 337: 1.0933544635772705 | Validation Loss: 1.0794894695281982\n",
            "Train Loss at iteration 338: 1.0887786149978638 | Validation Loss: 1.079755187034607\n",
            "Train Loss at iteration 339: 1.080156922340393 | Validation Loss: 1.0806097984313965\n",
            "Train Loss at iteration 340: 1.0774651765823364 | Validation Loss: 1.0904500484466553\n",
            "Train Loss at iteration 341: 1.0902824401855469 | Validation Loss: 1.089174509048462\n",
            "Train Loss at iteration 342: 1.0942403078079224 | Validation Loss: 1.0793774127960205\n",
            "Train Loss at iteration 343: 1.0681544542312622 | Validation Loss: 1.0802299976348877\n",
            "Train Loss at iteration 344: 1.0793875455856323 | Validation Loss: 1.0957597494125366\n",
            "Train Loss at iteration 345: 1.0921403169631958 | Validation Loss: 1.08712637424469\n",
            "Train Loss at iteration 346: 1.0802531242370605 | Validation Loss: 1.081373929977417\n",
            "Train Loss at iteration 347: 1.096579909324646 | Validation Loss: 1.0876435041427612\n",
            "Train Loss at iteration 348: 1.0883418321609497 | Validation Loss: 1.0868264436721802\n",
            "Train Loss at iteration 349: 1.0915627479553223 | Validation Loss: 1.1082868576049805\n",
            "Train Loss at iteration 350: 1.0834324359893799 | Validation Loss: 1.0901613235473633\n",
            "Train Loss at iteration 351: 1.0642120838165283 | Validation Loss: 1.0825222730636597\n",
            "Train Loss at iteration 352: 1.0833081007003784 | Validation Loss: 1.0549052953720093\n",
            "Train Loss at iteration 353: 1.0652132034301758 | Validation Loss: 1.0827703475952148\n",
            "Train Loss at iteration 354: 1.0872297286987305 | Validation Loss: 1.077778935432434\n",
            "Train Loss at iteration 355: 1.0753536224365234 | Validation Loss: 1.0856438875198364\n",
            "Train Loss at iteration 356: 1.0725077390670776 | Validation Loss: 1.0811164379119873\n",
            "Train Loss at iteration 357: 1.0741147994995117 | Validation Loss: 1.08255934715271\n",
            "Train Loss at iteration 358: 1.0746310949325562 | Validation Loss: 1.0800074338912964\n",
            "Train Loss at iteration 359: 1.0911691188812256 | Validation Loss: 1.087681531906128\n",
            "Train Loss at iteration 360: 1.0846585035324097 | Validation Loss: 1.0801424980163574\n",
            "Train Loss at iteration 361: 1.072843074798584 | Validation Loss: 1.0757975578308105\n",
            "Train Loss at iteration 362: 1.0738513469696045 | Validation Loss: 1.0833256244659424\n",
            "Train Loss at iteration 363: 1.0656208992004395 | Validation Loss: 1.0807456970214844\n",
            "Train Loss at iteration 364: 1.0724380016326904 | Validation Loss: 1.068142294883728\n",
            "Train Loss at iteration 365: 1.0599061250686646 | Validation Loss: 1.0645027160644531\n",
            "Train Loss at iteration 366: 1.0589916706085205 | Validation Loss: 1.067644715309143\n",
            "Train Loss at iteration 367: 1.0549925565719604 | Validation Loss: 1.0739357471466064\n",
            "Train Loss at iteration 368: 1.070095181465149 | Validation Loss: 1.0710046291351318\n",
            "Train Loss at iteration 369: 1.0717591047286987 | Validation Loss: 1.0677540302276611\n",
            "Train Loss at iteration 370: 1.0714586973190308 | Validation Loss: 1.085355281829834\n",
            "Train Loss at iteration 371: 1.071592926979065 | Validation Loss: 1.0824472904205322\n",
            "Train Loss at iteration 372: 1.0775442123413086 | Validation Loss: 1.0723533630371094\n",
            "Train Loss at iteration 373: 1.0835881233215332 | Validation Loss: 1.0739740133285522\n",
            "Train Loss at iteration 374: 1.0629926919937134 | Validation Loss: 1.085176706314087\n",
            "Train Loss at iteration 375: 1.084865689277649 | Validation Loss: 1.0699939727783203\n",
            "Train Loss at iteration 376: 1.090808391571045 | Validation Loss: 1.0862441062927246\n",
            "Train Loss at iteration 377: 1.0501964092254639 | Validation Loss: 1.060984492301941\n",
            "Train Loss at iteration 378: 1.0919383764266968 | Validation Loss: 1.0804567337036133\n",
            "Train Loss at iteration 379: 1.0717614889144897 | Validation Loss: 1.085351824760437\n",
            "Train Loss at iteration 380: 1.0852510929107666 | Validation Loss: 1.0684187412261963\n",
            "Train Loss at iteration 381: 1.0725574493408203 | Validation Loss: 1.0939940214157104\n",
            "Train Loss at iteration 382: 1.0643080472946167 | Validation Loss: 1.0783367156982422\n",
            "Train Loss at iteration 383: 1.0815403461456299 | Validation Loss: 1.0770294666290283\n",
            "Train Loss at iteration 384: 1.0947551727294922 | Validation Loss: 1.0646555423736572\n",
            "Train Loss at iteration 385: 1.0531378984451294 | Validation Loss: 1.0689642429351807\n",
            "Train Loss at iteration 386: 1.0735918283462524 | Validation Loss: 1.0495507717132568\n",
            "Train Loss at iteration 387: 1.0514214038848877 | Validation Loss: 1.0488147735595703\n",
            "Train Loss at iteration 388: 1.0701814889907837 | Validation Loss: 1.0623610019683838\n",
            "Train Loss at iteration 389: 1.0553117990493774 | Validation Loss: 1.0529145002365112\n",
            "Train Loss at iteration 390: 1.059208869934082 | Validation Loss: 1.0610811710357666\n",
            "Train Loss at iteration 391: 1.0598818063735962 | Validation Loss: 1.0540823936462402\n",
            "Train Loss at iteration 392: 1.0661289691925049 | Validation Loss: 1.047308087348938\n",
            "Train Loss at iteration 393: 1.0680958032608032 | Validation Loss: 1.0726487636566162\n",
            "Train Loss at iteration 394: 1.065475583076477 | Validation Loss: 1.0782517194747925\n",
            "Train Loss at iteration 395: 1.0654277801513672 | Validation Loss: 1.067186951637268\n",
            "Train Loss at iteration 396: 1.0621956586837769 | Validation Loss: 1.0725421905517578\n",
            "Train Loss at iteration 397: 1.0706812143325806 | Validation Loss: 1.0766799449920654\n",
            "Train Loss at iteration 398: 1.06802237033844 | Validation Loss: 1.0600032806396484\n",
            "Train Loss at iteration 399: 1.0606677532196045 | Validation Loss: 1.0671305656433105\n",
            "Train Loss at iteration 400: 1.0874769687652588 | Validation Loss: 1.0404677391052246\n",
            "Train Loss at iteration 401: 1.0755430459976196 | Validation Loss: 1.0512672662734985\n",
            "Train Loss at iteration 402: 1.0707435607910156 | Validation Loss: 1.0916343927383423\n",
            "Train Loss at iteration 403: 1.0802301168441772 | Validation Loss: 1.0834792852401733\n",
            "Train Loss at iteration 404: 1.0743567943572998 | Validation Loss: 1.057084560394287\n",
            "Train Loss at iteration 405: 1.0580018758773804 | Validation Loss: 1.0868898630142212\n",
            "Train Loss at iteration 406: 1.0722514390945435 | Validation Loss: 1.0777572393417358\n",
            "Train Loss at iteration 407: 1.047170639038086 | Validation Loss: 1.0735301971435547\n",
            "Train Loss at iteration 408: 1.0631036758422852 | Validation Loss: 1.0583921670913696\n",
            "Train Loss at iteration 409: 1.0598076581954956 | Validation Loss: 1.0540752410888672\n",
            "Train Loss at iteration 410: 1.0766242742538452 | Validation Loss: 1.0733492374420166\n",
            "Train Loss at iteration 411: 1.0778666734695435 | Validation Loss: 1.047402262687683\n",
            "Train Loss at iteration 412: 1.0712031126022339 | Validation Loss: 1.0423457622528076\n",
            "Train Loss at iteration 413: 1.0644440650939941 | Validation Loss: 1.059411644935608\n",
            "Train Loss at iteration 414: 1.0648587942123413 | Validation Loss: 1.037911057472229\n",
            "Train Loss at iteration 415: 1.0682328939437866 | Validation Loss: 1.0497798919677734\n",
            "Train Loss at iteration 416: 1.0641082525253296 | Validation Loss: 1.0711759328842163\n",
            "Train Loss at iteration 417: 1.0503969192504883 | Validation Loss: 1.0603560209274292\n",
            "Train Loss at iteration 418: 1.0560094118118286 | Validation Loss: 1.0834107398986816\n",
            "Train Loss at iteration 419: 1.0290447473526 | Validation Loss: 1.0526424646377563\n",
            "Train Loss at iteration 420: 1.0645015239715576 | Validation Loss: 1.0717203617095947\n",
            "Train Loss at iteration 421: 1.0563583374023438 | Validation Loss: 1.058224081993103\n",
            "Train Loss at iteration 422: 1.0882965326309204 | Validation Loss: 1.0569957494735718\n",
            "Train Loss at iteration 423: 1.0585527420043945 | Validation Loss: 1.0271652936935425\n",
            "Train Loss at iteration 424: 1.0735509395599365 | Validation Loss: 1.0409977436065674\n",
            "Train Loss at iteration 425: 1.0655629634857178 | Validation Loss: 1.0572619438171387\n",
            "Train Loss at iteration 426: 1.0601929426193237 | Validation Loss: 1.0903056859970093\n",
            "Train Loss at iteration 427: 1.082419514656067 | Validation Loss: 1.0670268535614014\n",
            "Train Loss at iteration 428: 1.0747172832489014 | Validation Loss: 1.0544776916503906\n",
            "Train Loss at iteration 429: 1.069878101348877 | Validation Loss: 1.063431978225708\n",
            "Train Loss at iteration 430: 1.075985312461853 | Validation Loss: 1.0752133131027222\n",
            "Train Loss at iteration 431: 1.0450764894485474 | Validation Loss: 1.052780270576477\n",
            "Train Loss at iteration 432: 1.0771727561950684 | Validation Loss: 1.0801979303359985\n",
            "Train Loss at iteration 433: 1.0521650314331055 | Validation Loss: 1.0603574514389038\n",
            "Train Loss at iteration 434: 1.0590273141860962 | Validation Loss: 1.0401989221572876\n",
            "Train Loss at iteration 435: 1.0566918849945068 | Validation Loss: 1.0406324863433838\n",
            "Train Loss at iteration 436: 1.0522454977035522 | Validation Loss: 1.0344599485397339\n",
            "Train Loss at iteration 437: 1.0401479005813599 | Validation Loss: 1.0476033687591553\n",
            "Train Loss at iteration 438: 1.0634227991104126 | Validation Loss: 1.0572694540023804\n",
            "Train Loss at iteration 439: 1.0561660528182983 | Validation Loss: 1.0702650547027588\n",
            "Train Loss at iteration 440: 1.037693738937378 | Validation Loss: 1.0512332916259766\n",
            "Train Loss at iteration 441: 1.0696123838424683 | Validation Loss: 1.0666643381118774\n",
            "Train Loss at iteration 442: 1.049394965171814 | Validation Loss: 1.0499870777130127\n",
            "Train Loss at iteration 443: 1.0614632368087769 | Validation Loss: 1.040360927581787\n",
            "Train Loss at iteration 444: 1.0479252338409424 | Validation Loss: 1.0448753833770752\n",
            "Train Loss at iteration 445: 1.0183042287826538 | Validation Loss: 1.0633116960525513\n",
            "Train Loss at iteration 446: 1.0647255182266235 | Validation Loss: 1.0526480674743652\n",
            "Train Loss at iteration 447: 1.0480040311813354 | Validation Loss: 1.0432153940200806\n",
            "Train Loss at iteration 448: 1.0803651809692383 | Validation Loss: 1.022803783416748\n",
            "Train Loss at iteration 449: 1.068077564239502 | Validation Loss: 1.0349342823028564\n",
            "Train Loss at iteration 450: 1.032901406288147 | Validation Loss: 1.0621798038482666\n",
            "Train Loss at iteration 451: 1.0783952474594116 | Validation Loss: 1.0503562688827515\n",
            "Train Loss at iteration 452: 1.0418540239334106 | Validation Loss: 1.0410219430923462\n",
            "Train Loss at iteration 453: 1.0418622493743896 | Validation Loss: 1.0615357160568237\n",
            "Train Loss at iteration 454: 1.0433429479599 | Validation Loss: 1.0468209981918335\n",
            "Train Loss at iteration 455: 1.0587912797927856 | Validation Loss: 1.0339703559875488\n",
            "Train Loss at iteration 456: 1.0482544898986816 | Validation Loss: 1.1011698246002197\n",
            "Train Loss at iteration 457: 1.0634406805038452 | Validation Loss: 1.0423544645309448\n",
            "Train Loss at iteration 458: 1.0511677265167236 | Validation Loss: 1.0632741451263428\n",
            "Train Loss at iteration 459: 1.0645018815994263 | Validation Loss: 1.034022331237793\n",
            "Train Loss at iteration 460: 1.050372838973999 | Validation Loss: 1.0631219148635864\n",
            "Train Loss at iteration 461: 1.0478650331497192 | Validation Loss: 1.0271834135055542\n",
            "Train Loss at iteration 462: 1.0407789945602417 | Validation Loss: 1.0222156047821045\n",
            "Train Loss at iteration 463: 1.043187141418457 | Validation Loss: 1.0645259618759155\n",
            "Train Loss at iteration 464: 1.024512529373169 | Validation Loss: 1.0212684869766235\n",
            "Train Loss at iteration 465: 1.0531933307647705 | Validation Loss: 1.0321688652038574\n",
            "Train Loss at iteration 466: 1.0281797647476196 | Validation Loss: 1.0442745685577393\n",
            "Train Loss at iteration 467: 1.0846151113510132 | Validation Loss: 1.0677155256271362\n",
            "Train Loss at iteration 468: 1.0729657411575317 | Validation Loss: 1.0252338647842407\n",
            "Train Loss at iteration 469: 1.0338228940963745 | Validation Loss: 1.0614326000213623\n",
            "Train Loss at iteration 470: 1.0523757934570312 | Validation Loss: 1.0300369262695312\n",
            "Train Loss at iteration 471: 1.0470236539840698 | Validation Loss: 1.0480443239212036\n",
            "Train Loss at iteration 472: 1.0455819368362427 | Validation Loss: 1.0370237827301025\n",
            "Train Loss at iteration 473: 1.0451349020004272 | Validation Loss: 1.0745164155960083\n",
            "Train Loss at iteration 474: 1.008779525756836 | Validation Loss: 1.0510989427566528\n",
            "Train Loss at iteration 475: 1.0598914623260498 | Validation Loss: 1.022748351097107\n",
            "Train Loss at iteration 476: 1.062264323234558 | Validation Loss: 1.068232774734497\n",
            "Train Loss at iteration 477: 1.0343209505081177 | Validation Loss: 1.037528395652771\n",
            "Train Loss at iteration 478: 1.0571770668029785 | Validation Loss: 1.0552300214767456\n",
            "Train Loss at iteration 479: 1.0414303541183472 | Validation Loss: 1.050566554069519\n",
            "Train Loss at iteration 480: 1.053356409072876 | Validation Loss: 1.0331511497497559\n",
            "Train Loss at iteration 481: 1.0728493928909302 | Validation Loss: 1.0344313383102417\n",
            "Train Loss at iteration 482: 1.072237491607666 | Validation Loss: 1.0602632761001587\n",
            "Train Loss at iteration 483: 1.0660079717636108 | Validation Loss: 1.0641732215881348\n",
            "Train Loss at iteration 484: 1.0461000204086304 | Validation Loss: 1.029440999031067\n",
            "Train Loss at iteration 485: 1.063949704170227 | Validation Loss: 1.0455306768417358\n",
            "Train Loss at iteration 486: 1.067104697227478 | Validation Loss: 1.0504287481307983\n",
            "Train Loss at iteration 487: 1.022940754890442 | Validation Loss: 1.0751432180404663\n",
            "Train Loss at iteration 488: 1.046339750289917 | Validation Loss: 1.0226043462753296\n",
            "Train Loss at iteration 489: 1.0531072616577148 | Validation Loss: 1.0574853420257568\n",
            "Train Loss at iteration 490: 1.0718748569488525 | Validation Loss: 1.0494987964630127\n",
            "Train Loss at iteration 491: 1.034425973892212 | Validation Loss: 1.0788723230361938\n",
            "Train Loss at iteration 492: 1.0600999593734741 | Validation Loss: 1.0628982782363892\n",
            "Train Loss at iteration 493: 1.005496621131897 | Validation Loss: 1.0386680364608765\n",
            "Train Loss at iteration 494: 1.0439624786376953 | Validation Loss: 1.0150678157806396\n",
            "Train Loss at iteration 495: 1.0304441452026367 | Validation Loss: 1.0238133668899536\n",
            "Train Loss at iteration 496: 1.0573680400848389 | Validation Loss: 1.0152842998504639\n",
            "Train Loss at iteration 497: 1.0633068084716797 | Validation Loss: 1.0405104160308838\n",
            "Train Loss at iteration 498: 1.0624966621398926 | Validation Loss: 1.0590083599090576\n",
            "Train Loss at iteration 499: 1.067147135734558 | Validation Loss: 1.0205297470092773\n",
            "Train Loss at iteration 500: 1.0782763957977295 | Validation Loss: 1.0567567348480225\n",
            "Train Loss at iteration 501: 1.022489309310913 | Validation Loss: 1.0359525680541992\n",
            "Train Loss at iteration 502: 1.063918113708496 | Validation Loss: 1.068725824356079\n",
            "Train Loss at iteration 503: 1.0405646562576294 | Validation Loss: 1.057426929473877\n",
            "Train Loss at iteration 504: 1.0316317081451416 | Validation Loss: 1.0307176113128662\n",
            "Train Loss at iteration 505: 1.0171698331832886 | Validation Loss: 1.0269755125045776\n",
            "Train Loss at iteration 506: 1.037567377090454 | Validation Loss: 1.0423717498779297\n",
            "Train Loss at iteration 507: 1.0507010221481323 | Validation Loss: 1.0677731037139893\n",
            "Train Loss at iteration 508: 1.047313928604126 | Validation Loss: 1.0161094665527344\n",
            "Train Loss at iteration 509: 1.0744842290878296 | Validation Loss: 1.0238996744155884\n",
            "Train Loss at iteration 510: 1.0386492013931274 | Validation Loss: 1.0355573892593384\n",
            "Train Loss at iteration 511: 1.0364660024642944 | Validation Loss: 1.032242774963379\n",
            "Train Loss at iteration 512: 1.0842523574829102 | Validation Loss: 1.0560884475708008\n",
            "Train Loss at iteration 513: 1.0546185970306396 | Validation Loss: 1.0396188497543335\n",
            "Train Loss at iteration 514: 1.0450688600540161 | Validation Loss: 1.045662522315979\n",
            "Train Loss at iteration 515: 1.0201116800308228 | Validation Loss: 1.0505295991897583\n",
            "Train Loss at iteration 516: 1.0505986213684082 | Validation Loss: 1.0407758951187134\n",
            "Train Loss at iteration 517: 1.0420911312103271 | Validation Loss: 1.0649582147598267\n",
            "Train Loss at iteration 518: 1.069826602935791 | Validation Loss: 1.0555089712142944\n",
            "Train Loss at iteration 519: 1.0539906024932861 | Validation Loss: 1.0343798398971558\n",
            "Train Loss at iteration 520: 1.023350477218628 | Validation Loss: 1.0461220741271973\n",
            "Train Loss at iteration 521: 1.0505486726760864 | Validation Loss: 1.0477722883224487\n",
            "Train Loss at iteration 522: 1.0466680526733398 | Validation Loss: 1.0818198919296265\n",
            "Train Loss at iteration 523: 1.0440460443496704 | Validation Loss: 1.0588157176971436\n",
            "Train Loss at iteration 524: 1.0450115203857422 | Validation Loss: 1.0390292406082153\n",
            "Train Loss at iteration 525: 1.0344244241714478 | Validation Loss: 1.0633659362792969\n",
            "Train Loss at iteration 526: 1.0594375133514404 | Validation Loss: 1.0598264932632446\n",
            "Train Loss at iteration 527: 1.063161015510559 | Validation Loss: 1.0510004758834839\n",
            "Train Loss at iteration 528: 1.064312219619751 | Validation Loss: 1.0434367656707764\n",
            "Train Loss at iteration 529: 1.0303831100463867 | Validation Loss: 1.0365389585494995\n",
            "Train Loss at iteration 530: 1.0624346733093262 | Validation Loss: 1.0639089345932007\n",
            "Train Loss at iteration 531: 1.0480812788009644 | Validation Loss: 1.0291789770126343\n",
            "Train Loss at iteration 532: 1.033000111579895 | Validation Loss: 1.0337871313095093\n",
            "Train Loss at iteration 533: 1.0738916397094727 | Validation Loss: 1.0345009565353394\n",
            "Train Loss at iteration 534: 1.0225095748901367 | Validation Loss: 1.0074865818023682\n",
            "Train Loss at iteration 535: 1.0721371173858643 | Validation Loss: 1.1046416759490967\n",
            "Train Loss at iteration 536: 1.0482115745544434 | Validation Loss: 1.0379579067230225\n",
            "Train Loss at iteration 537: 1.0399984121322632 | Validation Loss: 1.04348623752594\n",
            "Train Loss at iteration 538: 1.027075171470642 | Validation Loss: 1.0488077402114868\n",
            "Train Loss at iteration 539: 1.0504260063171387 | Validation Loss: 1.033399224281311\n",
            "Train Loss at iteration 540: 1.0490888357162476 | Validation Loss: 1.0520563125610352\n",
            "Train Loss at iteration 541: 1.0332634449005127 | Validation Loss: 1.055241346359253\n",
            "Train Loss at iteration 542: 1.0385257005691528 | Validation Loss: 1.0378795862197876\n",
            "Train Loss at iteration 543: 1.0254825353622437 | Validation Loss: 1.0137065649032593\n",
            "Train Loss at iteration 544: 1.038730263710022 | Validation Loss: 1.0635708570480347\n",
            "Train Loss at iteration 545: 1.0710020065307617 | Validation Loss: 1.0411912202835083\n",
            "Train Loss at iteration 546: 1.0300761461257935 | Validation Loss: 1.0376211404800415\n",
            "Train Loss at iteration 547: 1.060886025428772 | Validation Loss: 1.0526399612426758\n",
            "Train Loss at iteration 548: 1.0602478981018066 | Validation Loss: 1.0267789363861084\n",
            "Train Loss at iteration 549: 1.0811407566070557 | Validation Loss: 1.0691794157028198\n",
            "Train Loss at iteration 550: 1.0223721265792847 | Validation Loss: 1.0480602979660034\n",
            "Train Loss at iteration 551: 1.0497385263442993 | Validation Loss: 1.0251802206039429\n",
            "Train Loss at iteration 552: 1.0566264390945435 | Validation Loss: 1.0493841171264648\n",
            "Train Loss at iteration 553: 1.0200473070144653 | Validation Loss: 1.0546746253967285\n",
            "Train Loss at iteration 554: 1.025313377380371 | Validation Loss: 1.0758693218231201\n",
            "Train Loss at iteration 555: 1.0359129905700684 | Validation Loss: 1.0258220434188843\n",
            "Train Loss at iteration 556: 1.0311610698699951 | Validation Loss: 1.0451864004135132\n",
            "Train Loss at iteration 557: 1.0577868223190308 | Validation Loss: 1.0417431592941284\n",
            "Train Loss at iteration 558: 1.0638195276260376 | Validation Loss: 1.0617327690124512\n",
            "Train Loss at iteration 559: 1.0123037099838257 | Validation Loss: 1.062870740890503\n",
            "Train Loss at iteration 560: 1.0149693489074707 | Validation Loss: 1.0312455892562866\n",
            "Train Loss at iteration 561: 1.0354621410369873 | Validation Loss: 1.009312629699707\n",
            "Train Loss at iteration 562: 1.0606396198272705 | Validation Loss: 1.0547816753387451\n",
            "Train Loss at iteration 563: 1.075190544128418 | Validation Loss: 1.0554801225662231\n",
            "Train Loss at iteration 564: 1.079027771949768 | Validation Loss: 1.0471317768096924\n",
            "Train Loss at iteration 565: 1.0074654817581177 | Validation Loss: 1.0304737091064453\n",
            "Train Loss at iteration 566: 1.046188235282898 | Validation Loss: 1.0525431632995605\n",
            "Train Loss at iteration 567: 1.0507001876831055 | Validation Loss: 1.014062762260437\n",
            "Train Loss at iteration 568: 1.0528216361999512 | Validation Loss: 1.0435038805007935\n",
            "Train Loss at iteration 569: 1.0436328649520874 | Validation Loss: 1.0729243755340576\n",
            "Train Loss at iteration 570: 1.0353269577026367 | Validation Loss: 1.0375895500183105\n",
            "Train Loss at iteration 571: 1.027955412864685 | Validation Loss: 1.0369658470153809\n",
            "Train Loss at iteration 572: 1.011480689048767 | Validation Loss: 1.0609699487686157\n",
            "Train Loss at iteration 573: 1.058179259300232 | Validation Loss: 1.0108121633529663\n",
            "Train Loss at iteration 574: 1.0311657190322876 | Validation Loss: 1.0483732223510742\n",
            "Train Loss at iteration 575: 1.0551916360855103 | Validation Loss: 1.0180716514587402\n",
            "Train Loss at iteration 576: 1.032179832458496 | Validation Loss: 1.0322140455245972\n",
            "Train Loss at iteration 577: 1.0461947917938232 | Validation Loss: 1.0307399034500122\n",
            "Train Loss at iteration 578: 1.028975248336792 | Validation Loss: 1.0265928506851196\n",
            "Train Loss at iteration 579: 1.0231733322143555 | Validation Loss: 1.0522626638412476\n",
            "Train Loss at iteration 580: 1.053644061088562 | Validation Loss: 1.0373659133911133\n",
            "Train Loss at iteration 581: 1.0484007596969604 | Validation Loss: 1.038922905921936\n",
            "Train Loss at iteration 582: 1.0438302755355835 | Validation Loss: 1.0623573064804077\n",
            "Train Loss at iteration 583: 1.040093183517456 | Validation Loss: 1.057759165763855\n",
            "Train Loss at iteration 584: 1.0398600101470947 | Validation Loss: 1.0257561206817627\n",
            "Train Loss at iteration 585: 1.0431230068206787 | Validation Loss: 1.090559482574463\n",
            "Train Loss at iteration 586: 1.0618247985839844 | Validation Loss: 1.0860732793807983\n",
            "Train Loss at iteration 587: 1.0552235841751099 | Validation Loss: 1.0373646020889282\n",
            "Train Loss at iteration 588: 1.0223937034606934 | Validation Loss: 1.0390384197235107\n",
            "Train Loss at iteration 589: 1.0717228651046753 | Validation Loss: 1.0277096033096313\n",
            "Train Loss at iteration 590: 1.0540553331375122 | Validation Loss: 1.0550658702850342\n",
            "Train Loss at iteration 591: 1.0358200073242188 | Validation Loss: 1.0498802661895752\n",
            "Train Loss at iteration 592: 1.0212401151657104 | Validation Loss: 1.054214596748352\n",
            "Train Loss at iteration 593: 1.0106600522994995 | Validation Loss: 1.0368152856826782\n",
            "Train Loss at iteration 594: 1.0705273151397705 | Validation Loss: 1.0325498580932617\n",
            "Train Loss at iteration 595: 1.07416832447052 | Validation Loss: 1.0546003580093384\n",
            "Train Loss at iteration 596: 1.056185245513916 | Validation Loss: 1.0368998050689697\n",
            "Train Loss at iteration 597: 1.0616483688354492 | Validation Loss: 1.0402195453643799\n",
            "Train Loss at iteration 598: 1.0593219995498657 | Validation Loss: 1.0165408849716187\n",
            "Train Loss at iteration 599: 1.0747997760772705 | Validation Loss: 1.0416762828826904\n",
            "Train Loss at iteration 600: 1.032542109489441 | Validation Loss: 1.0004085302352905\n",
            "Train Loss at iteration 601: 1.0572491884231567 | Validation Loss: 1.039198398590088\n",
            "Train Loss at iteration 602: 1.004410743713379 | Validation Loss: 0.9986565113067627\n",
            "Train Loss at iteration 603: 1.068764090538025 | Validation Loss: 1.0141608715057373\n",
            "Train Loss at iteration 604: 1.0714502334594727 | Validation Loss: 1.041164755821228\n",
            "Train Loss at iteration 605: 1.0378718376159668 | Validation Loss: 1.022305965423584\n",
            "Train Loss at iteration 606: 1.027511477470398 | Validation Loss: 1.0414284467697144\n",
            "Train Loss at iteration 607: 1.032727837562561 | Validation Loss: 1.0164217948913574\n",
            "Train Loss at iteration 608: 1.058538794517517 | Validation Loss: 1.00778329372406\n",
            "Train Loss at iteration 609: 1.0461302995681763 | Validation Loss: 1.0439997911453247\n",
            "Train Loss at iteration 610: 1.0291920900344849 | Validation Loss: 1.0354241132736206\n",
            "Train Loss at iteration 611: 1.01786470413208 | Validation Loss: 1.009507179260254\n",
            "Train Loss at iteration 612: 1.0312824249267578 | Validation Loss: 1.016722321510315\n",
            "Train Loss at iteration 613: 1.064609169960022 | Validation Loss: 1.0607355833053589\n",
            "Train Loss at iteration 614: 1.0658191442489624 | Validation Loss: 1.032297134399414\n",
            "Train Loss at iteration 615: 1.0220344066619873 | Validation Loss: 1.014419674873352\n",
            "Train Loss at iteration 616: 1.038265585899353 | Validation Loss: 1.0773937702178955\n",
            "Train Loss at iteration 617: 1.0411853790283203 | Validation Loss: 1.0680838823318481\n",
            "Train Loss at iteration 618: 1.0253502130508423 | Validation Loss: 1.0331770181655884\n",
            "Train Loss at iteration 619: 1.0317543745040894 | Validation Loss: 1.040597677230835\n",
            "Train Loss at iteration 620: 1.050418734550476 | Validation Loss: 0.9996246099472046\n",
            "Train Loss at iteration 621: 1.0344486236572266 | Validation Loss: 1.0668776035308838\n",
            "Train Loss at iteration 622: 1.0122230052947998 | Validation Loss: 1.0330740213394165\n",
            "Train Loss at iteration 623: 1.0296661853790283 | Validation Loss: 1.031232237815857\n",
            "Train Loss at iteration 624: 1.0191816091537476 | Validation Loss: 1.0499207973480225\n",
            "Train Loss at iteration 625: 1.060330867767334 | Validation Loss: 1.0318876504898071\n",
            "Train Loss at iteration 626: 1.018757939338684 | Validation Loss: 1.0401941537857056\n",
            "Train Loss at iteration 627: 1.0403056144714355 | Validation Loss: 1.0225850343704224\n",
            "Train Loss at iteration 628: 1.0242880582809448 | Validation Loss: 0.993981659412384\n",
            "Train Loss at iteration 629: 1.0482114553451538 | Validation Loss: 1.0484384298324585\n",
            "Train Loss at iteration 630: 1.0418930053710938 | Validation Loss: 1.0327258110046387\n",
            "Train Loss at iteration 631: 1.0433284044265747 | Validation Loss: 1.0264215469360352\n",
            "Train Loss at iteration 632: 0.9979968667030334 | Validation Loss: 1.0335670709609985\n",
            "Train Loss at iteration 633: 1.0480155944824219 | Validation Loss: 1.0370234251022339\n",
            "Train Loss at iteration 634: 1.0423775911331177 | Validation Loss: 1.0202672481536865\n",
            "Train Loss at iteration 635: 1.036177158355713 | Validation Loss: 1.028562068939209\n",
            "Train Loss at iteration 636: 1.0254331827163696 | Validation Loss: 1.050180196762085\n",
            "Train Loss at iteration 637: 1.0378013849258423 | Validation Loss: 1.018457293510437\n",
            "Train Loss at iteration 638: 1.0374345779418945 | Validation Loss: 1.0382812023162842\n",
            "Train Loss at iteration 639: 0.9933309555053711 | Validation Loss: 1.047944188117981\n",
            "Train Loss at iteration 640: 1.0316708087921143 | Validation Loss: 1.010878562927246\n",
            "Train Loss at iteration 641: 0.9938153028488159 | Validation Loss: 1.0663175582885742\n",
            "Train Loss at iteration 642: 1.0526686906814575 | Validation Loss: 1.0364677906036377\n",
            "Train Loss at iteration 643: 1.0210661888122559 | Validation Loss: 1.0661512613296509\n",
            "Train Loss at iteration 644: 1.0323498249053955 | Validation Loss: 1.0467393398284912\n",
            "Train Loss at iteration 645: 1.0561504364013672 | Validation Loss: 1.0578662157058716\n",
            "Train Loss at iteration 646: 1.0521050691604614 | Validation Loss: 1.0059479475021362\n",
            "Train Loss at iteration 647: 1.0426877737045288 | Validation Loss: 1.0014344453811646\n",
            "Train Loss at iteration 648: 1.0134000778198242 | Validation Loss: 1.0521721839904785\n",
            "Train Loss at iteration 649: 1.0627249479293823 | Validation Loss: 1.042507529258728\n",
            "Train Loss at iteration 650: 1.0142797231674194 | Validation Loss: 1.052210807800293\n",
            "Train Loss at iteration 651: 1.0096311569213867 | Validation Loss: 1.0397834777832031\n",
            "Train Loss at iteration 652: 1.0231941938400269 | Validation Loss: 1.0285420417785645\n",
            "Train Loss at iteration 653: 1.0519033670425415 | Validation Loss: 1.0503414869308472\n",
            "Train Loss at iteration 654: 1.0295352935791016 | Validation Loss: 1.0615280866622925\n",
            "Train Loss at iteration 655: 1.0623735189437866 | Validation Loss: 1.0391566753387451\n",
            "Train Loss at iteration 656: 1.0377087593078613 | Validation Loss: 1.0198724269866943\n",
            "Train Loss at iteration 657: 1.0223817825317383 | Validation Loss: 1.0474071502685547\n",
            "Train Loss at iteration 658: 1.0226715803146362 | Validation Loss: 1.0393905639648438\n",
            "Train Loss at iteration 659: 1.0496273040771484 | Validation Loss: 1.010719656944275\n",
            "Train Loss at iteration 660: 1.0501623153686523 | Validation Loss: 1.0375937223434448\n",
            "Train Loss at iteration 661: 1.0544227361679077 | Validation Loss: 1.0279585123062134\n",
            "Train Loss at iteration 662: 1.0095713138580322 | Validation Loss: 1.0456417798995972\n",
            "Train Loss at iteration 663: 1.0216342210769653 | Validation Loss: 1.0404525995254517\n",
            "Train Loss at iteration 664: 1.0478415489196777 | Validation Loss: 1.0560365915298462\n",
            "Train Loss at iteration 665: 1.0421054363250732 | Validation Loss: 1.0417793989181519\n",
            "Train Loss at iteration 666: 1.043438196182251 | Validation Loss: 1.0368572473526\n",
            "Train Loss at iteration 667: 1.0385234355926514 | Validation Loss: 1.054377555847168\n",
            "Train Loss at iteration 668: 1.0410722494125366 | Validation Loss: 1.0423355102539062\n",
            "Train Loss at iteration 669: 1.0159209966659546 | Validation Loss: 1.033875584602356\n",
            "Train Loss at iteration 670: 0.9957337379455566 | Validation Loss: 1.0734163522720337\n",
            "Train Loss at iteration 671: 1.0420457124710083 | Validation Loss: 1.0119296312332153\n",
            "Train Loss at iteration 672: 1.0609471797943115 | Validation Loss: 1.0228720903396606\n",
            "Train Loss at iteration 673: 1.040384292602539 | Validation Loss: 1.058311104774475\n",
            "Train Loss at iteration 674: 0.9986914992332458 | Validation Loss: 1.053749680519104\n",
            "Train Loss at iteration 675: 1.0387721061706543 | Validation Loss: 1.0312321186065674\n",
            "Train Loss at iteration 676: 1.0425522327423096 | Validation Loss: 1.0377451181411743\n",
            "Train Loss at iteration 677: 1.043108344078064 | Validation Loss: 1.024893045425415\n",
            "Train Loss at iteration 678: 1.0360851287841797 | Validation Loss: 1.0445420742034912\n",
            "Train Loss at iteration 679: 1.035187005996704 | Validation Loss: 1.0279536247253418\n",
            "Train Loss at iteration 680: 1.0606261491775513 | Validation Loss: 1.0454181432724\n",
            "Train Loss at iteration 681: 1.0286002159118652 | Validation Loss: 1.0118536949157715\n",
            "Train Loss at iteration 682: 1.0313814878463745 | Validation Loss: 1.061820387840271\n",
            "Train Loss at iteration 683: 1.062228798866272 | Validation Loss: 1.0247701406478882\n",
            "Train Loss at iteration 684: 1.0425173044204712 | Validation Loss: 1.0360296964645386\n",
            "Train Loss at iteration 685: 1.0702577829360962 | Validation Loss: 1.0413053035736084\n",
            "Train Loss at iteration 686: 1.0450117588043213 | Validation Loss: 1.0656856298446655\n",
            "Train Loss at iteration 687: 1.0534873008728027 | Validation Loss: 1.0520051717758179\n",
            "Train Loss at iteration 688: 1.0336776971817017 | Validation Loss: 1.0600391626358032\n",
            "Train Loss at iteration 689: 1.0418518781661987 | Validation Loss: 1.0189433097839355\n",
            "Train Loss at iteration 690: 1.016805648803711 | Validation Loss: 1.0422515869140625\n",
            "Train Loss at iteration 691: 1.0665897130966187 | Validation Loss: 1.0517933368682861\n",
            "Train Loss at iteration 692: 1.0382460355758667 | Validation Loss: 1.0318946838378906\n",
            "Train Loss at iteration 693: 1.0153608322143555 | Validation Loss: 1.0221599340438843\n",
            "Train Loss at iteration 694: 1.025207757949829 | Validation Loss: 1.0792529582977295\n",
            "Train Loss at iteration 695: 1.026456356048584 | Validation Loss: 1.014662265777588\n",
            "Train Loss at iteration 696: 1.0393164157867432 | Validation Loss: 1.043830394744873\n",
            "Train Loss at iteration 697: 1.0345494747161865 | Validation Loss: 1.0190551280975342\n",
            "Train Loss at iteration 698: 1.0341039896011353 | Validation Loss: 1.054152011871338\n",
            "Train Loss at iteration 699: 1.039047360420227 | Validation Loss: 1.0034914016723633\n",
            "Train Loss at iteration 700: 1.0453227758407593 | Validation Loss: 1.042972207069397\n",
            "Train Loss at iteration 701: 1.0787237882614136 | Validation Loss: 1.0316932201385498\n",
            "Train Loss at iteration 702: 1.0093564987182617 | Validation Loss: 1.0511155128479004\n",
            "Train Loss at iteration 703: 1.063415765762329 | Validation Loss: 1.0426548719406128\n",
            "Train Loss at iteration 704: 1.0219391584396362 | Validation Loss: 1.0194909572601318\n",
            "Train Loss at iteration 705: 1.0256564617156982 | Validation Loss: 1.0316119194030762\n",
            "Train Loss at iteration 706: 1.0532257556915283 | Validation Loss: 1.0313557386398315\n",
            "Train Loss at iteration 707: 1.0313425064086914 | Validation Loss: 1.01240074634552\n",
            "Train Loss at iteration 708: 1.0153489112854004 | Validation Loss: 1.0419566631317139\n",
            "Train Loss at iteration 709: 1.0087946653366089 | Validation Loss: 1.0364134311676025\n",
            "Train Loss at iteration 710: 1.009192943572998 | Validation Loss: 1.0459421873092651\n",
            "Train Loss at iteration 711: 1.0279581546783447 | Validation Loss: 1.0351901054382324\n",
            "Train Loss at iteration 712: 1.0126765966415405 | Validation Loss: 1.0663748979568481\n",
            "Train Loss at iteration 713: 0.9967691898345947 | Validation Loss: 1.0353987216949463\n",
            "Train Loss at iteration 714: 1.0011351108551025 | Validation Loss: 1.027895212173462\n",
            "Train Loss at iteration 715: 1.01945161819458 | Validation Loss: 1.0121369361877441\n",
            "Train Loss at iteration 716: 1.0179972648620605 | Validation Loss: 1.060152292251587\n",
            "Train Loss at iteration 717: 1.037658452987671 | Validation Loss: 1.021321177482605\n",
            "Train Loss at iteration 718: 1.0581775903701782 | Validation Loss: 1.087373971939087\n",
            "Train Loss at iteration 719: 1.0278356075286865 | Validation Loss: 1.0369348526000977\n",
            "Train Loss at iteration 720: 1.07404363155365 | Validation Loss: 1.0145971775054932\n",
            "Train Loss at iteration 721: 1.0270122289657593 | Validation Loss: 1.0215342044830322\n",
            "Train Loss at iteration 722: 1.0503736734390259 | Validation Loss: 1.0736162662506104\n",
            "Train Loss at iteration 723: 1.0247011184692383 | Validation Loss: 1.016579031944275\n",
            "Train Loss at iteration 724: 1.0671329498291016 | Validation Loss: 1.0526032447814941\n",
            "Train Loss at iteration 725: 1.0445926189422607 | Validation Loss: 1.0419929027557373\n",
            "Train Loss at iteration 726: 1.0486977100372314 | Validation Loss: 1.0708632469177246\n",
            "Train Loss at iteration 727: 1.023168921470642 | Validation Loss: 1.0700167417526245\n",
            "Train Loss at iteration 728: 1.028093934059143 | Validation Loss: 0.9982576966285706\n",
            "Train Loss at iteration 729: 1.0480018854141235 | Validation Loss: 1.0518810749053955\n",
            "Train Loss at iteration 730: 1.008130431175232 | Validation Loss: 1.055759310722351\n",
            "Train Loss at iteration 731: 1.0720535516738892 | Validation Loss: 1.0079574584960938\n",
            "Train Loss at iteration 732: 1.0601989030838013 | Validation Loss: 1.0196325778961182\n",
            "Train Loss at iteration 733: 1.0646803379058838 | Validation Loss: 1.0521471500396729\n",
            "Train Loss at iteration 734: 1.0018959045410156 | Validation Loss: 1.0304205417633057\n",
            "Train Loss at iteration 735: 1.0559427738189697 | Validation Loss: 1.062846302986145\n",
            "Train Loss at iteration 736: 1.0291112661361694 | Validation Loss: 1.0303866863250732\n",
            "Train Loss at iteration 737: 1.052531361579895 | Validation Loss: 1.047603726387024\n",
            "Train Loss at iteration 738: 1.037003755569458 | Validation Loss: 1.050239086151123\n",
            "Train Loss at iteration 739: 1.0764527320861816 | Validation Loss: 1.0103994607925415\n",
            "Train Loss at iteration 740: 1.0654773712158203 | Validation Loss: 1.0420597791671753\n",
            "Train Loss at iteration 741: 1.0378419160842896 | Validation Loss: 1.0358513593673706\n",
            "Train Loss at iteration 742: 1.037814974784851 | Validation Loss: 1.0459874868392944\n",
            "Train Loss at iteration 743: 1.065024495124817 | Validation Loss: 1.0637422800064087\n",
            "Train Loss at iteration 744: 1.0131628513336182 | Validation Loss: 1.0260121822357178\n",
            "Train Loss at iteration 745: 1.0445917844772339 | Validation Loss: 1.0434141159057617\n",
            "Train Loss at iteration 746: 1.0134341716766357 | Validation Loss: 1.0446970462799072\n",
            "Train Loss at iteration 747: 1.0439680814743042 | Validation Loss: 1.035881519317627\n",
            "Train Loss at iteration 748: 1.0258959531784058 | Validation Loss: 1.063177227973938\n",
            "Train Loss at iteration 749: 1.042253851890564 | Validation Loss: 1.0327974557876587\n",
            "Train Loss at iteration 750: 1.0706089735031128 | Validation Loss: 1.02126944065094\n",
            "Train Loss at iteration 751: 1.0451056957244873 | Validation Loss: 1.0406467914581299\n",
            "Train Loss at iteration 752: 1.052551507949829 | Validation Loss: 1.037448763847351\n",
            "Train Loss at iteration 753: 1.0501686334609985 | Validation Loss: 1.0250778198242188\n",
            "Train Loss at iteration 754: 1.010156273841858 | Validation Loss: 1.0485624074935913\n",
            "Train Loss at iteration 755: 1.0548969507217407 | Validation Loss: 1.0307344198226929\n",
            "Train Loss at iteration 756: 1.0205963850021362 | Validation Loss: 1.0199344158172607\n",
            "Train Loss at iteration 757: 1.0049598217010498 | Validation Loss: 1.0257434844970703\n",
            "Train Loss at iteration 758: 1.0270373821258545 | Validation Loss: 1.0497061014175415\n",
            "Train Loss at iteration 759: 1.030112385749817 | Validation Loss: 1.031725287437439\n",
            "Train Loss at iteration 760: 1.0108870267868042 | Validation Loss: 1.0233359336853027\n",
            "Train Loss at iteration 761: 1.0254720449447632 | Validation Loss: 1.0586291551589966\n",
            "Train Loss at iteration 762: 1.0599815845489502 | Validation Loss: 1.0675177574157715\n",
            "Train Loss at iteration 763: 1.0556023120880127 | Validation Loss: 0.9988738894462585\n",
            "Train Loss at iteration 764: 1.0323439836502075 | Validation Loss: 1.0159786939620972\n",
            "Train Loss at iteration 765: 1.0473406314849854 | Validation Loss: 1.0440500974655151\n",
            "Train Loss at iteration 766: 1.0206243991851807 | Validation Loss: 1.0558009147644043\n",
            "Train Loss at iteration 767: 1.0164282321929932 | Validation Loss: 1.0296865701675415\n",
            "Train Loss at iteration 768: 1.0427500009536743 | Validation Loss: 1.049633502960205\n",
            "Train Loss at iteration 769: 1.0273112058639526 | Validation Loss: 1.0425001382827759\n",
            "Train Loss at iteration 770: 1.0470529794692993 | Validation Loss: 1.0152655839920044\n",
            "Train Loss at iteration 771: 1.0522739887237549 | Validation Loss: 0.9971815347671509\n",
            "Train Loss at iteration 772: 1.0329415798187256 | Validation Loss: 1.0417242050170898\n",
            "Train Loss at iteration 773: 1.0383784770965576 | Validation Loss: 1.0326952934265137\n",
            "Train Loss at iteration 774: 1.0231155157089233 | Validation Loss: 1.0064642429351807\n",
            "Train Loss at iteration 775: 1.0623975992202759 | Validation Loss: 1.024593710899353\n",
            "Train Loss at iteration 776: 1.031516671180725 | Validation Loss: 1.0888237953186035\n",
            "Train Loss at iteration 777: 1.0283575057983398 | Validation Loss: 1.042656660079956\n",
            "Train Loss at iteration 778: 1.0396137237548828 | Validation Loss: 1.062633752822876\n",
            "Train Loss at iteration 779: 1.035129427909851 | Validation Loss: 1.0668679475784302\n",
            "Train Loss at iteration 780: 1.0106666088104248 | Validation Loss: 1.0546114444732666\n",
            "Train Loss at iteration 781: 1.0192445516586304 | Validation Loss: 0.9961084127426147\n",
            "Train Loss at iteration 782: 1.0349550247192383 | Validation Loss: 1.0267977714538574\n",
            "Train Loss at iteration 783: 1.0429635047912598 | Validation Loss: 1.0374584197998047\n",
            "Train Loss at iteration 784: 0.9975185394287109 | Validation Loss: 1.0308574438095093\n",
            "Train Loss at iteration 785: 1.0420160293579102 | Validation Loss: 1.058797836303711\n",
            "Train Loss at iteration 786: 1.0530129671096802 | Validation Loss: 1.0155044794082642\n",
            "Train Loss at iteration 787: 1.0716049671173096 | Validation Loss: 1.029202938079834\n",
            "Train Loss at iteration 788: 1.0659371614456177 | Validation Loss: 1.0143115520477295\n",
            "Train Loss at iteration 789: 1.051524043083191 | Validation Loss: 1.040764570236206\n",
            "Train Loss at iteration 790: 0.9928680658340454 | Validation Loss: 1.0459492206573486\n",
            "Train Loss at iteration 791: 1.0234365463256836 | Validation Loss: 1.069059133529663\n",
            "Train Loss at iteration 792: 1.0217005014419556 | Validation Loss: 1.0421334505081177\n",
            "Train Loss at iteration 793: 1.0350767374038696 | Validation Loss: 1.0475144386291504\n",
            "Train Loss at iteration 794: 1.056392788887024 | Validation Loss: 1.0299330949783325\n",
            "Train Loss at iteration 795: 1.0215270519256592 | Validation Loss: 1.0497055053710938\n",
            "Train Loss at iteration 796: 1.0454009771347046 | Validation Loss: 1.058476448059082\n",
            "Train Loss at iteration 797: 1.066094160079956 | Validation Loss: 1.0215548276901245\n",
            "Train Loss at iteration 798: 1.0143685340881348 | Validation Loss: 1.0178288221359253\n",
            "Train Loss at iteration 799: 1.0673143863677979 | Validation Loss: 1.0385010242462158\n",
            "Train Loss at iteration 800: 1.029188871383667 | Validation Loss: 1.0495729446411133\n",
            "Train Loss at iteration 801: 1.019571304321289 | Validation Loss: 1.0303375720977783\n",
            "Train Loss at iteration 802: 1.0180039405822754 | Validation Loss: 1.0486963987350464\n",
            "Train Loss at iteration 803: 1.0328757762908936 | Validation Loss: 1.0277985334396362\n",
            "Train Loss at iteration 804: 1.0450809001922607 | Validation Loss: 1.0511956214904785\n",
            "Train Loss at iteration 805: 1.0105817317962646 | Validation Loss: 1.0168510675430298\n",
            "Train Loss at iteration 806: 1.0162841081619263 | Validation Loss: 1.0440722703933716\n",
            "Train Loss at iteration 807: 1.0461426973342896 | Validation Loss: 1.0426304340362549\n",
            "Train Loss at iteration 808: 1.0269469022750854 | Validation Loss: 1.0393257141113281\n",
            "Train Loss at iteration 809: 1.0300766229629517 | Validation Loss: 1.0345110893249512\n",
            "Train Loss at iteration 810: 1.053456425666809 | Validation Loss: 1.0552514791488647\n",
            "Train Loss at iteration 811: 1.0462898015975952 | Validation Loss: 1.035364031791687\n",
            "Train Loss at iteration 812: 1.040390133857727 | Validation Loss: 1.0289125442504883\n",
            "Train Loss at iteration 813: 1.0527719259262085 | Validation Loss: 1.013625979423523\n",
            "Train Loss at iteration 814: 1.03070867061615 | Validation Loss: 1.0304853916168213\n",
            "Train Loss at iteration 815: 1.0358346700668335 | Validation Loss: 1.0155335664749146\n",
            "Train Loss at iteration 816: 1.0154563188552856 | Validation Loss: 1.0369668006896973\n",
            "Train Loss at iteration 817: 1.0331634283065796 | Validation Loss: 1.022446870803833\n",
            "Train Loss at iteration 818: 1.0343379974365234 | Validation Loss: 1.0202217102050781\n",
            "Train Loss at iteration 819: 1.006866693496704 | Validation Loss: 1.0245245695114136\n",
            "Train Loss at iteration 820: 0.9931676387786865 | Validation Loss: 1.0312347412109375\n",
            "Train Loss at iteration 821: 1.068647861480713 | Validation Loss: 1.0856379270553589\n",
            "Train Loss at iteration 822: 1.04312002658844 | Validation Loss: 1.0252825021743774\n",
            "Train Loss at iteration 823: 1.0241036415100098 | Validation Loss: 1.0351120233535767\n",
            "Train Loss at iteration 824: 1.0406526327133179 | Validation Loss: 1.041171669960022\n",
            "Train Loss at iteration 825: 1.0435703992843628 | Validation Loss: 1.016008734703064\n",
            "Train Loss at iteration 826: 1.0441415309906006 | Validation Loss: 1.0092312097549438\n",
            "Train Loss at iteration 827: 1.0196187496185303 | Validation Loss: 1.0282288789749146\n",
            "Train Loss at iteration 828: 1.0392650365829468 | Validation Loss: 0.9932929277420044\n",
            "Train Loss at iteration 829: 1.03517484664917 | Validation Loss: 1.0658867359161377\n",
            "Train Loss at iteration 830: 1.027234435081482 | Validation Loss: 1.0087251663208008\n",
            "Train Loss at iteration 831: 1.0142253637313843 | Validation Loss: 0.9965471625328064\n",
            "Train Loss at iteration 832: 1.011286735534668 | Validation Loss: 1.0622057914733887\n",
            "Train Loss at iteration 833: 1.0172728300094604 | Validation Loss: 1.0488879680633545\n",
            "Train Loss at iteration 834: 0.9865102767944336 | Validation Loss: 1.0581696033477783\n",
            "Train Loss at iteration 835: 1.0403648614883423 | Validation Loss: 1.025916576385498\n",
            "Train Loss at iteration 836: 1.0415703058242798 | Validation Loss: 1.030965805053711\n",
            "Train Loss at iteration 837: 1.0659735202789307 | Validation Loss: 1.0193425416946411\n",
            "Train Loss at iteration 838: 1.058082938194275 | Validation Loss: 1.031921148300171\n",
            "Train Loss at iteration 839: 1.001044511795044 | Validation Loss: 1.055525779724121\n",
            "Train Loss at iteration 840: 1.0236382484436035 | Validation Loss: 1.0614782571792603\n",
            "Train Loss at iteration 841: 1.049321174621582 | Validation Loss: 1.0496200323104858\n",
            "Train Loss at iteration 842: 1.0242022275924683 | Validation Loss: 1.0359041690826416\n",
            "Train Loss at iteration 843: 1.0096957683563232 | Validation Loss: 1.0395578145980835\n",
            "Train Loss at iteration 844: 1.0631998777389526 | Validation Loss: 1.0312293767929077\n",
            "Train Loss at iteration 845: 1.0384705066680908 | Validation Loss: 1.0155916213989258\n",
            "Train Loss at iteration 846: 1.0492240190505981 | Validation Loss: 1.0452041625976562\n",
            "Train Loss at iteration 847: 1.046130895614624 | Validation Loss: 0.9992499351501465\n",
            "Train Loss at iteration 848: 1.0282281637191772 | Validation Loss: 0.9891766905784607\n",
            "Train Loss at iteration 849: 1.0359960794448853 | Validation Loss: 1.013405442237854\n",
            "Train Loss at iteration 850: 1.0212650299072266 | Validation Loss: 1.0197702646255493\n",
            "Train Loss at iteration 851: 1.043202519416809 | Validation Loss: 1.0487287044525146\n",
            "Train Loss at iteration 852: 1.0426199436187744 | Validation Loss: 1.0034878253936768\n",
            "Train Loss at iteration 853: 1.044285774230957 | Validation Loss: 1.0523576736450195\n",
            "Train Loss at iteration 854: 1.044270634651184 | Validation Loss: 1.044406533241272\n",
            "Train Loss at iteration 855: 0.9994893074035645 | Validation Loss: 1.031486988067627\n",
            "Train Loss at iteration 856: 1.011255145072937 | Validation Loss: 1.0841807126998901\n",
            "Train Loss at iteration 857: 1.0457640886306763 | Validation Loss: 1.0008867979049683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leh9HyjiMwlO"
      },
      "source": [
        "### Standart LSTM Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXtLy8x3skQP"
      },
      "source": [
        "class LSTM(torch.nn.Module):\n",
        "  def __init__(self,inp,hid,max_len):\n",
        "    super().__init__()\n",
        "    self.inp = inp\n",
        "    self.hid = hid\n",
        "    self.max_len = max_len\n",
        "    self.lstm = nn.LSTM(self.inp,self.hid)\n",
        "    self.fc1 = nn.Linear(self.max_len*4,100)\n",
        "    self.fc2 = nn.Linear(100,3)\n",
        "  def forward(self,premise,hypothesis):\n",
        "    h_premise,c_premise = self.lstm(premise)\n",
        "    h_hypothesis, c_hypothesis = self.lstm(hypothesis)\n",
        "\n",
        "    hp_average = torch.mean(h_premise,2)\n",
        "    hp_max = torch.max(h_premise,2).values\n",
        "\n",
        "    hh_average = torch.mean(h_hypothesis,2)\n",
        "    hh_max = torch.max(h_hypothesis,2).values\n",
        "\n",
        "    v = torch.cat((hp_average,hp_max,hh_average,hh_max),1)\n",
        "\n",
        "    v = self.fc1(v)\n",
        "    v = torch.tanh(v)\n",
        "    v = self.fc2(v)\n",
        "    v = F.softmax(v,dim=1)\n",
        "    return v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXf-XGWTsr_7"
      },
      "source": [
        "epochs = 10\n",
        "lr = 0.0004\n",
        "batch_size = 256\n",
        "hidden = 300\n",
        "max_len = 256\n",
        "input_size = 300\n",
        "\n",
        "model_2 = LSTM(input_size,hidden,max_len)\n",
        "model_2 = model_2.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_2.parameters(), lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_E9XPARSuzK9",
        "outputId": "f578469f-9f03-474d-d060-31540df7e639"
      },
      "source": [
        "summary(model=model_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "LSTM                                     --\n",
              "├─LSTM: 1-1                              722,400\n",
              "├─Linear: 1-2                            102,500\n",
              "├─Linear: 1-3                            303\n",
              "=================================================================\n",
              "Total params: 825,203\n",
              "Trainable params: 825,203\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wcex3YKJtN7E",
        "outputId": "97ea9550-658b-4826-c774-9864c40a94ff"
      },
      "source": [
        "train_loss_2,validation_loss_2 = train(model_2, criterion, optimizer, epochs, train_df,valid_df,embeddings_dict,batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Loss at iteration 1: 1.1003645658493042 | Validation Loss: 1.0977150201797485\n",
            "Train Loss at iteration 2: 1.0992730855941772 | Validation Loss: 1.1090463399887085\n",
            "Train Loss at iteration 3: 1.0999653339385986 | Validation Loss: 1.105333685874939\n",
            "Train Loss at iteration 4: 1.1002124547958374 | Validation Loss: 1.1003557443618774\n",
            "Train Loss at iteration 5: 1.104783296585083 | Validation Loss: 1.0984902381896973\n",
            "Train Loss at iteration 6: 1.0972894430160522 | Validation Loss: 1.101171612739563\n",
            "Train Loss at iteration 7: 1.101003885269165 | Validation Loss: 1.1009111404418945\n",
            "Train Loss at iteration 8: 1.099508285522461 | Validation Loss: 1.0963428020477295\n",
            "Train Loss at iteration 9: 1.099807858467102 | Validation Loss: 1.0997064113616943\n",
            "Train Loss at iteration 10: 1.0992439985275269 | Validation Loss: 1.097491979598999\n",
            "Train Loss at iteration 11: 1.1010271310806274 | Validation Loss: 1.1002843379974365\n",
            "Train Loss at iteration 12: 1.0979918241500854 | Validation Loss: 1.1008261442184448\n",
            "Train Loss at iteration 13: 1.0967590808868408 | Validation Loss: 1.0987850427627563\n",
            "Train Loss at iteration 14: 1.1016861200332642 | Validation Loss: 1.087607741355896\n",
            "Train Loss at iteration 15: 1.1036072969436646 | Validation Loss: 1.1019963026046753\n",
            "Train Loss at iteration 16: 1.1012866497039795 | Validation Loss: 1.099599003791809\n",
            "Train Loss at iteration 17: 1.1016525030136108 | Validation Loss: 1.101549506187439\n",
            "Train Loss at iteration 18: 1.0951120853424072 | Validation Loss: 1.096691370010376\n",
            "Train Loss at iteration 19: 1.0963025093078613 | Validation Loss: 1.0959243774414062\n",
            "Train Loss at iteration 20: 1.1092543601989746 | Validation Loss: 1.0973947048187256\n",
            "Train Loss at iteration 21: 1.104241967201233 | Validation Loss: 1.098809003829956\n",
            "Train Loss at iteration 22: 1.1020692586898804 | Validation Loss: 1.0966547727584839\n",
            "Train Loss at iteration 23: 1.0977033376693726 | Validation Loss: 1.097935438156128\n",
            "Train Loss at iteration 24: 1.0961601734161377 | Validation Loss: 1.1030014753341675\n",
            "Train Loss at iteration 25: 1.0986272096633911 | Validation Loss: 1.1017364263534546\n",
            "Train Loss at iteration 26: 1.099036455154419 | Validation Loss: 1.1052347421646118\n",
            "Train Loss at iteration 27: 1.0976520776748657 | Validation Loss: 1.1073594093322754\n",
            "Train Loss at iteration 28: 1.1025960445404053 | Validation Loss: 1.1044548749923706\n",
            "Train Loss at iteration 29: 1.0994946956634521 | Validation Loss: 1.1003785133361816\n",
            "Train Loss at iteration 30: 1.1065380573272705 | Validation Loss: 1.1007397174835205\n",
            "Train Loss at iteration 31: 1.099095344543457 | Validation Loss: 1.0984619855880737\n",
            "Train Loss at iteration 32: 1.0999727249145508 | Validation Loss: 1.0993624925613403\n",
            "Train Loss at iteration 33: 1.1023660898208618 | Validation Loss: 1.0959409475326538\n",
            "Train Loss at iteration 34: 1.1037960052490234 | Validation Loss: 1.096678376197815\n",
            "Train Loss at iteration 35: 1.1014702320098877 | Validation Loss: 1.0992008447647095\n",
            "Train Loss at iteration 36: 1.1024329662322998 | Validation Loss: 1.097827434539795\n",
            "Train Loss at iteration 37: 1.0971100330352783 | Validation Loss: 1.099331259727478\n",
            "Train Loss at iteration 38: 1.1002155542373657 | Validation Loss: 1.0978057384490967\n",
            "Train Loss at iteration 39: 1.1000909805297852 | Validation Loss: 1.0985299348831177\n",
            "Train Loss at iteration 40: 1.0996248722076416 | Validation Loss: 1.0987626314163208\n",
            "Train Loss at iteration 41: 1.097853183746338 | Validation Loss: 1.097069263458252\n",
            "Train Loss at iteration 42: 1.0973058938980103 | Validation Loss: 1.0983442068099976\n",
            "Train Loss at iteration 43: 1.1014328002929688 | Validation Loss: 1.0975936651229858\n",
            "Train Loss at iteration 44: 1.0986438989639282 | Validation Loss: 1.0969715118408203\n",
            "Train Loss at iteration 45: 1.0996663570404053 | Validation Loss: 1.1005758047103882\n",
            "Train Loss at iteration 46: 1.100063443183899 | Validation Loss: 1.0951216220855713\n",
            "Train Loss at iteration 47: 1.0991199016571045 | Validation Loss: 1.0988048315048218\n",
            "Train Loss at iteration 48: 1.0981112718582153 | Validation Loss: 1.0969581604003906\n",
            "Train Loss at iteration 49: 1.0962496995925903 | Validation Loss: 1.097396731376648\n",
            "Train Loss at iteration 50: 1.1008232831954956 | Validation Loss: 1.0966044664382935\n",
            "Train Loss at iteration 51: 1.1014938354492188 | Validation Loss: 1.095114827156067\n",
            "Train Loss at iteration 52: 1.1020196676254272 | Validation Loss: 1.097062349319458\n",
            "Train Loss at iteration 53: 1.098229169845581 | Validation Loss: 1.0984492301940918\n",
            "Train Loss at iteration 54: 1.0987335443496704 | Validation Loss: 1.099239706993103\n",
            "Train Loss at iteration 55: 1.0988346338272095 | Validation Loss: 1.1000018119812012\n",
            "Train Loss at iteration 56: 1.0976670980453491 | Validation Loss: 1.104359745979309\n",
            "Train Loss at iteration 57: 1.0976797342300415 | Validation Loss: 1.1022316217422485\n",
            "Train Loss at iteration 58: 1.099273443222046 | Validation Loss: 1.1023259162902832\n",
            "Train Loss at iteration 59: 1.1045399904251099 | Validation Loss: 1.0977174043655396\n",
            "Train Loss at iteration 60: 1.1002180576324463 | Validation Loss: 1.104151725769043\n",
            "Train Loss at iteration 61: 1.0975086688995361 | Validation Loss: 1.104044795036316\n",
            "Train Loss at iteration 62: 1.096838355064392 | Validation Loss: 1.103163719177246\n",
            "Train Loss at iteration 63: 1.0945273637771606 | Validation Loss: 1.099647879600525\n",
            "Train Loss at iteration 64: 1.0966852903366089 | Validation Loss: 1.0970189571380615\n",
            "Train Loss at iteration 65: 1.0908452272415161 | Validation Loss: 1.1003998517990112\n",
            "Train Loss at iteration 66: 1.1102795600891113 | Validation Loss: 1.102931022644043\n",
            "Train Loss at iteration 67: 1.09661865234375 | Validation Loss: 1.1011279821395874\n",
            "Train Loss at iteration 68: 1.0950288772583008 | Validation Loss: 1.099347710609436\n",
            "Train Loss at iteration 69: 1.0969980955123901 | Validation Loss: 1.1008590459823608\n",
            "Train Loss at iteration 70: 1.0990835428237915 | Validation Loss: 1.1021898984909058\n",
            "Train Loss at iteration 71: 1.0963903665542603 | Validation Loss: 1.105739951133728\n",
            "Train Loss at iteration 72: 1.10654878616333 | Validation Loss: 1.106042742729187\n",
            "Train Loss at iteration 73: 1.1017626523971558 | Validation Loss: 1.1044299602508545\n",
            "Train Loss at iteration 74: 1.0960232019424438 | Validation Loss: 1.100368857383728\n",
            "Train Loss at iteration 75: 1.1024422645568848 | Validation Loss: 1.099845051765442\n",
            "Train Loss at iteration 76: 1.1032124757766724 | Validation Loss: 1.0987309217453003\n",
            "Train Loss at iteration 77: 1.100480556488037 | Validation Loss: 1.0988569259643555\n",
            "Train Loss at iteration 78: 1.098496437072754 | Validation Loss: 1.098544716835022\n",
            "Train Loss at iteration 79: 1.0986626148223877 | Validation Loss: 1.0980437994003296\n",
            "Train Loss at iteration 80: 1.0992761850357056 | Validation Loss: 1.0959081649780273\n",
            "Train Loss at iteration 81: 1.0966005325317383 | Validation Loss: 1.0959877967834473\n",
            "Train Loss at iteration 82: 1.1004513502120972 | Validation Loss: 1.0980867147445679\n",
            "Train Loss at iteration 83: 1.1003400087356567 | Validation Loss: 1.0981959104537964\n",
            "Train Loss at iteration 84: 1.0979728698730469 | Validation Loss: 1.1000537872314453\n",
            "Train Loss at iteration 85: 1.0971202850341797 | Validation Loss: 1.0985383987426758\n",
            "Train Loss at iteration 86: 1.1044808626174927 | Validation Loss: 1.0979410409927368\n",
            "Train Loss at iteration 87: 1.0987591743469238 | Validation Loss: 1.0987224578857422\n",
            "Train Loss at iteration 88: 1.099290132522583 | Validation Loss: 1.094152569770813\n",
            "Train Loss at iteration 89: 1.1026891469955444 | Validation Loss: 1.0958521366119385\n",
            "Train Loss at iteration 90: 1.1000441312789917 | Validation Loss: 1.1001064777374268\n",
            "Train Loss at iteration 91: 1.099008560180664 | Validation Loss: 1.0986427068710327\n",
            "Train Loss at iteration 92: 1.0988272428512573 | Validation Loss: 1.0979987382888794\n",
            "Train Loss at iteration 93: 1.0983195304870605 | Validation Loss: 1.0984433889389038\n",
            "Train Loss at iteration 94: 1.0983704328536987 | Validation Loss: 1.0992307662963867\n",
            "Train Loss at iteration 95: 1.0991841554641724 | Validation Loss: 1.1002848148345947\n",
            "Train Loss at iteration 96: 1.0989165306091309 | Validation Loss: 1.100091576576233\n",
            "Train Loss at iteration 97: 1.1009732484817505 | Validation Loss: 1.10015869140625\n",
            "Train Loss at iteration 98: 1.098496913909912 | Validation Loss: 1.0989429950714111\n",
            "Train Loss at iteration 99: 1.0976734161376953 | Validation Loss: 1.098205327987671\n",
            "Train Loss at iteration 100: 1.0976841449737549 | Validation Loss: 1.1001075506210327\n",
            "Train Loss at iteration 101: 1.0981611013412476 | Validation Loss: 1.100557565689087\n",
            "Train Loss at iteration 102: 1.099524736404419 | Validation Loss: 1.1003369092941284\n",
            "Train Loss at iteration 103: 1.1006429195404053 | Validation Loss: 1.0996893644332886\n",
            "Train Loss at iteration 104: 1.097245454788208 | Validation Loss: 1.1013191938400269\n",
            "Train Loss at iteration 105: 1.0987423658370972 | Validation Loss: 1.099266529083252\n",
            "Train Loss at iteration 106: 1.0965396165847778 | Validation Loss: 1.097396969795227\n",
            "Train Loss at iteration 107: 1.099463701248169 | Validation Loss: 1.0989865064620972\n",
            "Train Loss at iteration 108: 1.0980278253555298 | Validation Loss: 1.0991082191467285\n",
            "Train Loss at iteration 109: 1.0998119115829468 | Validation Loss: 1.100940465927124\n",
            "Train Loss at iteration 110: 1.0993691682815552 | Validation Loss: 1.0987120866775513\n",
            "Train Loss at iteration 111: 1.0982614755630493 | Validation Loss: 1.0989018678665161\n",
            "Train Loss at iteration 112: 1.0990930795669556 | Validation Loss: 1.100941777229309\n",
            "Train Loss at iteration 113: 1.0982471704483032 | Validation Loss: 1.0989807844161987\n",
            "Train Loss at iteration 114: 1.1003069877624512 | Validation Loss: 1.1021654605865479\n",
            "Train Loss at iteration 115: 1.0975911617279053 | Validation Loss: 1.099837303161621\n",
            "Train Loss at iteration 116: 1.0990049839019775 | Validation Loss: 1.09916353225708\n",
            "Train Loss at iteration 117: 1.0989012718200684 | Validation Loss: 1.1004350185394287\n",
            "Train Loss at iteration 118: 1.0998680591583252 | Validation Loss: 1.0993212461471558\n",
            "Train Loss at iteration 119: 1.096519947052002 | Validation Loss: 1.0978680849075317\n",
            "Train Loss at iteration 120: 1.097052812576294 | Validation Loss: 1.0997811555862427\n",
            "Train Loss at iteration 121: 1.1004856824874878 | Validation Loss: 1.0985314846038818\n",
            "Train Loss at iteration 122: 1.0968300104141235 | Validation Loss: 1.1019152402877808\n",
            "Train Loss at iteration 123: 1.099988341331482 | Validation Loss: 1.0986638069152832\n",
            "Train Loss at iteration 124: 1.1013673543930054 | Validation Loss: 1.0988194942474365\n",
            "Train Loss at iteration 125: 1.1010316610336304 | Validation Loss: 1.0973482131958008\n",
            "Train Loss at iteration 126: 1.0977942943572998 | Validation Loss: 1.0975229740142822\n",
            "Train Loss at iteration 127: 1.0995934009552002 | Validation Loss: 1.0995792150497437\n",
            "Train Loss at iteration 128: 1.0984355211257935 | Validation Loss: 1.0988737344741821\n",
            "Train Loss at iteration 129: 1.0985229015350342 | Validation Loss: 1.0981338024139404\n",
            "Train Loss at iteration 130: 1.0984306335449219 | Validation Loss: 1.0976486206054688\n",
            "Train Loss at iteration 131: 1.0969557762145996 | Validation Loss: 1.0976529121398926\n",
            "Train Loss at iteration 132: 1.0992038249969482 | Validation Loss: 1.0990597009658813\n",
            "Train Loss at iteration 133: 1.0995527505874634 | Validation Loss: 1.099599838256836\n",
            "Train Loss at iteration 134: 1.097941517829895 | Validation Loss: 1.0983647108078003\n",
            "Train Loss at iteration 135: 1.0988017320632935 | Validation Loss: 1.1000773906707764\n",
            "Train Loss at iteration 136: 1.0960332155227661 | Validation Loss: 1.1015087366104126\n",
            "Train Loss at iteration 137: 1.0977129936218262 | Validation Loss: 1.0985429286956787\n",
            "Train Loss at iteration 138: 1.0979849100112915 | Validation Loss: 1.1014803647994995\n",
            "Train Loss at iteration 139: 1.101233720779419 | Validation Loss: 1.102797508239746\n",
            "Train Loss at iteration 140: 1.0981183052062988 | Validation Loss: 1.0977733135223389\n",
            "Train Loss at iteration 141: 1.0999401807785034 | Validation Loss: 1.1010823249816895\n",
            "Train Loss at iteration 142: 1.1003215312957764 | Validation Loss: 1.0976543426513672\n",
            "Train Loss at iteration 143: 1.098334550857544 | Validation Loss: 1.0967304706573486\n",
            "Train Loss at iteration 144: 1.0936968326568604 | Validation Loss: 1.1009585857391357\n",
            "Train Loss at iteration 145: 1.1026039123535156 | Validation Loss: 1.0992720127105713\n",
            "Train Loss at iteration 146: 1.0977730751037598 | Validation Loss: 1.100578784942627\n",
            "Train Loss at iteration 147: 1.100624442100525 | Validation Loss: 1.1004096269607544\n",
            "Train Loss at iteration 148: 1.0974072217941284 | Validation Loss: 1.098347783088684\n",
            "Train Loss at iteration 149: 1.0980404615402222 | Validation Loss: 1.0987834930419922\n",
            "Train Loss at iteration 150: 1.0989651679992676 | Validation Loss: 1.098519206047058\n",
            "Train Loss at iteration 151: 1.0987787246704102 | Validation Loss: 1.0968575477600098\n",
            "Train Loss at iteration 152: 1.098671793937683 | Validation Loss: 1.0977014303207397\n",
            "Train Loss at iteration 153: 1.097846269607544 | Validation Loss: 1.0970741510391235\n",
            "Train Loss at iteration 154: 1.099249243736267 | Validation Loss: 1.0986769199371338\n",
            "Train Loss at iteration 155: 1.1002205610275269 | Validation Loss: 1.0994861125946045\n",
            "Train Loss at iteration 156: 1.0994203090667725 | Validation Loss: 1.098812222480774\n",
            "Train Loss at iteration 157: 1.0981249809265137 | Validation Loss: 1.0995128154754639\n",
            "Train Loss at iteration 158: 1.0972055196762085 | Validation Loss: 1.0981745719909668\n",
            "Train Loss at iteration 159: 1.0993915796279907 | Validation Loss: 1.0993711948394775\n",
            "Train Loss at iteration 160: 1.0993252992630005 | Validation Loss: 1.1009788513183594\n",
            "Train Loss at iteration 161: 1.098149299621582 | Validation Loss: 1.0973732471466064\n",
            "Train Loss at iteration 162: 1.1012071371078491 | Validation Loss: 1.0993813276290894\n",
            "Train Loss at iteration 163: 1.0971064567565918 | Validation Loss: 1.1000699996948242\n",
            "Train Loss at iteration 164: 1.09971022605896 | Validation Loss: 1.0971978902816772\n",
            "Train Loss at iteration 165: 1.0983682870864868 | Validation Loss: 1.100982904434204\n",
            "Train Loss at iteration 166: 1.0988517999649048 | Validation Loss: 1.096960186958313\n",
            "Train Loss at iteration 167: 1.0997790098190308 | Validation Loss: 1.1000224351882935\n",
            "Train Loss at iteration 168: 1.0990114212036133 | Validation Loss: 1.098352313041687\n",
            "Train Loss at iteration 169: 1.0981210470199585 | Validation Loss: 1.100343942642212\n",
            "Train Loss at iteration 170: 1.0968506336212158 | Validation Loss: 1.0974174737930298\n",
            "Train Loss at iteration 171: 1.0980373620986938 | Validation Loss: 1.1003154516220093\n",
            "Train Loss at iteration 172: 1.097666621208191 | Validation Loss: 1.0942808389663696\n",
            "Train Loss at iteration 173: 1.1047617197036743 | Validation Loss: 1.0978671312332153\n",
            "Train Loss at iteration 174: 1.0994398593902588 | Validation Loss: 1.0961792469024658\n",
            "Train Loss at iteration 175: 1.0986026525497437 | Validation Loss: 1.0969457626342773\n",
            "Train Loss at iteration 176: 1.0982446670532227 | Validation Loss: 1.097669243812561\n",
            "Train Loss at iteration 177: 1.097362756729126 | Validation Loss: 1.0988833904266357\n",
            "Train Loss at iteration 178: 1.098189115524292 | Validation Loss: 1.0970567464828491\n",
            "Train Loss at iteration 179: 1.0979588031768799 | Validation Loss: 1.0960625410079956\n",
            "Train Loss at iteration 180: 1.0989282131195068 | Validation Loss: 1.099409580230713\n",
            "Train Loss at iteration 181: 1.097560167312622 | Validation Loss: 1.0980587005615234\n",
            "Train Loss at iteration 182: 1.0957269668579102 | Validation Loss: 1.0992823839187622\n",
            "Train Loss at iteration 183: 1.1009743213653564 | Validation Loss: 1.0994775295257568\n",
            "Train Loss at iteration 184: 1.1000334024429321 | Validation Loss: 1.101322054862976\n",
            "Train Loss at iteration 185: 1.0993309020996094 | Validation Loss: 1.0954270362854004\n",
            "Train Loss at iteration 186: 1.0994353294372559 | Validation Loss: 1.101205825805664\n",
            "Train Loss at iteration 187: 1.1010677814483643 | Validation Loss: 1.1000593900680542\n",
            "Train Loss at iteration 188: 1.100075364112854 | Validation Loss: 1.0983128547668457\n",
            "Train Loss at iteration 189: 1.0997058153152466 | Validation Loss: 1.0994470119476318\n",
            "Train Loss at iteration 190: 1.0981885194778442 | Validation Loss: 1.1004036664962769\n",
            "Train Loss at iteration 191: 1.0985562801361084 | Validation Loss: 1.0963371992111206\n",
            "Train Loss at iteration 192: 1.0977776050567627 | Validation Loss: 1.0967472791671753\n",
            "Train Loss at iteration 193: 1.0974782705307007 | Validation Loss: 1.1004855632781982\n",
            "Train Loss at iteration 194: 1.098944067955017 | Validation Loss: 1.0977836847305298\n",
            "Train Loss at iteration 195: 1.0981485843658447 | Validation Loss: 1.0979747772216797\n",
            "Train Loss at iteration 196: 1.0989177227020264 | Validation Loss: 1.0984727144241333\n",
            "Train Loss at iteration 197: 1.0984973907470703 | Validation Loss: 1.0982418060302734\n",
            "Train Loss at iteration 198: 1.0965890884399414 | Validation Loss: 1.099118947982788\n",
            "Train Loss at iteration 199: 1.0966259241104126 | Validation Loss: 1.1003752946853638\n",
            "Train Loss at iteration 200: 1.0976837873458862 | Validation Loss: 1.0996395349502563\n",
            "Train Loss at iteration 201: 1.098156452178955 | Validation Loss: 1.0990420579910278\n",
            "Train Loss at iteration 202: 1.0977617502212524 | Validation Loss: 1.0990575551986694\n",
            "Train Loss at iteration 203: 1.0972342491149902 | Validation Loss: 1.098692774772644\n",
            "Train Loss at iteration 204: 1.0986640453338623 | Validation Loss: 1.0984708070755005\n",
            "Train Loss at iteration 205: 1.0983343124389648 | Validation Loss: 1.0991097688674927\n",
            "Train Loss at iteration 206: 1.0955368280410767 | Validation Loss: 1.1000256538391113\n",
            "Train Loss at iteration 207: 1.1026204824447632 | Validation Loss: 1.0970460176467896\n",
            "Train Loss at iteration 208: 1.0961095094680786 | Validation Loss: 1.0984435081481934\n",
            "Train Loss at iteration 209: 1.1016802787780762 | Validation Loss: 1.099092721939087\n",
            "Train Loss at iteration 210: 1.098060131072998 | Validation Loss: 1.098487138748169\n",
            "Train Loss at iteration 211: 1.0967707633972168 | Validation Loss: 1.098253846168518\n",
            "Train Loss at iteration 212: 1.0970311164855957 | Validation Loss: 1.0981427431106567\n",
            "Train Loss at iteration 213: 1.0979831218719482 | Validation Loss: 1.0980353355407715\n",
            "Train Loss at iteration 214: 1.0966006517410278 | Validation Loss: 1.0975161790847778\n",
            "Train Loss at iteration 215: 1.0971790552139282 | Validation Loss: 1.0981838703155518\n",
            "Train Loss at iteration 216: 1.1002980470657349 | Validation Loss: 1.0951439142227173\n",
            "Train Loss at iteration 217: 1.0972405672073364 | Validation Loss: 1.0976600646972656\n",
            "Train Loss at iteration 218: 1.0978989601135254 | Validation Loss: 1.096125602722168\n",
            "Train Loss at iteration 219: 1.0971839427947998 | Validation Loss: 1.0948148965835571\n",
            "Train Loss at iteration 220: 1.0952692031860352 | Validation Loss: 1.1046230792999268\n",
            "Train Loss at iteration 221: 1.1002452373504639 | Validation Loss: 1.100237250328064\n",
            "Train Loss at iteration 222: 1.093977689743042 | Validation Loss: 1.0965672731399536\n",
            "Train Loss at iteration 223: 1.0976300239562988 | Validation Loss: 1.0961894989013672\n",
            "Train Loss at iteration 224: 1.0955866575241089 | Validation Loss: 1.0957690477371216\n",
            "Train Loss at iteration 225: 1.1010147333145142 | Validation Loss: 1.0987664461135864\n",
            "Train Loss at iteration 226: 1.0952752828598022 | Validation Loss: 1.0966169834136963\n",
            "Train Loss at iteration 227: 1.0951762199401855 | Validation Loss: 1.092672348022461\n",
            "Train Loss at iteration 228: 1.098832130432129 | Validation Loss: 1.0999349355697632\n",
            "Train Loss at iteration 229: 1.0988837480545044 | Validation Loss: 1.099191665649414\n",
            "Train Loss at iteration 230: 1.0964765548706055 | Validation Loss: 1.0941671133041382\n",
            "Train Loss at iteration 231: 1.1012333631515503 | Validation Loss: 1.0948899984359741\n",
            "Train Loss at iteration 232: 1.0990945100784302 | Validation Loss: 1.0947413444519043\n",
            "Train Loss at iteration 233: 1.0987318754196167 | Validation Loss: 1.095887303352356\n",
            "Train Loss at iteration 234: 1.0957884788513184 | Validation Loss: 1.0984479188919067\n",
            "Train Loss at iteration 235: 1.0959270000457764 | Validation Loss: 1.0968290567398071\n",
            "Train Loss at iteration 236: 1.0959429740905762 | Validation Loss: 1.097800850868225\n",
            "Train Loss at iteration 237: 1.0979124307632446 | Validation Loss: 1.0967495441436768\n",
            "Train Loss at iteration 238: 1.095810890197754 | Validation Loss: 1.0978832244873047\n",
            "Train Loss at iteration 239: 1.0959646701812744 | Validation Loss: 1.0948165655136108\n",
            "Train Loss at iteration 240: 1.0952309370040894 | Validation Loss: 1.09586763381958\n",
            "Train Loss at iteration 241: 1.0962222814559937 | Validation Loss: 1.0985755920410156\n",
            "Train Loss at iteration 242: 1.0954400300979614 | Validation Loss: 1.1000888347625732\n",
            "Train Loss at iteration 243: 1.0995362997055054 | Validation Loss: 1.0969433784484863\n",
            "Train Loss at iteration 244: 1.0951834917068481 | Validation Loss: 1.0987989902496338\n",
            "Train Loss at iteration 245: 1.0962815284729004 | Validation Loss: 1.0981733798980713\n",
            "Train Loss at iteration 246: 1.0996332168579102 | Validation Loss: 1.0973498821258545\n",
            "Train Loss at iteration 247: 1.0973268747329712 | Validation Loss: 1.0956565141677856\n",
            "Train Loss at iteration 248: 1.0941954851150513 | Validation Loss: 1.0959275960922241\n",
            "Train Loss at iteration 249: 1.0957027673721313 | Validation Loss: 1.0968458652496338\n",
            "Train Loss at iteration 250: 1.0940989255905151 | Validation Loss: 1.0998350381851196\n",
            "Train Loss at iteration 251: 1.1006356477737427 | Validation Loss: 1.093543529510498\n",
            "Train Loss at iteration 252: 1.0976024866104126 | Validation Loss: 1.0988081693649292\n",
            "Train Loss at iteration 253: 1.0910063982009888 | Validation Loss: 1.098254680633545\n",
            "Train Loss at iteration 254: 1.0951566696166992 | Validation Loss: 1.0948090553283691\n",
            "Train Loss at iteration 255: 1.0955132246017456 | Validation Loss: 1.1014631986618042\n",
            "Train Loss at iteration 256: 1.0906373262405396 | Validation Loss: 1.0937285423278809\n",
            "Train Loss at iteration 257: 1.0929919481277466 | Validation Loss: 1.0955108404159546\n",
            "Train Loss at iteration 258: 1.0958307981491089 | Validation Loss: 1.0963497161865234\n",
            "Train Loss at iteration 259: 1.098987340927124 | Validation Loss: 1.1016227006912231\n",
            "Train Loss at iteration 260: 1.0938390493392944 | Validation Loss: 1.0939370393753052\n",
            "Train Loss at iteration 261: 1.0929195880889893 | Validation Loss: 1.095582365989685\n",
            "Train Loss at iteration 262: 1.0907578468322754 | Validation Loss: 1.0945063829421997\n",
            "Train Loss at iteration 263: 1.0886765718460083 | Validation Loss: 1.0932668447494507\n",
            "Train Loss at iteration 264: 1.0976859331130981 | Validation Loss: 1.093505620956421\n",
            "Train Loss at iteration 265: 1.0963709354400635 | Validation Loss: 1.093435525894165\n",
            "Train Loss at iteration 266: 1.0973998308181763 | Validation Loss: 1.0926017761230469\n",
            "Train Loss at iteration 267: 1.0906575918197632 | Validation Loss: 1.0947715044021606\n",
            "Train Loss at iteration 268: 1.0919215679168701 | Validation Loss: 1.0955100059509277\n",
            "Train Loss at iteration 269: 1.0976828336715698 | Validation Loss: 1.0937498807907104\n",
            "Train Loss at iteration 270: 1.09224534034729 | Validation Loss: 1.0951799154281616\n",
            "Train Loss at iteration 271: 1.0938525199890137 | Validation Loss: 1.0968995094299316\n",
            "Train Loss at iteration 272: 1.0955719947814941 | Validation Loss: 1.0941107273101807\n",
            "Train Loss at iteration 273: 1.0944966077804565 | Validation Loss: 1.0925687551498413\n",
            "Train Loss at iteration 274: 1.0928364992141724 | Validation Loss: 1.0937435626983643\n",
            "Train Loss at iteration 275: 1.0944889783859253 | Validation Loss: 1.0886260271072388\n",
            "Train Loss at iteration 276: 1.0927093029022217 | Validation Loss: 1.092415452003479\n",
            "Train Loss at iteration 277: 1.0908018350601196 | Validation Loss: 1.0985302925109863\n",
            "Train Loss at iteration 278: 1.088667631149292 | Validation Loss: 1.0938291549682617\n",
            "Train Loss at iteration 279: 1.0971752405166626 | Validation Loss: 1.098890781402588\n",
            "Train Loss at iteration 280: 1.09040367603302 | Validation Loss: 1.1031261682510376\n",
            "Train Loss at iteration 281: 1.0949031114578247 | Validation Loss: 1.0935251712799072\n",
            "Train Loss at iteration 282: 1.0969998836517334 | Validation Loss: 1.091651439666748\n",
            "Train Loss at iteration 283: 1.08872652053833 | Validation Loss: 1.090625286102295\n",
            "Train Loss at iteration 284: 1.095422625541687 | Validation Loss: 1.0940393209457397\n",
            "Train Loss at iteration 285: 1.0941789150238037 | Validation Loss: 1.0960190296173096\n",
            "Train Loss at iteration 286: 1.0865321159362793 | Validation Loss: 1.1060024499893188\n",
            "Train Loss at iteration 287: 1.0969384908676147 | Validation Loss: 1.0932989120483398\n",
            "Train Loss at iteration 288: 1.0835360288619995 | Validation Loss: 1.1013134717941284\n",
            "Train Loss at iteration 289: 1.0957703590393066 | Validation Loss: 1.106139898300171\n",
            "Train Loss at iteration 290: 1.084747076034546 | Validation Loss: 1.1075669527053833\n",
            "Train Loss at iteration 291: 1.0944219827651978 | Validation Loss: 1.1037044525146484\n",
            "Train Loss at iteration 292: 1.1063201427459717 | Validation Loss: 1.0933078527450562\n",
            "Train Loss at iteration 293: 1.0913418531417847 | Validation Loss: 1.1015654802322388\n",
            "Train Loss at iteration 294: 1.0888593196868896 | Validation Loss: 1.0905873775482178\n",
            "Train Loss at iteration 295: 1.0887863636016846 | Validation Loss: 1.0908186435699463\n",
            "Train Loss at iteration 296: 1.089347243309021 | Validation Loss: 1.0956076383590698\n",
            "Train Loss at iteration 297: 1.0957446098327637 | Validation Loss: 1.0969622135162354\n",
            "Train Loss at iteration 298: 1.0816020965576172 | Validation Loss: 1.0957558155059814\n",
            "Train Loss at iteration 299: 1.0929845571517944 | Validation Loss: 1.0918498039245605\n",
            "Train Loss at iteration 300: 1.093078851699829 | Validation Loss: 1.084786295890808\n",
            "Train Loss at iteration 301: 1.086167573928833 | Validation Loss: 1.0910446643829346\n",
            "Train Loss at iteration 302: 1.0865517854690552 | Validation Loss: 1.0835413932800293\n",
            "Train Loss at iteration 303: 1.085064172744751 | Validation Loss: 1.0898404121398926\n",
            "Train Loss at iteration 304: 1.0866186618804932 | Validation Loss: 1.0893868207931519\n",
            "Train Loss at iteration 305: 1.0943547487258911 | Validation Loss: 1.0919468402862549\n",
            "Train Loss at iteration 306: 1.0895540714263916 | Validation Loss: 1.093794822692871\n",
            "Train Loss at iteration 307: 1.0794602632522583 | Validation Loss: 1.0918819904327393\n",
            "Train Loss at iteration 308: 1.0820024013519287 | Validation Loss: 1.0903741121292114\n",
            "Train Loss at iteration 309: 1.0895888805389404 | Validation Loss: 1.0884677171707153\n",
            "Train Loss at iteration 310: 1.084586501121521 | Validation Loss: 1.1042330265045166\n",
            "Train Loss at iteration 311: 1.0827561616897583 | Validation Loss: 1.0887713432312012\n",
            "Train Loss at iteration 312: 1.0908507108688354 | Validation Loss: 1.0842339992523193\n",
            "Train Loss at iteration 313: 1.0990301370620728 | Validation Loss: 1.0843981504440308\n",
            "Train Loss at iteration 314: 1.085919976234436 | Validation Loss: 1.0964500904083252\n",
            "Train Loss at iteration 315: 1.098878264427185 | Validation Loss: 1.0967847108840942\n",
            "Train Loss at iteration 316: 1.0912446975708008 | Validation Loss: 1.1052465438842773\n",
            "Train Loss at iteration 317: 1.0900084972381592 | Validation Loss: 1.0865864753723145\n",
            "Train Loss at iteration 318: 1.0999035835266113 | Validation Loss: 1.0884615182876587\n",
            "Train Loss at iteration 319: 1.0795820951461792 | Validation Loss: 1.085694670677185\n",
            "Train Loss at iteration 320: 1.0858067274093628 | Validation Loss: 1.0911341905593872\n",
            "Train Loss at iteration 321: 1.0771136283874512 | Validation Loss: 1.0920255184173584\n",
            "Train Loss at iteration 322: 1.0945374965667725 | Validation Loss: 1.0975345373153687\n",
            "Train Loss at iteration 323: 1.1012048721313477 | Validation Loss: 1.0907622575759888\n",
            "Train Loss at iteration 324: 1.0949546098709106 | Validation Loss: 1.0949864387512207\n",
            "Train Loss at iteration 325: 1.0870864391326904 | Validation Loss: 1.088783860206604\n",
            "Train Loss at iteration 326: 1.093363881111145 | Validation Loss: 1.0814381837844849\n",
            "Train Loss at iteration 327: 1.0844148397445679 | Validation Loss: 1.0904051065444946\n",
            "Train Loss at iteration 328: 1.0914853811264038 | Validation Loss: 1.0836982727050781\n",
            "Train Loss at iteration 329: 1.0909141302108765 | Validation Loss: 1.0881128311157227\n",
            "Train Loss at iteration 330: 1.0766521692276 | Validation Loss: 1.0973992347717285\n",
            "Train Loss at iteration 331: 1.092036247253418 | Validation Loss: 1.1020978689193726\n",
            "Train Loss at iteration 332: 1.086773157119751 | Validation Loss: 1.0996686220169067\n",
            "Train Loss at iteration 333: 1.0784754753112793 | Validation Loss: 1.1011441946029663\n",
            "Train Loss at iteration 334: 1.0794286727905273 | Validation Loss: 1.0933743715286255\n",
            "Train Loss at iteration 335: 1.0900627374649048 | Validation Loss: 1.0916279554367065\n",
            "Train Loss at iteration 336: 1.0880045890808105 | Validation Loss: 1.0824471712112427\n",
            "Train Loss at iteration 337: 1.08463716506958 | Validation Loss: 1.0889233350753784\n",
            "Train Loss at iteration 338: 1.0906982421875 | Validation Loss: 1.073693037033081\n",
            "Train Loss at iteration 339: 1.079869270324707 | Validation Loss: 1.0847657918930054\n",
            "Train Loss at iteration 340: 1.0902572870254517 | Validation Loss: 1.0863195657730103\n",
            "Train Loss at iteration 341: 1.083971619606018 | Validation Loss: 1.0818994045257568\n",
            "Train Loss at iteration 342: 1.0873323678970337 | Validation Loss: 1.0911484956741333\n",
            "Train Loss at iteration 343: 1.0888830423355103 | Validation Loss: 1.0947749614715576\n",
            "Train Loss at iteration 344: 1.089530348777771 | Validation Loss: 1.0735628604888916\n",
            "Train Loss at iteration 345: 1.0779329538345337 | Validation Loss: 1.0849030017852783\n",
            "Train Loss at iteration 346: 1.0996677875518799 | Validation Loss: 1.0763146877288818\n",
            "Train Loss at iteration 347: 1.0802810192108154 | Validation Loss: 1.0894886255264282\n",
            "Train Loss at iteration 348: 1.094385027885437 | Validation Loss: 1.0874894857406616\n",
            "Train Loss at iteration 349: 1.0823920965194702 | Validation Loss: 1.096664309501648\n",
            "Train Loss at iteration 350: 1.0912425518035889 | Validation Loss: 1.1144566535949707\n",
            "Train Loss at iteration 351: 1.0812057256698608 | Validation Loss: 1.0976396799087524\n",
            "Train Loss at iteration 352: 1.0973364114761353 | Validation Loss: 1.0871931314468384\n",
            "Train Loss at iteration 353: 1.0900925397872925 | Validation Loss: 1.093988060951233\n",
            "Train Loss at iteration 354: 1.0822665691375732 | Validation Loss: 1.0939867496490479\n",
            "Train Loss at iteration 355: 1.0999730825424194 | Validation Loss: 1.1016550064086914\n",
            "Train Loss at iteration 356: 1.0827362537384033 | Validation Loss: 1.0947420597076416\n",
            "Train Loss at iteration 357: 1.0929139852523804 | Validation Loss: 1.073683738708496\n",
            "Train Loss at iteration 358: 1.0830161571502686 | Validation Loss: 1.0959725379943848\n",
            "Train Loss at iteration 359: 1.0801875591278076 | Validation Loss: 1.0902842283248901\n",
            "Train Loss at iteration 360: 1.089473843574524 | Validation Loss: 1.0845850706100464\n",
            "Train Loss at iteration 361: 1.1020311117172241 | Validation Loss: 1.07296884059906\n",
            "Train Loss at iteration 362: 1.065223217010498 | Validation Loss: 1.0890717506408691\n",
            "Train Loss at iteration 363: 1.0864853858947754 | Validation Loss: 1.0746790170669556\n",
            "Train Loss at iteration 364: 1.0813791751861572 | Validation Loss: 1.1003504991531372\n",
            "Train Loss at iteration 365: 1.0798649787902832 | Validation Loss: 1.0850342512130737\n",
            "Train Loss at iteration 366: 1.0816253423690796 | Validation Loss: 1.0823935270309448\n",
            "Train Loss at iteration 367: 1.100126028060913 | Validation Loss: 1.0798441171646118\n",
            "Train Loss at iteration 368: 1.0784088373184204 | Validation Loss: 1.0736056566238403\n",
            "Train Loss at iteration 369: 1.0861555337905884 | Validation Loss: 1.0859603881835938\n",
            "Train Loss at iteration 370: 1.0929069519042969 | Validation Loss: 1.0849202871322632\n",
            "Train Loss at iteration 371: 1.0885683298110962 | Validation Loss: 1.0918617248535156\n",
            "Train Loss at iteration 372: 1.0755245685577393 | Validation Loss: 1.080341100692749\n",
            "Train Loss at iteration 373: 1.0720969438552856 | Validation Loss: 1.0912938117980957\n",
            "Train Loss at iteration 374: 1.0914818048477173 | Validation Loss: 1.0850499868392944\n",
            "Train Loss at iteration 375: 1.0839810371398926 | Validation Loss: 1.0935355424880981\n",
            "Train Loss at iteration 376: 1.0965347290039062 | Validation Loss: 1.0877715349197388\n",
            "Train Loss at iteration 377: 1.0851486921310425 | Validation Loss: 1.0747439861297607\n",
            "Train Loss at iteration 378: 1.0933750867843628 | Validation Loss: 1.0876526832580566\n",
            "Train Loss at iteration 379: 1.0798627138137817 | Validation Loss: 1.104343295097351\n",
            "Train Loss at iteration 380: 1.0968481302261353 | Validation Loss: 1.0777244567871094\n",
            "Train Loss at iteration 381: 1.0970354080200195 | Validation Loss: 1.0833300352096558\n",
            "Train Loss at iteration 382: 1.0794830322265625 | Validation Loss: 1.0899685621261597\n",
            "Train Loss at iteration 383: 1.0750854015350342 | Validation Loss: 1.0900284051895142\n",
            "Train Loss at iteration 384: 1.0963486433029175 | Validation Loss: 1.0966917276382446\n",
            "Train Loss at iteration 385: 1.0761945247650146 | Validation Loss: 1.0887048244476318\n",
            "Train Loss at iteration 386: 1.0762392282485962 | Validation Loss: 1.0911791324615479\n",
            "Train Loss at iteration 387: 1.080742359161377 | Validation Loss: 1.0939899682998657\n",
            "Train Loss at iteration 388: 1.0826154947280884 | Validation Loss: 1.0963693857192993\n",
            "Train Loss at iteration 389: 1.0766364336013794 | Validation Loss: 1.1027501821517944\n",
            "Train Loss at iteration 390: 1.084689736366272 | Validation Loss: 1.1153395175933838\n",
            "Train Loss at iteration 391: 1.0837613344192505 | Validation Loss: 1.0917739868164062\n",
            "Train Loss at iteration 392: 1.0988534688949585 | Validation Loss: 1.0781641006469727\n",
            "Train Loss at iteration 393: 1.091873288154602 | Validation Loss: 1.0896064043045044\n",
            "Train Loss at iteration 394: 1.095649003982544 | Validation Loss: 1.0865857601165771\n",
            "Train Loss at iteration 395: 1.0737143754959106 | Validation Loss: 1.0893728733062744\n",
            "Train Loss at iteration 396: 1.0843547582626343 | Validation Loss: 1.0697298049926758\n",
            "Train Loss at iteration 397: 1.0880266427993774 | Validation Loss: 1.0823383331298828\n",
            "Train Loss at iteration 398: 1.096264362335205 | Validation Loss: 1.0800142288208008\n",
            "Train Loss at iteration 399: 1.0921355485916138 | Validation Loss: 1.0906563997268677\n",
            "Train Loss at iteration 400: 1.071670413017273 | Validation Loss: 1.0924263000488281\n",
            "Train Loss at iteration 401: 1.068595290184021 | Validation Loss: 1.1009714603424072\n",
            "Train Loss at iteration 402: 1.0849992036819458 | Validation Loss: 1.0876485109329224\n",
            "Train Loss at iteration 403: 1.0887305736541748 | Validation Loss: 1.0940920114517212\n",
            "Train Loss at iteration 404: 1.082220196723938 | Validation Loss: 1.075594186782837\n",
            "Train Loss at iteration 405: 1.065503716468811 | Validation Loss: 1.1060137748718262\n",
            "Train Loss at iteration 406: 1.0852811336517334 | Validation Loss: 1.0987588167190552\n",
            "Train Loss at iteration 407: 1.0860627889633179 | Validation Loss: 1.0960571765899658\n",
            "Train Loss at iteration 408: 1.0996088981628418 | Validation Loss: 1.1083073616027832\n",
            "Train Loss at iteration 409: 1.085616111755371 | Validation Loss: 1.0789088010787964\n",
            "Train Loss at iteration 410: 1.0812842845916748 | Validation Loss: 1.0948072671890259\n",
            "Train Loss at iteration 411: 1.0938061475753784 | Validation Loss: 1.1016595363616943\n",
            "Train Loss at iteration 412: 1.1004911661148071 | Validation Loss: 1.1041429042816162\n",
            "Train Loss at iteration 413: 1.1142191886901855 | Validation Loss: 1.0867664813995361\n",
            "Train Loss at iteration 414: 1.0704096555709839 | Validation Loss: 1.088802456855774\n",
            "Train Loss at iteration 415: 1.0699714422225952 | Validation Loss: 1.105940341949463\n",
            "Train Loss at iteration 416: 1.0936161279678345 | Validation Loss: 1.1155269145965576\n",
            "Train Loss at iteration 417: 1.1025457382202148 | Validation Loss: 1.0839751958847046\n",
            "Train Loss at iteration 418: 1.089114785194397 | Validation Loss: 1.1082196235656738\n",
            "Train Loss at iteration 419: 1.0721344947814941 | Validation Loss: 1.0953407287597656\n",
            "Train Loss at iteration 420: 1.1076453924179077 | Validation Loss: 1.0980291366577148\n",
            "Train Loss at iteration 421: 1.096822738647461 | Validation Loss: 1.1014066934585571\n",
            "Train Loss at iteration 422: 1.0899707078933716 | Validation Loss: 1.0867794752120972\n",
            "Train Loss at iteration 423: 1.079699158668518 | Validation Loss: 1.0947315692901611\n",
            "Train Loss at iteration 424: 1.0866408348083496 | Validation Loss: 1.0734339952468872\n",
            "Train Loss at iteration 425: 1.0727840662002563 | Validation Loss: 1.0782089233398438\n",
            "Train Loss at iteration 426: 1.094102382659912 | Validation Loss: 1.0830861330032349\n",
            "Train Loss at iteration 427: 1.0805050134658813 | Validation Loss: 1.0771464109420776\n",
            "Train Loss at iteration 428: 1.093672275543213 | Validation Loss: 1.0725278854370117\n",
            "Train Loss at iteration 429: 1.081284523010254 | Validation Loss: 1.0680303573608398\n",
            "Train Loss at iteration 430: 1.0855765342712402 | Validation Loss: 1.0772266387939453\n",
            "Train Loss at iteration 431: 1.0846879482269287 | Validation Loss: 1.0881115198135376\n",
            "Train Loss at iteration 432: 1.0844273567199707 | Validation Loss: 1.0842761993408203\n",
            "Train Loss at iteration 433: 1.0874258279800415 | Validation Loss: 1.0913779735565186\n",
            "Train Loss at iteration 434: 1.0729111433029175 | Validation Loss: 1.0875401496887207\n",
            "Train Loss at iteration 435: 1.0986062288284302 | Validation Loss: 1.0878475904464722\n",
            "Train Loss at iteration 436: 1.0760350227355957 | Validation Loss: 1.0916060209274292\n",
            "Train Loss at iteration 437: 1.0814337730407715 | Validation Loss: 1.090754508972168\n",
            "Train Loss at iteration 438: 1.0832613706588745 | Validation Loss: 1.0917361974716187\n",
            "Train Loss at iteration 439: 1.0744729042053223 | Validation Loss: 1.0969959497451782\n",
            "Train Loss at iteration 440: 1.0720514059066772 | Validation Loss: 1.0746105909347534\n",
            "Train Loss at iteration 441: 1.07919180393219 | Validation Loss: 1.0961387157440186\n",
            "Train Loss at iteration 442: 1.0902148485183716 | Validation Loss: 1.0908232927322388\n",
            "Train Loss at iteration 443: 1.0766032934188843 | Validation Loss: 1.095921277999878\n",
            "Train Loss at iteration 444: 1.088783621788025 | Validation Loss: 1.0784833431243896\n",
            "Train Loss at iteration 445: 1.0904325246810913 | Validation Loss: 1.0815690755844116\n",
            "Train Loss at iteration 446: 1.0743825435638428 | Validation Loss: 1.082649827003479\n",
            "Train Loss at iteration 447: 1.0680351257324219 | Validation Loss: 1.0734069347381592\n",
            "Train Loss at iteration 448: 1.08625066280365 | Validation Loss: 1.0771056413650513\n",
            "Train Loss at iteration 449: 1.0760501623153687 | Validation Loss: 1.0884462594985962\n",
            "Train Loss at iteration 450: 1.087610125541687 | Validation Loss: 1.0889536142349243\n",
            "Train Loss at iteration 451: 1.0861281156539917 | Validation Loss: 1.0945886373519897\n",
            "Train Loss at iteration 452: 1.0654089450836182 | Validation Loss: 1.0957008600234985\n",
            "Train Loss at iteration 453: 1.0754365921020508 | Validation Loss: 1.0847830772399902\n",
            "Train Loss at iteration 454: 1.0674567222595215 | Validation Loss: 1.083446979522705\n",
            "Train Loss at iteration 455: 1.092071533203125 | Validation Loss: 1.1040880680084229\n",
            "Train Loss at iteration 456: 1.07707679271698 | Validation Loss: 1.1042219400405884\n",
            "Train Loss at iteration 457: 1.094820499420166 | Validation Loss: 1.0950121879577637\n",
            "Train Loss at iteration 458: 1.0619909763336182 | Validation Loss: 1.0838006734848022\n",
            "Train Loss at iteration 459: 1.0793631076812744 | Validation Loss: 1.1086212396621704\n",
            "Train Loss at iteration 460: 1.1018775701522827 | Validation Loss: 1.088433027267456\n",
            "Train Loss at iteration 461: 1.0953835248947144 | Validation Loss: 1.0882039070129395\n",
            "Train Loss at iteration 462: 1.0719503164291382 | Validation Loss: 1.0882312059402466\n",
            "Train Loss at iteration 463: 1.0849283933639526 | Validation Loss: 1.0815616846084595\n",
            "Train Loss at iteration 464: 1.0815129280090332 | Validation Loss: 1.0820515155792236\n",
            "Train Loss at iteration 465: 1.0791282653808594 | Validation Loss: 1.0829445123672485\n",
            "Train Loss at iteration 466: 1.0770219564437866 | Validation Loss: 1.0976393222808838\n",
            "Train Loss at iteration 467: 1.0836660861968994 | Validation Loss: 1.0784759521484375\n",
            "Train Loss at iteration 468: 1.0917776823043823 | Validation Loss: 1.08063805103302\n",
            "Train Loss at iteration 469: 1.0758477449417114 | Validation Loss: 1.072089433670044\n",
            "Train Loss at iteration 470: 1.0732738971710205 | Validation Loss: 1.0691348314285278\n",
            "Train Loss at iteration 471: 1.0777137279510498 | Validation Loss: 1.0734540224075317\n",
            "Train Loss at iteration 472: 1.073966145515442 | Validation Loss: 1.0805968046188354\n",
            "Train Loss at iteration 473: 1.0839306116104126 | Validation Loss: 1.0895142555236816\n",
            "Train Loss at iteration 474: 1.085052728652954 | Validation Loss: 1.0771807432174683\n",
            "Train Loss at iteration 475: 1.0751004219055176 | Validation Loss: 1.07566499710083\n",
            "Train Loss at iteration 476: 1.0741233825683594 | Validation Loss: 1.082119107246399\n",
            "Train Loss at iteration 477: 1.0721278190612793 | Validation Loss: 1.0801349878311157\n",
            "Train Loss at iteration 478: 1.079336404800415 | Validation Loss: 1.0843948125839233\n",
            "Train Loss at iteration 479: 1.0907018184661865 | Validation Loss: 1.0870143175125122\n",
            "Train Loss at iteration 480: 1.088779330253601 | Validation Loss: 1.0927181243896484\n",
            "Train Loss at iteration 481: 1.083984136581421 | Validation Loss: 1.0835281610488892\n",
            "Train Loss at iteration 482: 1.0719943046569824 | Validation Loss: 1.086348295211792\n",
            "Train Loss at iteration 483: 1.0771013498306274 | Validation Loss: 1.090807318687439\n",
            "Train Loss at iteration 484: 1.0859882831573486 | Validation Loss: 1.079198956489563\n",
            "Train Loss at iteration 485: 1.068294644355774 | Validation Loss: 1.0822803974151611\n",
            "Train Loss at iteration 486: 1.07853364944458 | Validation Loss: 1.0960861444473267\n",
            "Train Loss at iteration 487: 1.0698987245559692 | Validation Loss: 1.0784096717834473\n",
            "Train Loss at iteration 488: 1.0883065462112427 | Validation Loss: 1.0749930143356323\n",
            "Train Loss at iteration 489: 1.0805028676986694 | Validation Loss: 1.076806664466858\n",
            "Train Loss at iteration 490: 1.0715019702911377 | Validation Loss: 1.0780643224716187\n",
            "Train Loss at iteration 491: 1.076410174369812 | Validation Loss: 1.0817346572875977\n",
            "Train Loss at iteration 492: 1.078206181526184 | Validation Loss: 1.079952597618103\n",
            "Train Loss at iteration 493: 1.0681648254394531 | Validation Loss: 1.0651363134384155\n",
            "Train Loss at iteration 494: 1.075661301612854 | Validation Loss: 1.0781811475753784\n",
            "Train Loss at iteration 495: 1.0818748474121094 | Validation Loss: 1.0942453145980835\n",
            "Train Loss at iteration 496: 1.0596277713775635 | Validation Loss: 1.0775054693222046\n",
            "Train Loss at iteration 497: 1.0740797519683838 | Validation Loss: 1.1032482385635376\n",
            "Train Loss at iteration 498: 1.0638474225997925 | Validation Loss: 1.0815585851669312\n",
            "Train Loss at iteration 499: 1.0827797651290894 | Validation Loss: 1.0855244398117065\n",
            "Train Loss at iteration 500: 1.0783140659332275 | Validation Loss: 1.082598328590393\n",
            "Train Loss at iteration 501: 1.087235689163208 | Validation Loss: 1.0819456577301025\n",
            "Train Loss at iteration 502: 1.0747575759887695 | Validation Loss: 1.0818921327590942\n",
            "Train Loss at iteration 503: 1.0664738416671753 | Validation Loss: 1.0542662143707275\n",
            "Train Loss at iteration 504: 1.0743780136108398 | Validation Loss: 1.098692536354065\n",
            "Train Loss at iteration 505: 1.0755366086959839 | Validation Loss: 1.086667537689209\n",
            "Train Loss at iteration 506: 1.078651785850525 | Validation Loss: 1.0855330228805542\n",
            "Train Loss at iteration 507: 1.0878958702087402 | Validation Loss: 1.0844272375106812\n",
            "Train Loss at iteration 508: 1.0620262622833252 | Validation Loss: 1.0643761157989502\n",
            "Train Loss at iteration 509: 1.077141523361206 | Validation Loss: 1.065064549446106\n",
            "Train Loss at iteration 510: 1.0690407752990723 | Validation Loss: 1.0932368040084839\n",
            "Train Loss at iteration 511: 1.0632480382919312 | Validation Loss: 1.0824135541915894\n",
            "Train Loss at iteration 512: 1.090842604637146 | Validation Loss: 1.08749258518219\n",
            "Train Loss at iteration 513: 1.0745879411697388 | Validation Loss: 1.0789260864257812\n",
            "Train Loss at iteration 514: 1.0708715915679932 | Validation Loss: 1.0847491025924683\n",
            "Train Loss at iteration 515: 1.070472002029419 | Validation Loss: 1.0756992101669312\n",
            "Train Loss at iteration 516: 1.070618748664856 | Validation Loss: 1.0926305055618286\n",
            "Train Loss at iteration 517: 1.0967628955841064 | Validation Loss: 1.0923134088516235\n",
            "Train Loss at iteration 518: 1.086612582206726 | Validation Loss: 1.0968565940856934\n",
            "Train Loss at iteration 519: 1.0526976585388184 | Validation Loss: 1.1027123928070068\n",
            "Train Loss at iteration 520: 1.0662509202957153 | Validation Loss: 1.08242928981781\n",
            "Train Loss at iteration 521: 1.0825417041778564 | Validation Loss: 1.061642050743103\n",
            "Train Loss at iteration 522: 1.0807627439498901 | Validation Loss: 1.0751550197601318\n",
            "Train Loss at iteration 523: 1.078086256980896 | Validation Loss: 1.084063172340393\n",
            "Train Loss at iteration 524: 1.0845173597335815 | Validation Loss: 1.0925883054733276\n",
            "Train Loss at iteration 525: 1.0538973808288574 | Validation Loss: 1.0773605108261108\n",
            "Train Loss at iteration 526: 1.0526115894317627 | Validation Loss: 1.0701463222503662\n",
            "Train Loss at iteration 527: 1.078452229499817 | Validation Loss: 1.0698201656341553\n",
            "Train Loss at iteration 528: 1.0930004119873047 | Validation Loss: 1.0898319482803345\n",
            "Train Loss at iteration 529: 1.084021806716919 | Validation Loss: 1.0787866115570068\n",
            "Train Loss at iteration 530: 1.0833073854446411 | Validation Loss: 1.0839956998825073\n",
            "Train Loss at iteration 531: 1.072938084602356 | Validation Loss: 1.064523696899414\n",
            "Train Loss at iteration 532: 1.0752216577529907 | Validation Loss: 1.0819132328033447\n",
            "Train Loss at iteration 533: 1.0623743534088135 | Validation Loss: 1.0673205852508545\n",
            "Train Loss at iteration 534: 1.0699255466461182 | Validation Loss: 1.091902494430542\n",
            "Train Loss at iteration 535: 1.0793852806091309 | Validation Loss: 1.0790570974349976\n",
            "Train Loss at iteration 536: 1.0692145824432373 | Validation Loss: 1.074436902999878\n",
            "Train Loss at iteration 537: 1.077060341835022 | Validation Loss: 1.0718536376953125\n",
            "Train Loss at iteration 538: 1.0798202753067017 | Validation Loss: 1.0799500942230225\n",
            "Train Loss at iteration 539: 1.0822620391845703 | Validation Loss: 1.079576849937439\n",
            "Train Loss at iteration 540: 1.0739996433258057 | Validation Loss: 1.084607720375061\n",
            "Train Loss at iteration 541: 1.0817071199417114 | Validation Loss: 1.0753339529037476\n",
            "Train Loss at iteration 542: 1.0819413661956787 | Validation Loss: 1.08567476272583\n",
            "Train Loss at iteration 543: 1.0816274881362915 | Validation Loss: 1.0759297609329224\n",
            "Train Loss at iteration 544: 1.077783226966858 | Validation Loss: 1.069049596786499\n",
            "Train Loss at iteration 545: 1.0622315406799316 | Validation Loss: 1.0875712633132935\n",
            "Train Loss at iteration 546: 1.0788283348083496 | Validation Loss: 1.0838209390640259\n",
            "Train Loss at iteration 547: 1.0719224214553833 | Validation Loss: 1.065985083580017\n",
            "Train Loss at iteration 548: 1.0755953788757324 | Validation Loss: 1.0732100009918213\n",
            "Train Loss at iteration 549: 1.0670989751815796 | Validation Loss: 1.077821969985962\n",
            "Train Loss at iteration 550: 1.0773502588272095 | Validation Loss: 1.0838730335235596\n",
            "Train Loss at iteration 551: 1.0704562664031982 | Validation Loss: 1.0672097206115723\n",
            "Train Loss at iteration 552: 1.0644612312316895 | Validation Loss: 1.0833708047866821\n",
            "Train Loss at iteration 553: 1.0711934566497803 | Validation Loss: 1.080432415008545\n",
            "Train Loss at iteration 554: 1.064287781715393 | Validation Loss: 1.083321452140808\n",
            "Train Loss at iteration 555: 1.0682144165039062 | Validation Loss: 1.066188097000122\n",
            "Train Loss at iteration 556: 1.0631366968154907 | Validation Loss: 1.0778127908706665\n",
            "Train Loss at iteration 557: 1.0638047456741333 | Validation Loss: 1.0849419832229614\n",
            "Train Loss at iteration 558: 1.0569956302642822 | Validation Loss: 1.0920101404190063\n",
            "Train Loss at iteration 559: 1.0675760507583618 | Validation Loss: 1.1004003286361694\n",
            "Train Loss at iteration 560: 1.0684984922409058 | Validation Loss: 1.0688092708587646\n",
            "Train Loss at iteration 561: 1.0591421127319336 | Validation Loss: 1.085354208946228\n",
            "Train Loss at iteration 562: 1.0841668844223022 | Validation Loss: 1.0870946645736694\n",
            "Train Loss at iteration 563: 1.0696768760681152 | Validation Loss: 1.0829977989196777\n",
            "Train Loss at iteration 564: 1.0666372776031494 | Validation Loss: 1.0892423391342163\n",
            "Train Loss at iteration 565: 1.0571025609970093 | Validation Loss: 1.0848244428634644\n",
            "Train Loss at iteration 566: 1.0685782432556152 | Validation Loss: 1.0777631998062134\n",
            "Train Loss at iteration 567: 1.0886541604995728 | Validation Loss: 1.0680856704711914\n",
            "Train Loss at iteration 568: 1.0770586729049683 | Validation Loss: 1.0875623226165771\n",
            "Train Loss at iteration 569: 1.0695713758468628 | Validation Loss: 1.0725419521331787\n",
            "Train Loss at iteration 570: 1.0670462846755981 | Validation Loss: 1.0828354358673096\n",
            "Train Loss at iteration 571: 1.0691112279891968 | Validation Loss: 1.07450532913208\n",
            "Train Loss at iteration 572: 1.0585514307022095 | Validation Loss: 1.0875513553619385\n",
            "Train Loss at iteration 573: 1.0548782348632812 | Validation Loss: 1.077380895614624\n",
            "Train Loss at iteration 574: 1.055793046951294 | Validation Loss: 1.0614813566207886\n",
            "Train Loss at iteration 575: 1.0512551069259644 | Validation Loss: 1.0935081243515015\n",
            "Train Loss at iteration 576: 1.0795024633407593 | Validation Loss: 1.0704891681671143\n",
            "Train Loss at iteration 577: 1.0714788436889648 | Validation Loss: 1.0546642541885376\n",
            "Train Loss at iteration 578: 1.0568559169769287 | Validation Loss: 1.082868218421936\n",
            "Train Loss at iteration 579: 1.0686053037643433 | Validation Loss: 1.0579808950424194\n",
            "Train Loss at iteration 580: 1.0610889196395874 | Validation Loss: 1.0579204559326172\n",
            "Train Loss at iteration 581: 1.0704691410064697 | Validation Loss: 1.0725860595703125\n",
            "Train Loss at iteration 582: 1.06754732131958 | Validation Loss: 1.0927823781967163\n",
            "Train Loss at iteration 583: 1.0679372549057007 | Validation Loss: 1.071000337600708\n",
            "Train Loss at iteration 584: 1.070528507232666 | Validation Loss: 1.0777039527893066\n",
            "Train Loss at iteration 585: 1.0642776489257812 | Validation Loss: 1.092392086982727\n",
            "Train Loss at iteration 586: 1.0677940845489502 | Validation Loss: 1.062024712562561\n",
            "Train Loss at iteration 587: 1.059752106666565 | Validation Loss: 1.0711649656295776\n",
            "Train Loss at iteration 588: 1.0652265548706055 | Validation Loss: 1.0816447734832764\n",
            "Train Loss at iteration 589: 1.0602675676345825 | Validation Loss: 1.0750659704208374\n",
            "Train Loss at iteration 590: 1.0931674242019653 | Validation Loss: 1.0736570358276367\n",
            "Train Loss at iteration 591: 1.0693378448486328 | Validation Loss: 1.0995393991470337\n",
            "Train Loss at iteration 592: 1.0595176219940186 | Validation Loss: 1.073568344116211\n",
            "Train Loss at iteration 593: 1.0593332052230835 | Validation Loss: 1.068730354309082\n",
            "Train Loss at iteration 594: 1.0728837251663208 | Validation Loss: 1.0718790292739868\n",
            "Train Loss at iteration 595: 1.0912176370620728 | Validation Loss: 1.0838673114776611\n",
            "Train Loss at iteration 596: 1.0736303329467773 | Validation Loss: 1.0709576606750488\n",
            "Train Loss at iteration 597: 1.080875277519226 | Validation Loss: 1.0832726955413818\n",
            "Train Loss at iteration 598: 1.0523273944854736 | Validation Loss: 1.0858010053634644\n",
            "Train Loss at iteration 599: 1.056890845298767 | Validation Loss: 1.0526349544525146\n",
            "Train Loss at iteration 600: 1.0741913318634033 | Validation Loss: 1.0915937423706055\n",
            "Train Loss at iteration 601: 1.0636941194534302 | Validation Loss: 1.090575933456421\n",
            "Train Loss at iteration 602: 1.0639512538909912 | Validation Loss: 1.0835822820663452\n",
            "Train Loss at iteration 603: 1.0474039316177368 | Validation Loss: 1.0727766752243042\n",
            "Train Loss at iteration 604: 1.0469292402267456 | Validation Loss: 1.0905035734176636\n",
            "Train Loss at iteration 605: 1.0683180093765259 | Validation Loss: 1.088409185409546\n",
            "Train Loss at iteration 606: 1.0647118091583252 | Validation Loss: 1.0747992992401123\n",
            "Train Loss at iteration 607: 1.0478254556655884 | Validation Loss: 1.07949697971344\n",
            "Train Loss at iteration 608: 1.0730953216552734 | Validation Loss: 1.062309980392456\n",
            "Train Loss at iteration 609: 1.050644874572754 | Validation Loss: 1.09235417842865\n",
            "Train Loss at iteration 610: 1.086798906326294 | Validation Loss: 1.0835154056549072\n",
            "Train Loss at iteration 611: 1.0387581586837769 | Validation Loss: 1.0917013883590698\n",
            "Train Loss at iteration 612: 1.0645006895065308 | Validation Loss: 1.076237678527832\n",
            "Train Loss at iteration 613: 1.0878726243972778 | Validation Loss: 1.0822819471359253\n",
            "Train Loss at iteration 614: 1.080729365348816 | Validation Loss: 1.0612800121307373\n",
            "Train Loss at iteration 615: 1.080068588256836 | Validation Loss: 1.102656602859497\n",
            "Train Loss at iteration 616: 1.0662363767623901 | Validation Loss: 1.0562657117843628\n",
            "Train Loss at iteration 617: 1.063884973526001 | Validation Loss: 1.0807677507400513\n",
            "Train Loss at iteration 618: 1.0756932497024536 | Validation Loss: 1.0614888668060303\n",
            "Train Loss at iteration 619: 1.0518301725387573 | Validation Loss: 1.077314853668213\n",
            "Train Loss at iteration 620: 1.0556285381317139 | Validation Loss: 1.0651195049285889\n",
            "Train Loss at iteration 621: 1.0583140850067139 | Validation Loss: 1.077713131904602\n",
            "Train Loss at iteration 622: 1.0830342769622803 | Validation Loss: 1.0448322296142578\n",
            "Train Loss at iteration 623: 1.0360549688339233 | Validation Loss: 1.0548622608184814\n",
            "Train Loss at iteration 624: 1.0593478679656982 | Validation Loss: 1.0704457759857178\n",
            "Train Loss at iteration 625: 1.0703078508377075 | Validation Loss: 1.0579310655593872\n",
            "Train Loss at iteration 626: 1.0723607540130615 | Validation Loss: 1.0538333654403687\n",
            "Train Loss at iteration 627: 1.0796658992767334 | Validation Loss: 1.0839579105377197\n",
            "Train Loss at iteration 628: 1.0649555921554565 | Validation Loss: 1.079620599746704\n",
            "Train Loss at iteration 629: 1.0780060291290283 | Validation Loss: 1.0726770162582397\n",
            "Train Loss at iteration 630: 1.0580755472183228 | Validation Loss: 1.0439521074295044\n",
            "Train Loss at iteration 631: 1.0546629428863525 | Validation Loss: 1.0781148672103882\n",
            "Train Loss at iteration 632: 1.054697871208191 | Validation Loss: 1.0842393636703491\n",
            "Train Loss at iteration 633: 1.0567729473114014 | Validation Loss: 1.0575298070907593\n",
            "Train Loss at iteration 634: 1.061653733253479 | Validation Loss: 1.0652014017105103\n",
            "Train Loss at iteration 635: 1.0729244947433472 | Validation Loss: 1.087097406387329\n",
            "Train Loss at iteration 636: 1.0605838298797607 | Validation Loss: 1.0642648935317993\n",
            "Train Loss at iteration 637: 1.0506619215011597 | Validation Loss: 1.0892475843429565\n",
            "Train Loss at iteration 638: 1.0709985494613647 | Validation Loss: 1.0706088542938232\n",
            "Train Loss at iteration 639: 1.0527362823486328 | Validation Loss: 1.0746960639953613\n",
            "Train Loss at iteration 640: 1.0750975608825684 | Validation Loss: 1.0583736896514893\n",
            "Train Loss at iteration 641: 1.0765234231948853 | Validation Loss: 1.069155216217041\n",
            "Train Loss at iteration 642: 1.063023567199707 | Validation Loss: 1.0526096820831299\n",
            "Train Loss at iteration 643: 1.0665411949157715 | Validation Loss: 1.0866128206253052\n",
            "Train Loss at iteration 644: 1.0324375629425049 | Validation Loss: 1.0702913999557495\n",
            "Train Loss at iteration 645: 1.0478910207748413 | Validation Loss: 1.0671212673187256\n",
            "Train Loss at iteration 646: 1.0672789812088013 | Validation Loss: 1.0796425342559814\n",
            "Train Loss at iteration 647: 1.0396465063095093 | Validation Loss: 1.053734302520752\n",
            "Train Loss at iteration 648: 1.0861340761184692 | Validation Loss: 1.0655912160873413\n",
            "Train Loss at iteration 649: 1.0617996454238892 | Validation Loss: 1.0699490308761597\n",
            "Train Loss at iteration 650: 1.057267427444458 | Validation Loss: 1.0682779550552368\n",
            "Train Loss at iteration 651: 1.0556756258010864 | Validation Loss: 1.0518213510513306\n",
            "Train Loss at iteration 652: 1.0586962699890137 | Validation Loss: 1.067413568496704\n",
            "Train Loss at iteration 653: 1.0755337476730347 | Validation Loss: 1.0760197639465332\n",
            "Train Loss at iteration 654: 1.0738356113433838 | Validation Loss: 1.050182819366455\n",
            "Train Loss at iteration 655: 1.0528697967529297 | Validation Loss: 1.079129934310913\n",
            "Train Loss at iteration 656: 1.062778115272522 | Validation Loss: 1.060374140739441\n",
            "Train Loss at iteration 657: 1.0580428838729858 | Validation Loss: 1.0368142127990723\n",
            "Train Loss at iteration 658: 1.0607484579086304 | Validation Loss: 1.0705699920654297\n",
            "Train Loss at iteration 659: 1.0694249868392944 | Validation Loss: 1.087304711341858\n",
            "Train Loss at iteration 660: 1.0812581777572632 | Validation Loss: 1.0818243026733398\n",
            "Train Loss at iteration 661: 1.0708813667297363 | Validation Loss: 1.0538790225982666\n",
            "Train Loss at iteration 662: 1.0611693859100342 | Validation Loss: 1.0540988445281982\n",
            "Train Loss at iteration 663: 1.0630475282669067 | Validation Loss: 1.0620803833007812\n",
            "Train Loss at iteration 664: 1.0516653060913086 | Validation Loss: 1.0582047700881958\n",
            "Train Loss at iteration 665: 1.0489168167114258 | Validation Loss: 1.057676076889038\n",
            "Train Loss at iteration 666: 1.0722564458847046 | Validation Loss: 1.0707981586456299\n",
            "Train Loss at iteration 667: 1.0609304904937744 | Validation Loss: 1.0610440969467163\n",
            "Train Loss at iteration 668: 1.0613154172897339 | Validation Loss: 1.0788148641586304\n",
            "Train Loss at iteration 669: 1.0573532581329346 | Validation Loss: 1.0537257194519043\n",
            "Train Loss at iteration 670: 1.0478248596191406 | Validation Loss: 1.0713802576065063\n",
            "Train Loss at iteration 671: 1.0550569295883179 | Validation Loss: 1.0727403163909912\n",
            "Train Loss at iteration 672: 1.0671145915985107 | Validation Loss: 1.0716718435287476\n",
            "Train Loss at iteration 673: 1.0458979606628418 | Validation Loss: 1.0563195943832397\n",
            "Train Loss at iteration 674: 1.0599311590194702 | Validation Loss: 1.0854977369308472\n",
            "Train Loss at iteration 675: 1.0670948028564453 | Validation Loss: 1.0706989765167236\n",
            "Train Loss at iteration 676: 1.053218960762024 | Validation Loss: 1.0669236183166504\n",
            "Train Loss at iteration 677: 1.0642681121826172 | Validation Loss: 1.0738719701766968\n",
            "Train Loss at iteration 678: 1.0397752523422241 | Validation Loss: 1.0779328346252441\n",
            "Train Loss at iteration 679: 1.060276746749878 | Validation Loss: 1.0637785196304321\n",
            "Train Loss at iteration 680: 1.0602930784225464 | Validation Loss: 1.0725719928741455\n",
            "Train Loss at iteration 681: 1.0847997665405273 | Validation Loss: 1.0843833684921265\n",
            "Train Loss at iteration 682: 1.0610613822937012 | Validation Loss: 1.0708773136138916\n",
            "Train Loss at iteration 683: 1.0740528106689453 | Validation Loss: 1.0702699422836304\n",
            "Train Loss at iteration 684: 1.063803791999817 | Validation Loss: 1.0467028617858887\n",
            "Train Loss at iteration 685: 1.084297776222229 | Validation Loss: 1.0635552406311035\n",
            "Train Loss at iteration 686: 1.0812512636184692 | Validation Loss: 1.0677635669708252\n",
            "Train Loss at iteration 687: 1.0480948686599731 | Validation Loss: 1.0811370611190796\n",
            "Train Loss at iteration 688: 1.0693637132644653 | Validation Loss: 1.0709340572357178\n",
            "Train Loss at iteration 689: 1.0652168989181519 | Validation Loss: 1.0635002851486206\n",
            "Train Loss at iteration 690: 1.0540848970413208 | Validation Loss: 1.055207371711731\n",
            "Train Loss at iteration 691: 1.0761741399765015 | Validation Loss: 1.0603660345077515\n",
            "Train Loss at iteration 692: 1.09520423412323 | Validation Loss: 1.0833172798156738\n",
            "Train Loss at iteration 693: 1.0732916593551636 | Validation Loss: 1.0730992555618286\n",
            "Train Loss at iteration 694: 1.0627719163894653 | Validation Loss: 1.0309975147247314\n",
            "Train Loss at iteration 695: 1.0424916744232178 | Validation Loss: 1.0599586963653564\n",
            "Train Loss at iteration 696: 1.0731605291366577 | Validation Loss: 1.0591756105422974\n",
            "Train Loss at iteration 697: 1.0712289810180664 | Validation Loss: 1.0735808610916138\n",
            "Train Loss at iteration 698: 1.081937551498413 | Validation Loss: 1.06769859790802\n",
            "Train Loss at iteration 699: 1.0844424962997437 | Validation Loss: 1.0688120126724243\n",
            "Train Loss at iteration 700: 1.05666184425354 | Validation Loss: 1.0917681455612183\n",
            "Train Loss at iteration 701: 1.0592262744903564 | Validation Loss: 1.0506386756896973\n",
            "Train Loss at iteration 702: 1.0706932544708252 | Validation Loss: 1.06476628780365\n",
            "Train Loss at iteration 703: 1.0641582012176514 | Validation Loss: 1.0758287906646729\n",
            "Train Loss at iteration 704: 1.044904112815857 | Validation Loss: 1.0694217681884766\n",
            "Train Loss at iteration 705: 1.0484809875488281 | Validation Loss: 1.0654206275939941\n",
            "Train Loss at iteration 706: 1.049225091934204 | Validation Loss: 1.0548268556594849\n",
            "Train Loss at iteration 707: 1.0790526866912842 | Validation Loss: 1.0497658252716064\n",
            "Train Loss at iteration 708: 1.0710290670394897 | Validation Loss: 1.067137598991394\n",
            "Train Loss at iteration 709: 1.072807788848877 | Validation Loss: 1.0713247060775757\n",
            "Train Loss at iteration 710: 1.0528258085250854 | Validation Loss: 1.0929663181304932\n",
            "Train Loss at iteration 711: 1.0627716779708862 | Validation Loss: 1.0455322265625\n",
            "Train Loss at iteration 712: 1.044110655784607 | Validation Loss: 1.0710043907165527\n",
            "Train Loss at iteration 713: 1.056979775428772 | Validation Loss: 1.0377331972122192\n",
            "Train Loss at iteration 714: 1.0626345872879028 | Validation Loss: 1.0595088005065918\n",
            "Train Loss at iteration 715: 1.064609408378601 | Validation Loss: 1.0598880052566528\n",
            "Train Loss at iteration 716: 1.057020902633667 | Validation Loss: 1.0302263498306274\n",
            "Train Loss at iteration 717: 1.0865623950958252 | Validation Loss: 1.0730111598968506\n",
            "Train Loss at iteration 718: 1.064103364944458 | Validation Loss: 1.0851619243621826\n",
            "Train Loss at iteration 719: 1.060249924659729 | Validation Loss: 1.0454716682434082\n",
            "Train Loss at iteration 720: 1.0644546747207642 | Validation Loss: 1.0589747428894043\n",
            "Train Loss at iteration 721: 1.077260971069336 | Validation Loss: 1.0853348970413208\n",
            "Train Loss at iteration 722: 1.0486953258514404 | Validation Loss: 1.0519921779632568\n",
            "Train Loss at iteration 723: 1.0635606050491333 | Validation Loss: 1.0647467374801636\n",
            "Train Loss at iteration 724: 1.0605374574661255 | Validation Loss: 1.093248963356018\n",
            "Train Loss at iteration 725: 1.0700567960739136 | Validation Loss: 1.071425199508667\n",
            "Train Loss at iteration 726: 1.0620301961898804 | Validation Loss: 1.0654124021530151\n",
            "Train Loss at iteration 727: 1.0415396690368652 | Validation Loss: 1.0683573484420776\n",
            "Train Loss at iteration 728: 1.039331078529358 | Validation Loss: 1.0656174421310425\n",
            "Train Loss at iteration 729: 1.0732132196426392 | Validation Loss: 1.078018069267273\n",
            "Train Loss at iteration 730: 1.0386720895767212 | Validation Loss: 1.0408674478530884\n",
            "Train Loss at iteration 731: 1.0427627563476562 | Validation Loss: 1.0609062910079956\n",
            "Train Loss at iteration 732: 1.049353003501892 | Validation Loss: 1.0578755140304565\n",
            "Train Loss at iteration 733: 1.0785313844680786 | Validation Loss: 1.030014991760254\n",
            "Train Loss at iteration 734: 1.064554214477539 | Validation Loss: 1.0442713499069214\n",
            "Train Loss at iteration 735: 1.0457181930541992 | Validation Loss: 1.061880111694336\n",
            "Train Loss at iteration 736: 1.0449918508529663 | Validation Loss: 1.0458170175552368\n",
            "Train Loss at iteration 737: 1.054885745048523 | Validation Loss: 1.0569528341293335\n",
            "Train Loss at iteration 738: 1.0550252199172974 | Validation Loss: 1.0323141813278198\n",
            "Train Loss at iteration 739: 1.046328067779541 | Validation Loss: 1.0423359870910645\n",
            "Train Loss at iteration 740: 1.0588111877441406 | Validation Loss: 1.0613981485366821\n",
            "Train Loss at iteration 741: 1.0848886966705322 | Validation Loss: 1.0786458253860474\n",
            "Train Loss at iteration 742: 1.0437060594558716 | Validation Loss: 1.0624951124191284\n",
            "Train Loss at iteration 743: 1.0447698831558228 | Validation Loss: 1.062842845916748\n",
            "Train Loss at iteration 744: 1.0699037313461304 | Validation Loss: 1.0582534074783325\n",
            "Train Loss at iteration 745: 1.0602216720581055 | Validation Loss: 1.0473889112472534\n",
            "Train Loss at iteration 746: 1.0899666547775269 | Validation Loss: 1.0719289779663086\n",
            "Train Loss at iteration 747: 1.0573126077651978 | Validation Loss: 1.0541813373565674\n",
            "Train Loss at iteration 748: 1.0473207235336304 | Validation Loss: 1.0810950994491577\n",
            "Train Loss at iteration 749: 1.0763609409332275 | Validation Loss: 1.057859182357788\n",
            "Train Loss at iteration 750: 1.0837714672088623 | Validation Loss: 1.0766280889511108\n",
            "Train Loss at iteration 751: 1.050423264503479 | Validation Loss: 1.0318914651870728\n",
            "Train Loss at iteration 752: 1.0579389333724976 | Validation Loss: 1.055267572402954\n",
            "Train Loss at iteration 753: 1.0751389265060425 | Validation Loss: 1.0553927421569824\n",
            "Train Loss at iteration 754: 1.0436490774154663 | Validation Loss: 1.074495792388916\n",
            "Train Loss at iteration 755: 1.0634042024612427 | Validation Loss: 1.0720702409744263\n",
            "Train Loss at iteration 756: 1.0333516597747803 | Validation Loss: 1.0452516078948975\n",
            "Train Loss at iteration 757: 1.0518163442611694 | Validation Loss: 1.0686513185501099\n",
            "Train Loss at iteration 758: 1.065773844718933 | Validation Loss: 1.0415765047073364\n",
            "Train Loss at iteration 759: 1.037697196006775 | Validation Loss: 1.0692417621612549\n",
            "Train Loss at iteration 760: 1.0540388822555542 | Validation Loss: 1.044320821762085\n",
            "Train Loss at iteration 761: 1.0590041875839233 | Validation Loss: 1.042885422706604\n",
            "Train Loss at iteration 762: 1.0451319217681885 | Validation Loss: 1.0552211999893188\n",
            "Train Loss at iteration 763: 1.0702800750732422 | Validation Loss: 1.0683444738388062\n",
            "Train Loss at iteration 764: 1.0400792360305786 | Validation Loss: 1.0335693359375\n",
            "Train Loss at iteration 765: 1.0697933435440063 | Validation Loss: 1.0536308288574219\n",
            "Train Loss at iteration 766: 1.0631285905838013 | Validation Loss: 1.0880993604660034\n",
            "Train Loss at iteration 767: 1.0573062896728516 | Validation Loss: 1.0783121585845947\n",
            "Train Loss at iteration 768: 1.0653504133224487 | Validation Loss: 1.066441535949707\n",
            "Train Loss at iteration 769: 1.0645724534988403 | Validation Loss: 1.0544548034667969\n",
            "Train Loss at iteration 770: 1.0847548246383667 | Validation Loss: 1.0625388622283936\n",
            "Train Loss at iteration 771: 1.0533288717269897 | Validation Loss: 1.0584195852279663\n",
            "Train Loss at iteration 772: 1.067206621170044 | Validation Loss: 1.0472040176391602\n",
            "Train Loss at iteration 773: 1.0448986291885376 | Validation Loss: 1.062840461730957\n",
            "Train Loss at iteration 774: 1.0404629707336426 | Validation Loss: 1.0435106754302979\n",
            "Train Loss at iteration 775: 1.070518970489502 | Validation Loss: 1.048571228981018\n",
            "Train Loss at iteration 776: 1.0214403867721558 | Validation Loss: 1.0570263862609863\n",
            "Train Loss at iteration 777: 1.075914740562439 | Validation Loss: 1.044981837272644\n",
            "Train Loss at iteration 778: 1.0681982040405273 | Validation Loss: 1.0361448526382446\n",
            "Train Loss at iteration 779: 1.0491578578948975 | Validation Loss: 1.0540566444396973\n",
            "Train Loss at iteration 780: 1.0348340272903442 | Validation Loss: 1.05427885055542\n",
            "Train Loss at iteration 781: 1.0701056718826294 | Validation Loss: 1.0583487749099731\n",
            "Train Loss at iteration 782: 1.072660207748413 | Validation Loss: 1.0434046983718872\n",
            "Train Loss at iteration 783: 1.0642156600952148 | Validation Loss: 1.0512186288833618\n",
            "Train Loss at iteration 784: 1.0387130975723267 | Validation Loss: 1.053805947303772\n",
            "Train Loss at iteration 785: 1.0575288534164429 | Validation Loss: 1.0553661584854126\n",
            "Train Loss at iteration 786: 1.0414098501205444 | Validation Loss: 1.0457042455673218\n",
            "Train Loss at iteration 787: 1.051377296447754 | Validation Loss: 1.0745981931686401\n",
            "Train Loss at iteration 788: 1.0462650060653687 | Validation Loss: 1.0506616830825806\n",
            "Train Loss at iteration 789: 1.0579392910003662 | Validation Loss: 1.0590075254440308\n",
            "Train Loss at iteration 790: 1.0632140636444092 | Validation Loss: 1.0790280103683472\n",
            "Train Loss at iteration 791: 1.0439891815185547 | Validation Loss: 1.0640236139297485\n",
            "Train Loss at iteration 792: 1.0647658109664917 | Validation Loss: 1.0613046884536743\n",
            "Train Loss at iteration 793: 1.054880142211914 | Validation Loss: 1.0906078815460205\n",
            "Train Loss at iteration 794: 1.0354466438293457 | Validation Loss: 1.063754916191101\n",
            "Train Loss at iteration 795: 1.0540629625320435 | Validation Loss: 1.0639443397521973\n",
            "Train Loss at iteration 796: 1.0488557815551758 | Validation Loss: 1.0511506795883179\n",
            "Train Loss at iteration 797: 1.0415592193603516 | Validation Loss: 1.044458270072937\n",
            "Train Loss at iteration 798: 1.0643478631973267 | Validation Loss: 1.0673770904541016\n",
            "Train Loss at iteration 799: 1.0466071367263794 | Validation Loss: 1.0550559759140015\n",
            "Train Loss at iteration 800: 1.0604770183563232 | Validation Loss: 1.0630890130996704\n",
            "Train Loss at iteration 801: 1.055681586265564 | Validation Loss: 1.047310709953308\n",
            "Train Loss at iteration 802: 1.045805811882019 | Validation Loss: 1.0702499151229858\n",
            "Train Loss at iteration 803: 1.0867795944213867 | Validation Loss: 1.0460681915283203\n",
            "Train Loss at iteration 804: 1.0527571439743042 | Validation Loss: 1.0608625411987305\n",
            "Train Loss at iteration 805: 1.0455496311187744 | Validation Loss: 1.044063925743103\n",
            "Train Loss at iteration 806: 1.0597970485687256 | Validation Loss: 1.072828769683838\n",
            "Train Loss at iteration 807: 1.0388418436050415 | Validation Loss: 1.0316163301467896\n",
            "Train Loss at iteration 808: 1.032309651374817 | Validation Loss: 1.055829644203186\n",
            "Train Loss at iteration 809: 1.0590564012527466 | Validation Loss: 1.0806703567504883\n",
            "Train Loss at iteration 810: 1.0597343444824219 | Validation Loss: 1.047818660736084\n",
            "Train Loss at iteration 811: 1.0542949438095093 | Validation Loss: 1.0626099109649658\n",
            "Train Loss at iteration 812: 1.051398754119873 | Validation Loss: 1.0326979160308838\n",
            "Train Loss at iteration 813: 1.0800580978393555 | Validation Loss: 1.076436996459961\n",
            "Train Loss at iteration 814: 1.0672191381454468 | Validation Loss: 1.0650955438613892\n",
            "Train Loss at iteration 815: 1.057605504989624 | Validation Loss: 1.0337777137756348\n",
            "Train Loss at iteration 816: 1.06050705909729 | Validation Loss: 1.064277172088623\n",
            "Train Loss at iteration 817: 1.063461184501648 | Validation Loss: 1.0658928155899048\n",
            "Train Loss at iteration 818: 1.0601341724395752 | Validation Loss: 1.0224827527999878\n",
            "Train Loss at iteration 819: 1.0507484674453735 | Validation Loss: 1.0477275848388672\n",
            "Train Loss at iteration 820: 1.0555839538574219 | Validation Loss: 1.030012845993042\n",
            "Train Loss at iteration 821: 1.054465889930725 | Validation Loss: 1.0563322305679321\n",
            "Train Loss at iteration 822: 1.0584423542022705 | Validation Loss: 1.0463323593139648\n",
            "Train Loss at iteration 823: 1.0561891794204712 | Validation Loss: 1.0396541357040405\n",
            "Train Loss at iteration 824: 1.0558074712753296 | Validation Loss: 1.047914743423462\n",
            "Train Loss at iteration 825: 1.059611439704895 | Validation Loss: 1.0423849821090698\n",
            "Train Loss at iteration 826: 1.0584348440170288 | Validation Loss: 1.0482921600341797\n",
            "Train Loss at iteration 827: 1.02725088596344 | Validation Loss: 1.062880277633667\n",
            "Train Loss at iteration 828: 1.0494017601013184 | Validation Loss: 1.063902497291565\n",
            "Train Loss at iteration 829: 1.0514353513717651 | Validation Loss: 1.0337867736816406\n",
            "Train Loss at iteration 830: 1.0551073551177979 | Validation Loss: 1.0478425025939941\n",
            "Train Loss at iteration 831: 1.061400055885315 | Validation Loss: 1.0676524639129639\n",
            "Train Loss at iteration 832: 1.0459920167922974 | Validation Loss: 1.0470064878463745\n",
            "Train Loss at iteration 833: 1.024011492729187 | Validation Loss: 1.0654163360595703\n",
            "Train Loss at iteration 834: 1.0255826711654663 | Validation Loss: 1.0696324110031128\n",
            "Train Loss at iteration 835: 1.0255956649780273 | Validation Loss: 1.0642050504684448\n",
            "Train Loss at iteration 836: 1.050080418586731 | Validation Loss: 1.0471186637878418\n",
            "Train Loss at iteration 837: 1.0705622434616089 | Validation Loss: 1.0520329475402832\n",
            "Train Loss at iteration 838: 1.0650614500045776 | Validation Loss: 1.0431711673736572\n",
            "Train Loss at iteration 839: 1.0405193567276 | Validation Loss: 1.0515315532684326\n",
            "Train Loss at iteration 840: 1.0438218116760254 | Validation Loss: 1.0610519647598267\n",
            "Train Loss at iteration 841: 1.0414708852767944 | Validation Loss: 1.0385715961456299\n",
            "Train Loss at iteration 842: 1.0520519018173218 | Validation Loss: 1.036055088043213\n",
            "Train Loss at iteration 843: 1.054336667060852 | Validation Loss: 1.066554307937622\n",
            "Train Loss at iteration 844: 1.0498894453048706 | Validation Loss: 1.050864815711975\n",
            "Train Loss at iteration 845: 1.06145179271698 | Validation Loss: 1.0567331314086914\n",
            "Train Loss at iteration 846: 1.0728929042816162 | Validation Loss: 1.0590094327926636\n",
            "Train Loss at iteration 847: 1.0794479846954346 | Validation Loss: 1.0180087089538574\n",
            "Train Loss at iteration 848: 1.0429154634475708 | Validation Loss: 1.0667929649353027\n",
            "Train Loss at iteration 849: 1.0977108478546143 | Validation Loss: 1.0455360412597656\n",
            "Train Loss at iteration 850: 1.0545071363449097 | Validation Loss: 1.0430488586425781\n",
            "Train Loss at iteration 851: 1.0552289485931396 | Validation Loss: 1.0561496019363403\n",
            "Train Loss at iteration 852: 1.0430151224136353 | Validation Loss: 1.0399328470230103\n",
            "Train Loss at iteration 853: 1.0747113227844238 | Validation Loss: 1.0580518245697021\n",
            "Train Loss at iteration 854: 1.0418601036071777 | Validation Loss: 1.0676600933074951\n",
            "Train Loss at iteration 855: 1.032475233078003 | Validation Loss: 1.045936107635498\n",
            "Train Loss at iteration 856: 1.0589038133621216 | Validation Loss: 1.042609453201294\n",
            "Train Loss at iteration 857: 1.078683853149414 | Validation Loss: 1.0453799962997437\n",
            "Train Loss at iteration 858: 1.0629593133926392 | Validation Loss: 1.0452585220336914\n",
            "Train Loss at iteration 859: 1.0510814189910889 | Validation Loss: 1.047997236251831\n",
            "Train Loss at iteration 860: 1.0736021995544434 | Validation Loss: 1.0792930126190186\n",
            "Train Loss at iteration 861: 1.0748447179794312 | Validation Loss: 1.038273572921753\n",
            "Train Loss at iteration 862: 1.0586925745010376 | Validation Loss: 1.0571320056915283\n",
            "Train Loss at iteration 863: 1.0372421741485596 | Validation Loss: 1.0586938858032227\n",
            "Train Loss at iteration 864: 1.051098346710205 | Validation Loss: 1.0468708276748657\n",
            "Train Loss at iteration 865: 1.0663905143737793 | Validation Loss: 1.054484248161316\n",
            "Train Loss at iteration 866: 1.065767526626587 | Validation Loss: 1.0423409938812256\n",
            "Train Loss at iteration 867: 1.0234596729278564 | Validation Loss: 1.04764723777771\n",
            "Train Loss at iteration 868: 1.0437871217727661 | Validation Loss: 1.0615489482879639\n",
            "Train Loss at iteration 869: 1.0542709827423096 | Validation Loss: 1.0471047163009644\n",
            "Train Loss at iteration 870: 1.0441538095474243 | Validation Loss: 1.050310492515564\n",
            "Train Loss at iteration 871: 1.059781551361084 | Validation Loss: 1.0519338846206665\n",
            "Train Loss at iteration 872: 1.0632716417312622 | Validation Loss: 1.0547099113464355\n",
            "Train Loss at iteration 873: 1.0806242227554321 | Validation Loss: 1.0354254245758057\n",
            "Train Loss at iteration 874: 1.0580272674560547 | Validation Loss: 1.0720728635787964\n",
            "Train Loss at iteration 875: 1.0377346277236938 | Validation Loss: 1.059010624885559\n",
            "Train Loss at iteration 876: 1.0510363578796387 | Validation Loss: 1.0689705610275269\n",
            "Train Loss at iteration 877: 1.045599102973938 | Validation Loss: 1.0806657075881958\n",
            "Train Loss at iteration 878: 1.0725446939468384 | Validation Loss: 1.052869200706482\n",
            "Train Loss at iteration 879: 1.063039779663086 | Validation Loss: 1.0574719905853271\n",
            "Train Loss at iteration 880: 1.0669939517974854 | Validation Loss: 1.0651063919067383\n",
            "Train Loss at iteration 881: 1.0342938899993896 | Validation Loss: 1.0722674131393433\n",
            "Train Loss at iteration 882: 1.0683577060699463 | Validation Loss: 1.037507176399231\n",
            "Train Loss at iteration 883: 1.0461597442626953 | Validation Loss: 1.0412020683288574\n",
            "Train Loss at iteration 884: 1.0768654346466064 | Validation Loss: 1.042163372039795\n",
            "Train Loss at iteration 885: 1.0578653812408447 | Validation Loss: 1.0531681776046753\n",
            "Train Loss at iteration 886: 1.0568859577178955 | Validation Loss: 1.054213047027588\n",
            "Train Loss at iteration 887: 1.0431150197982788 | Validation Loss: 1.0632874965667725\n",
            "Train Loss at iteration 888: 1.0562431812286377 | Validation Loss: 1.0586719512939453\n",
            "Train Loss at iteration 889: 1.0413943529129028 | Validation Loss: 1.0702719688415527\n",
            "Train Loss at iteration 890: 1.0411062240600586 | Validation Loss: 1.0633618831634521\n",
            "Train Loss at iteration 891: 1.0561009645462036 | Validation Loss: 1.0642590522766113\n",
            "Train Loss at iteration 892: 1.0470974445343018 | Validation Loss: 1.0240215063095093\n",
            "Train Loss at iteration 893: 1.0633156299591064 | Validation Loss: 1.0402318239212036\n",
            "Train Loss at iteration 894: 1.072813868522644 | Validation Loss: 1.0479600429534912\n",
            "Train Loss at iteration 895: 1.0369164943695068 | Validation Loss: 1.0553325414657593\n",
            "Train Loss at iteration 896: 1.0176949501037598 | Validation Loss: 1.0575940608978271\n",
            "Train Loss at iteration 897: 1.0276728868484497 | Validation Loss: 1.0652610063552856\n",
            "Train Loss at iteration 898: 1.0525250434875488 | Validation Loss: 1.0562363862991333\n",
            "Train Loss at iteration 899: 1.0332701206207275 | Validation Loss: 1.0468209981918335\n",
            "Train Loss at iteration 900: 1.0547319650650024 | Validation Loss: 1.050845980644226\n",
            "Train Loss at iteration 901: 1.0584535598754883 | Validation Loss: 1.0339773893356323\n",
            "Train Loss at iteration 902: 1.0531469583511353 | Validation Loss: 1.0456600189208984\n",
            "Train Loss at iteration 903: 1.0545344352722168 | Validation Loss: 1.0222243070602417\n",
            "Train Loss at iteration 904: 1.0512678623199463 | Validation Loss: 1.0849608182907104\n",
            "Train Loss at iteration 905: 1.0486263036727905 | Validation Loss: 1.048032522201538\n",
            "Train Loss at iteration 906: 1.0691120624542236 | Validation Loss: 1.0570549964904785\n",
            "Train Loss at iteration 907: 1.0639383792877197 | Validation Loss: 1.0584102869033813\n",
            "Train Loss at iteration 908: 1.0494427680969238 | Validation Loss: 1.0538313388824463\n",
            "Train Loss at iteration 909: 1.0349918603897095 | Validation Loss: 1.0609350204467773\n",
            "Train Loss at iteration 910: 1.0478166341781616 | Validation Loss: 1.068464756011963\n",
            "Train Loss at iteration 911: 1.069082260131836 | Validation Loss: 1.0416901111602783\n",
            "Train Loss at iteration 912: 1.028490662574768 | Validation Loss: 1.0797537565231323\n",
            "Train Loss at iteration 913: 1.0431901216506958 | Validation Loss: 1.0554357767105103\n",
            "Train Loss at iteration 914: 1.0598663091659546 | Validation Loss: 1.0352336168289185\n",
            "Train Loss at iteration 915: 1.0305312871932983 | Validation Loss: 1.0824239253997803\n",
            "Train Loss at iteration 916: 1.062118411064148 | Validation Loss: 1.0695252418518066\n",
            "Train Loss at iteration 917: 1.0666595697402954 | Validation Loss: 1.0713670253753662\n",
            "Train Loss at iteration 918: 1.0682662725448608 | Validation Loss: 1.0531185865402222\n",
            "Train Loss at iteration 919: 1.039126992225647 | Validation Loss: 1.068349838256836\n",
            "Train Loss at iteration 920: 1.042008876800537 | Validation Loss: 1.0686824321746826\n",
            "Train Loss at iteration 921: 1.0512157678604126 | Validation Loss: 1.0552303791046143\n",
            "Train Loss at iteration 922: 1.0142666101455688 | Validation Loss: 1.053262710571289\n",
            "Train Loss at iteration 923: 1.0677334070205688 | Validation Loss: 1.0362240076065063\n",
            "Train Loss at iteration 924: 1.0397406816482544 | Validation Loss: 1.0790241956710815\n",
            "Train Loss at iteration 925: 1.0570333003997803 | Validation Loss: 1.0373945236206055\n",
            "Train Loss at iteration 926: 1.0762132406234741 | Validation Loss: 1.06100594997406\n",
            "Train Loss at iteration 927: 1.032156229019165 | Validation Loss: 1.0640170574188232\n",
            "Train Loss at iteration 928: 1.051667332649231 | Validation Loss: 1.0531381368637085\n",
            "Train Loss at iteration 929: 1.048423409461975 | Validation Loss: 1.0337671041488647\n",
            "Train Loss at iteration 930: 1.0266281366348267 | Validation Loss: 1.0830718278884888\n",
            "Train Loss at iteration 931: 1.0571351051330566 | Validation Loss: 1.0512678623199463\n",
            "Train Loss at iteration 932: 1.0461252927780151 | Validation Loss: 1.026168942451477\n",
            "Train Loss at iteration 933: 1.0298733711242676 | Validation Loss: 1.0334280729293823\n",
            "Train Loss at iteration 934: 1.0414562225341797 | Validation Loss: 1.063052773475647\n",
            "Train Loss at iteration 935: 1.0506688356399536 | Validation Loss: 1.0478557348251343\n",
            "Train Loss at iteration 936: 1.0657423734664917 | Validation Loss: 1.051709771156311\n",
            "Train Loss at iteration 937: 1.0600249767303467 | Validation Loss: 1.0602281093597412\n",
            "Train Loss at iteration 938: 1.0541123151779175 | Validation Loss: 1.04677152633667\n",
            "Train Loss at iteration 939: 1.0485111474990845 | Validation Loss: 1.035058617591858\n",
            "Train Loss at iteration 940: 1.0597895383834839 | Validation Loss: 1.0653233528137207\n",
            "Train Loss at iteration 941: 1.0469954013824463 | Validation Loss: 1.022157073020935\n",
            "Train Loss at iteration 942: 1.0646928548812866 | Validation Loss: 1.0595489740371704\n",
            "Train Loss at iteration 943: 1.0673574209213257 | Validation Loss: 1.0755518674850464\n",
            "Train Loss at iteration 944: 1.0579817295074463 | Validation Loss: 1.056725263595581\n",
            "Train Loss at iteration 945: 1.0546128749847412 | Validation Loss: 1.0635180473327637\n",
            "Train Loss at iteration 946: 1.047071099281311 | Validation Loss: 1.0443217754364014\n",
            "Train Loss at iteration 947: 1.0578733682632446 | Validation Loss: 1.0432562828063965\n",
            "Train Loss at iteration 948: 1.0637695789337158 | Validation Loss: 1.042744755744934\n",
            "Train Loss at iteration 949: 1.0556527376174927 | Validation Loss: 1.0462085008621216\n",
            "Train Loss at iteration 950: 1.0504757165908813 | Validation Loss: 1.0675632953643799\n",
            "Train Loss at iteration 951: 1.0417966842651367 | Validation Loss: 1.0562866926193237\n",
            "Train Loss at iteration 952: 1.0475531816482544 | Validation Loss: 1.0181697607040405\n",
            "Train Loss at iteration 953: 1.0514568090438843 | Validation Loss: 1.043258786201477\n",
            "Train Loss at iteration 954: 1.0446397066116333 | Validation Loss: 1.0425363779067993\n",
            "Train Loss at iteration 955: 1.042449712753296 | Validation Loss: 1.0469330549240112\n",
            "Train Loss at iteration 956: 1.049414873123169 | Validation Loss: 1.044374942779541\n",
            "Train Loss at iteration 957: 1.050872564315796 | Validation Loss: 1.058931827545166\n",
            "Train Loss at iteration 958: 1.0543615818023682 | Validation Loss: 1.05046546459198\n",
            "Train Loss at iteration 959: 1.0608093738555908 | Validation Loss: 1.0441193580627441\n",
            "Train Loss at iteration 960: 1.064864993095398 | Validation Loss: 1.045807957649231\n",
            "Train Loss at iteration 961: 1.0252151489257812 | Validation Loss: 1.0457074642181396\n",
            "Train Loss at iteration 962: 1.0431140661239624 | Validation Loss: 1.0574954748153687\n",
            "Train Loss at iteration 963: 1.0518896579742432 | Validation Loss: 1.0459245443344116\n",
            "Train Loss at iteration 964: 1.0279606580734253 | Validation Loss: 1.0778757333755493\n",
            "Train Loss at iteration 965: 1.056143879890442 | Validation Loss: 1.0626240968704224\n",
            "Train Loss at iteration 966: 1.0194212198257446 | Validation Loss: 1.0385441780090332\n",
            "Train Loss at iteration 967: 1.0408819913864136 | Validation Loss: 1.0456074476242065\n",
            "Train Loss at iteration 968: 1.0467263460159302 | Validation Loss: 1.0405422449111938\n",
            "Train Loss at iteration 969: 1.0502147674560547 | Validation Loss: 1.040321707725525\n",
            "Train Loss at iteration 970: 1.0235074758529663 | Validation Loss: 1.0481163263320923\n",
            "Train Loss at iteration 971: 1.0277148485183716 | Validation Loss: 1.064644694328308\n",
            "Train Loss at iteration 972: 1.0538328886032104 | Validation Loss: 1.0398942232131958\n",
            "Train Loss at iteration 973: 1.0549122095108032 | Validation Loss: 1.0643447637557983\n",
            "Train Loss at iteration 974: 1.0524722337722778 | Validation Loss: 1.0797444581985474\n",
            "Train Loss at iteration 975: 1.0486582517623901 | Validation Loss: 1.0398902893066406\n",
            "Train Loss at iteration 976: 1.0549895763397217 | Validation Loss: 1.0424983501434326\n",
            "Train Loss at iteration 977: 1.0624396800994873 | Validation Loss: 1.0330028533935547\n",
            "Train Loss at iteration 978: 1.029292106628418 | Validation Loss: 1.038152813911438\n",
            "Train Loss at iteration 979: 1.0387920141220093 | Validation Loss: 1.0336382389068604\n",
            "Train Loss at iteration 980: 1.0296505689620972 | Validation Loss: 1.0196295976638794\n",
            "Train Loss at iteration 981: 1.0315215587615967 | Validation Loss: 1.0752358436584473\n",
            "Train Loss at iteration 982: 1.052658200263977 | Validation Loss: 1.0549534559249878\n",
            "Train Loss at iteration 983: 1.0373607873916626 | Validation Loss: 1.0774648189544678\n",
            "Train Loss at iteration 984: 1.063637614250183 | Validation Loss: 1.0435559749603271\n",
            "Train Loss at iteration 985: 1.0241042375564575 | Validation Loss: 1.0486960411071777\n",
            "Train Loss at iteration 986: 1.0669423341751099 | Validation Loss: 1.0148530006408691\n",
            "Train Loss at iteration 987: 1.013447642326355 | Validation Loss: 1.066564679145813\n",
            "Train Loss at iteration 988: 1.0364402532577515 | Validation Loss: 1.0533767938613892\n",
            "Train Loss at iteration 989: 1.059251070022583 | Validation Loss: 1.0341752767562866\n",
            "Train Loss at iteration 990: 1.0410430431365967 | Validation Loss: 1.0528312921524048\n",
            "Train Loss at iteration 991: 1.0362776517868042 | Validation Loss: 1.019784688949585\n",
            "Train Loss at iteration 992: 1.0369681119918823 | Validation Loss: 1.0642470121383667\n",
            "Train Loss at iteration 993: 1.08539879322052 | Validation Loss: 1.0460577011108398\n",
            "Train Loss at iteration 994: 1.0487335920333862 | Validation Loss: 1.0518052577972412\n",
            "Train Loss at iteration 995: 1.031404733657837 | Validation Loss: 1.0653287172317505\n",
            "Train Loss at iteration 996: 1.0522457361221313 | Validation Loss: 1.0229675769805908\n",
            "Train Loss at iteration 997: 1.0351556539535522 | Validation Loss: 1.039533257484436\n",
            "Train Loss at iteration 998: 1.0838863849639893 | Validation Loss: 1.0508142709732056\n",
            "Train Loss at iteration 999: 1.0549284219741821 | Validation Loss: 1.0491420030593872\n",
            "Train Loss at iteration 1000: 1.0759317874908447 | Validation Loss: 1.065206527709961\n",
            "Train Loss at iteration 1001: 1.0435296297073364 | Validation Loss: 1.0635325908660889\n",
            "Train Loss at iteration 1002: 1.0352555513381958 | Validation Loss: 1.0287374258041382\n",
            "Train Loss at iteration 1003: 1.0495898723602295 | Validation Loss: 1.0587208271026611\n",
            "Train Loss at iteration 1004: 1.0192071199417114 | Validation Loss: 1.0405843257904053\n",
            "Train Loss at iteration 1005: 1.0592666864395142 | Validation Loss: 1.0413769483566284\n",
            "Train Loss at iteration 1006: 1.0491591691970825 | Validation Loss: 1.0248929262161255\n",
            "Train Loss at iteration 1007: 1.059932827949524 | Validation Loss: 1.0354666709899902\n",
            "Train Loss at iteration 1008: 1.0553615093231201 | Validation Loss: 1.069486379623413\n",
            "Train Loss at iteration 1009: 1.0441888570785522 | Validation Loss: 1.0379093885421753\n",
            "Train Loss at iteration 1010: 1.0697003602981567 | Validation Loss: 1.0493675470352173\n",
            "Train Loss at iteration 1011: 1.0320026874542236 | Validation Loss: 1.042433500289917\n",
            "Train Loss at iteration 1012: 1.0468199253082275 | Validation Loss: 1.0570954084396362\n",
            "Train Loss at iteration 1013: 1.0382156372070312 | Validation Loss: 1.0222711563110352\n",
            "Train Loss at iteration 1014: 1.021968960762024 | Validation Loss: 1.0313867330551147\n",
            "Train Loss at iteration 1015: 1.0227563381195068 | Validation Loss: 1.0611249208450317\n",
            "Train Loss at iteration 1016: 1.0529534816741943 | Validation Loss: 1.0595738887786865\n",
            "Train Loss at iteration 1017: 1.0543946027755737 | Validation Loss: 1.0338728427886963\n",
            "Train Loss at iteration 1018: 1.0612385272979736 | Validation Loss: 1.0769034624099731\n",
            "Train Loss at iteration 1019: 1.0567514896392822 | Validation Loss: 1.061475157737732\n",
            "Train Loss at iteration 1020: 1.061545968055725 | Validation Loss: 1.064089059829712\n",
            "Train Loss at iteration 1021: 1.0503488779067993 | Validation Loss: 1.049776315689087\n",
            "Train Loss at iteration 1022: 1.0357328653335571 | Validation Loss: 1.0414173603057861\n",
            "Train Loss at iteration 1023: 1.0393599271774292 | Validation Loss: 1.0622020959854126\n",
            "Train Loss at iteration 1024: 1.051314353942871 | Validation Loss: 1.0430376529693604\n",
            "Train Loss at iteration 1025: 1.077354073524475 | Validation Loss: 1.034278392791748\n",
            "Train Loss at iteration 1026: 1.025209903717041 | Validation Loss: 1.0492281913757324\n",
            "Train Loss at iteration 1027: 1.0352708101272583 | Validation Loss: 1.0239498615264893\n",
            "Train Loss at iteration 1028: 1.072941541671753 | Validation Loss: 1.032312035560608\n",
            "Train Loss at iteration 1029: 1.0398073196411133 | Validation Loss: 1.0506209135055542\n",
            "Train Loss at iteration 1030: 1.063805103302002 | Validation Loss: 1.041401982307434\n",
            "Train Loss at iteration 1031: 1.055027961730957 | Validation Loss: 1.0179409980773926\n",
            "Train Loss at iteration 1032: 1.040413737297058 | Validation Loss: 1.0267386436462402\n",
            "Train Loss at iteration 1033: 1.0348849296569824 | Validation Loss: 1.0616954565048218\n",
            "Train Loss at iteration 1034: 1.0394330024719238 | Validation Loss: 1.046007513999939\n",
            "Train Loss at iteration 1035: 1.0359936952590942 | Validation Loss: 1.0400623083114624\n",
            "Train Loss at iteration 1036: 1.051634669303894 | Validation Loss: 1.06863534450531\n",
            "Train Loss at iteration 1037: 1.0565041303634644 | Validation Loss: 1.0451884269714355\n",
            "Train Loss at iteration 1038: 1.0176351070404053 | Validation Loss: 1.0658658742904663\n",
            "Train Loss at iteration 1039: 1.0494272708892822 | Validation Loss: 1.067229986190796\n",
            "Train Loss at iteration 1040: 1.07688307762146 | Validation Loss: 1.0098062753677368\n",
            "Train Loss at iteration 1041: 1.055088758468628 | Validation Loss: 1.0400434732437134\n",
            "Train Loss at iteration 1042: 1.054415225982666 | Validation Loss: 1.0561147928237915\n",
            "Train Loss at iteration 1043: 1.022449016571045 | Validation Loss: 1.0524719953536987\n",
            "Train Loss at iteration 1044: 1.0233078002929688 | Validation Loss: 1.0670182704925537\n",
            "Train Loss at iteration 1045: 1.052422046661377 | Validation Loss: 1.0575294494628906\n",
            "Train Loss at iteration 1046: 1.0474592447280884 | Validation Loss: 1.0662325620651245\n",
            "Train Loss at iteration 1047: 1.0254467725753784 | Validation Loss: 1.0600913763046265\n",
            "Train Loss at iteration 1048: 1.0324680805206299 | Validation Loss: 1.0729371309280396\n",
            "Train Loss at iteration 1049: 1.0522971153259277 | Validation Loss: 1.0643137693405151\n",
            "Train Loss at iteration 1050: 1.055277705192566 | Validation Loss: 1.0744330883026123\n",
            "Train Loss at iteration 1051: 1.0542808771133423 | Validation Loss: 1.0831007957458496\n",
            "Train Loss at iteration 1052: 1.0598335266113281 | Validation Loss: 1.0445735454559326\n",
            "Train Loss at iteration 1053: 1.0583174228668213 | Validation Loss: 1.047594666481018\n",
            "Train Loss at iteration 1054: 1.0410293340682983 | Validation Loss: 1.0408633947372437\n",
            "Train Loss at iteration 1055: 1.055569052696228 | Validation Loss: 1.043269157409668\n",
            "Train Loss at iteration 1056: 1.0688819885253906 | Validation Loss: 1.0722044706344604\n",
            "Train Loss at iteration 1057: 1.0460413694381714 | Validation Loss: 1.0430999994277954\n",
            "Train Loss at iteration 1058: 1.0617116689682007 | Validation Loss: 1.0447853803634644\n",
            "Train Loss at iteration 1059: 1.0445865392684937 | Validation Loss: 1.0376513004302979\n",
            "Train Loss at iteration 1060: 1.0158908367156982 | Validation Loss: 1.0623300075531006\n",
            "Train Loss at iteration 1061: 1.0294032096862793 | Validation Loss: 1.05142080783844\n",
            "Train Loss at iteration 1062: 1.0809704065322876 | Validation Loss: 1.0389078855514526\n",
            "Train Loss at iteration 1063: 1.0377366542816162 | Validation Loss: 1.0619150400161743\n",
            "Train Loss at iteration 1064: 1.038155436515808 | Validation Loss: 1.0275657176971436\n",
            "Train Loss at iteration 1065: 1.0469993352890015 | Validation Loss: 1.0317716598510742\n",
            "Train Loss at iteration 1066: 1.0692671537399292 | Validation Loss: 1.0643253326416016\n",
            "Train Loss at iteration 1067: 1.0798487663269043 | Validation Loss: 1.0296883583068848\n",
            "Train Loss at iteration 1068: 1.0169541835784912 | Validation Loss: 1.0386483669281006\n",
            "Train Loss at iteration 1069: 1.0737090110778809 | Validation Loss: 1.056209683418274\n",
            "Train Loss at iteration 1070: 1.0610625743865967 | Validation Loss: 1.0529675483703613\n",
            "Train Loss at iteration 1071: 1.0637670755386353 | Validation Loss: 1.0639474391937256\n",
            "Train Loss at iteration 1072: 1.018890619277954 | Validation Loss: 1.0430923700332642\n",
            "Train Loss at iteration 1073: 1.0549533367156982 | Validation Loss: 1.0456881523132324\n",
            "Train Loss at iteration 1074: 1.0358079671859741 | Validation Loss: 1.0892937183380127\n",
            "Train Loss at iteration 1075: 1.0235317945480347 | Validation Loss: 1.065412163734436\n",
            "Train Loss at iteration 1076: 1.0159480571746826 | Validation Loss: 1.0421357154846191\n",
            "Train Loss at iteration 1077: 1.0408527851104736 | Validation Loss: 1.0222187042236328\n",
            "Train Loss at iteration 1078: 1.0678530931472778 | Validation Loss: 1.0655608177185059\n",
            "Train Loss at iteration 1079: 1.0565956830978394 | Validation Loss: 1.018910527229309\n",
            "Train Loss at iteration 1080: 1.080283761024475 | Validation Loss: 1.0254677534103394\n",
            "Train Loss at iteration 1081: 1.0462528467178345 | Validation Loss: 1.0699206590652466\n",
            "Train Loss at iteration 1082: 1.0454521179199219 | Validation Loss: 1.0635706186294556\n",
            "Train Loss at iteration 1083: 1.0139886140823364 | Validation Loss: 1.0498019456863403\n",
            "Train Loss at iteration 1084: 1.0122114419937134 | Validation Loss: 1.0478405952453613\n",
            "Train Loss at iteration 1085: 1.037306785583496 | Validation Loss: 1.0055038928985596\n",
            "Train Loss at iteration 1086: 1.0510286092758179 | Validation Loss: 1.0463671684265137\n",
            "Train Loss at iteration 1087: 1.0650691986083984 | Validation Loss: 1.0486218929290771\n",
            "Train Loss at iteration 1088: 1.038761019706726 | Validation Loss: 1.0742442607879639\n",
            "Train Loss at iteration 1089: 1.0532580614089966 | Validation Loss: 1.026824951171875\n",
            "Train Loss at iteration 1090: 1.0709655284881592 | Validation Loss: 1.053123950958252\n",
            "Train Loss at iteration 1091: 1.0250699520111084 | Validation Loss: 1.052419662475586\n",
            "Train Loss at iteration 1092: 1.0518654584884644 | Validation Loss: 1.0641436576843262\n",
            "Train Loss at iteration 1093: 1.0472205877304077 | Validation Loss: 1.0358091592788696\n",
            "Train Loss at iteration 1094: 1.0153156518936157 | Validation Loss: 1.0388219356536865\n",
            "Train Loss at iteration 1095: 1.0528312921524048 | Validation Loss: 1.0613954067230225\n",
            "Train Loss at iteration 1096: 1.0636812448501587 | Validation Loss: 1.0273500680923462\n",
            "Train Loss at iteration 1097: 1.0577597618103027 | Validation Loss: 1.0405521392822266\n",
            "Train Loss at iteration 1098: 1.0547202825546265 | Validation Loss: 1.0667369365692139\n",
            "Train Loss at iteration 1099: 1.0476443767547607 | Validation Loss: 1.0353199243545532\n",
            "Train Loss at iteration 1100: 1.0517971515655518 | Validation Loss: 1.0400289297103882\n",
            "Train Loss at iteration 1101: 1.0343189239501953 | Validation Loss: 1.0643328428268433\n",
            "Train Loss at iteration 1102: 1.0408064126968384 | Validation Loss: 1.03887140750885\n",
            "Train Loss at iteration 1103: 1.0326507091522217 | Validation Loss: 1.0353562831878662\n",
            "Train Loss at iteration 1104: 1.0430991649627686 | Validation Loss: 1.0520639419555664\n",
            "Train Loss at iteration 1105: 1.0417299270629883 | Validation Loss: 1.061862826347351\n",
            "Train Loss at iteration 1106: 1.0319485664367676 | Validation Loss: 1.0384576320648193\n",
            "Train Loss at iteration 1107: 1.0239442586898804 | Validation Loss: 1.0464434623718262\n",
            "Train Loss at iteration 1108: 1.0249780416488647 | Validation Loss: 1.0387463569641113\n",
            "Train Loss at iteration 1109: 1.067183017730713 | Validation Loss: 1.0603622198104858\n",
            "Train Loss at iteration 1110: 1.0563384294509888 | Validation Loss: 1.0610047578811646\n",
            "Train Loss at iteration 1111: 1.025858759880066 | Validation Loss: 1.0338817834854126\n",
            "Train Loss at iteration 1112: 1.0337417125701904 | Validation Loss: 1.023520588874817\n",
            "Train Loss at iteration 1113: 1.0559638738632202 | Validation Loss: 1.0115571022033691\n",
            "Train Loss at iteration 1114: 1.0386817455291748 | Validation Loss: 1.0598971843719482\n",
            "Train Loss at iteration 1115: 1.013567328453064 | Validation Loss: 1.0506004095077515\n",
            "Train Loss at iteration 1116: 1.0506876707077026 | Validation Loss: 1.0476765632629395\n",
            "Train Loss at iteration 1117: 1.0236055850982666 | Validation Loss: 1.0400192737579346\n",
            "Train Loss at iteration 1118: 1.0536446571350098 | Validation Loss: 1.0396546125411987\n",
            "Train Loss at iteration 1119: 1.0136570930480957 | Validation Loss: 1.0349355936050415\n",
            "Train Loss at iteration 1120: 1.0384068489074707 | Validation Loss: 1.048492431640625\n",
            "Train Loss at iteration 1121: 1.0446511507034302 | Validation Loss: 1.0336809158325195\n",
            "Train Loss at iteration 1122: 1.042117953300476 | Validation Loss: 1.0429904460906982\n",
            "Train Loss at iteration 1123: 1.0460119247436523 | Validation Loss: 1.0165703296661377\n",
            "Train Loss at iteration 1124: 1.061106562614441 | Validation Loss: 1.0465840101242065\n",
            "Train Loss at iteration 1125: 1.0273406505584717 | Validation Loss: 1.0731652975082397\n",
            "Train Loss at iteration 1126: 1.0239733457565308 | Validation Loss: 1.0080708265304565\n",
            "Train Loss at iteration 1127: 1.0535304546356201 | Validation Loss: 1.049569845199585\n",
            "Train Loss at iteration 1128: 1.0278198719024658 | Validation Loss: 1.0411769151687622\n",
            "Train Loss at iteration 1129: 1.0571781396865845 | Validation Loss: 1.0318031311035156\n",
            "Train Loss at iteration 1130: 1.0585510730743408 | Validation Loss: 1.0571048259735107\n",
            "Train Loss at iteration 1131: 1.0450695753097534 | Validation Loss: 1.0780727863311768\n",
            "Train Loss at iteration 1132: 1.0649876594543457 | Validation Loss: 1.0530500411987305\n",
            "Train Loss at iteration 1133: 1.0395408868789673 | Validation Loss: 1.049767255783081\n",
            "Train Loss at iteration 1134: 1.079129934310913 | Validation Loss: 1.0765749216079712\n",
            "Train Loss at iteration 1135: 1.04073965549469 | Validation Loss: 1.068713665008545\n",
            "Train Loss at iteration 1136: 1.063715934753418 | Validation Loss: 1.0670610666275024\n",
            "Train Loss at iteration 1137: 1.0622484683990479 | Validation Loss: 1.03477144241333\n",
            "Train Loss at iteration 1138: 1.0868624448776245 | Validation Loss: 1.0843273401260376\n",
            "Train Loss at iteration 1139: 1.0760048627853394 | Validation Loss: 1.0584304332733154\n",
            "Train Loss at iteration 1140: 1.02222740650177 | Validation Loss: 1.052417516708374\n",
            "Train Loss at iteration 1141: 1.034704566001892 | Validation Loss: 1.0419143438339233\n",
            "Train Loss at iteration 1142: 1.0565519332885742 | Validation Loss: 1.0362434387207031\n",
            "Train Loss at iteration 1143: 1.0337787866592407 | Validation Loss: 1.0398188829421997\n",
            "Train Loss at iteration 1144: 1.0399471521377563 | Validation Loss: 1.0350408554077148\n",
            "Train Loss at iteration 1145: 1.0288441181182861 | Validation Loss: 1.0375218391418457\n",
            "Train Loss at iteration 1146: 1.046960711479187 | Validation Loss: 1.0400264263153076\n",
            "Train Loss at iteration 1147: 1.0423977375030518 | Validation Loss: 1.0384002923965454\n",
            "Train Loss at iteration 1148: 1.0566076040267944 | Validation Loss: 1.0602962970733643\n",
            "Train Loss at iteration 1149: 1.0551118850708008 | Validation Loss: 1.0725595951080322\n",
            "Train Loss at iteration 1150: 1.0276539325714111 | Validation Loss: 1.051131248474121\n",
            "Train Loss at iteration 1151: 1.050950050354004 | Validation Loss: 1.029383659362793\n",
            "Train Loss at iteration 1152: 1.0333480834960938 | Validation Loss: 1.0280119180679321\n",
            "Train Loss at iteration 1153: 1.0642472505569458 | Validation Loss: 1.0362763404846191\n",
            "Train Loss at iteration 1154: 1.036197304725647 | Validation Loss: 1.0184367895126343\n",
            "Train Loss at iteration 1155: 1.0219429731369019 | Validation Loss: 1.0393935441970825\n",
            "Train Loss at iteration 1156: 1.0401490926742554 | Validation Loss: 1.0577194690704346\n",
            "Train Loss at iteration 1157: 1.0316942930221558 | Validation Loss: 1.0672253370285034\n",
            "Train Loss at iteration 1158: 1.0571943521499634 | Validation Loss: 1.0518715381622314\n",
            "Train Loss at iteration 1159: 1.0430538654327393 | Validation Loss: 1.0799545049667358\n",
            "Train Loss at iteration 1160: 1.0234479904174805 | Validation Loss: 1.0453603267669678\n",
            "Train Loss at iteration 1161: 1.0121697187423706 | Validation Loss: 1.0742636919021606\n",
            "Train Loss at iteration 1162: 1.0413213968276978 | Validation Loss: 1.0558744668960571\n",
            "Train Loss at iteration 1163: 1.0284833908081055 | Validation Loss: 1.045060157775879\n",
            "Train Loss at iteration 1164: 1.0472322702407837 | Validation Loss: 1.0693795680999756\n",
            "Train Loss at iteration 1165: 1.0309640169143677 | Validation Loss: 1.031247854232788\n",
            "Train Loss at iteration 1166: 1.0549039840698242 | Validation Loss: 1.0282388925552368\n",
            "Train Loss at iteration 1167: 1.052644968032837 | Validation Loss: 1.0203959941864014\n",
            "Train Loss at iteration 1168: 1.0339099168777466 | Validation Loss: 1.0540564060211182\n",
            "Train Loss at iteration 1169: 1.0454246997833252 | Validation Loss: 1.0533006191253662\n",
            "Train Loss at iteration 1170: 1.0199850797653198 | Validation Loss: 1.0259441137313843\n",
            "Train Loss at iteration 1171: 1.0104193687438965 | Validation Loss: 1.0200883150100708\n",
            "Train Loss at iteration 1172: 1.0561556816101074 | Validation Loss: 1.0493206977844238\n",
            "Train Loss at iteration 1173: 1.0539631843566895 | Validation Loss: 1.052390217781067\n",
            "Train Loss at iteration 1174: 1.0471701622009277 | Validation Loss: 1.0632212162017822\n",
            "Train Loss at iteration 1175: 1.0668847560882568 | Validation Loss: 1.0562338829040527\n",
            "Train Loss at iteration 1176: 1.0566165447235107 | Validation Loss: 1.0711266994476318\n",
            "Train Loss at iteration 1177: 1.0288498401641846 | Validation Loss: 1.0296388864517212\n",
            "Train Loss at iteration 1178: 1.031855821609497 | Validation Loss: 1.0412777662277222\n",
            "Train Loss at iteration 1179: 1.0578707456588745 | Validation Loss: 1.0607916116714478\n",
            "Train Loss at iteration 1180: 1.054075002670288 | Validation Loss: 1.077239990234375\n",
            "Train Loss at iteration 1181: 1.0517213344573975 | Validation Loss: 1.073502779006958\n",
            "Train Loss at iteration 1182: 1.0615054368972778 | Validation Loss: 1.022505521774292\n",
            "Train Loss at iteration 1183: 1.0686298608779907 | Validation Loss: 1.0556403398513794\n",
            "Train Loss at iteration 1184: 1.0273762941360474 | Validation Loss: 1.0316892862319946\n",
            "Train Loss at iteration 1185: 1.041637897491455 | Validation Loss: 1.0608254671096802\n",
            "Train Loss at iteration 1186: 1.023115873336792 | Validation Loss: 1.045333981513977\n",
            "Train Loss at iteration 1187: 1.0343040227890015 | Validation Loss: 1.0242213010787964\n",
            "Train Loss at iteration 1188: 1.0611213445663452 | Validation Loss: 1.0522524118423462\n",
            "Train Loss at iteration 1189: 1.0440459251403809 | Validation Loss: 1.02312171459198\n",
            "Train Loss at iteration 1190: 1.0432275533676147 | Validation Loss: 1.0533559322357178\n",
            "Train Loss at iteration 1191: 1.0286478996276855 | Validation Loss: 1.0373656749725342\n",
            "Train Loss at iteration 1192: 1.0302976369857788 | Validation Loss: 1.0328748226165771\n",
            "Train Loss at iteration 1193: 1.0103236436843872 | Validation Loss: 1.0529513359069824\n",
            "Train Loss at iteration 1194: 1.0001050233840942 | Validation Loss: 1.043961763381958\n",
            "Train Loss at iteration 1195: 1.0388779640197754 | Validation Loss: 1.043562650680542\n",
            "Train Loss at iteration 1196: 1.035881519317627 | Validation Loss: 1.0594489574432373\n",
            "Train Loss at iteration 1197: 1.0627855062484741 | Validation Loss: 1.0483150482177734\n",
            "Train Loss at iteration 1198: 1.0507742166519165 | Validation Loss: 1.0483218431472778\n",
            "Train Loss at iteration 1199: 1.0341360569000244 | Validation Loss: 1.0595296621322632\n",
            "Train Loss at iteration 1200: 1.0417652130126953 | Validation Loss: 1.0556522607803345\n",
            "Train Loss at iteration 1201: 1.0796537399291992 | Validation Loss: 1.0371805429458618\n",
            "Train Loss at iteration 1202: 1.013055682182312 | Validation Loss: 1.049664855003357\n",
            "Train Loss at iteration 1203: 1.0257511138916016 | Validation Loss: 1.0556141138076782\n",
            "Train Loss at iteration 1204: 1.0276821851730347 | Validation Loss: 1.035967469215393\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}