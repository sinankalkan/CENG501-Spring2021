{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluate.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4G_Vc6niMpL"
      },
      "source": [
        "### The goal of this study is to reproduce the results of the paper â€œSemi-supervised Semantic Segmentation via Strong-weak Dual-branch Network\".\n",
        "\n",
        "### This file contains necessary definitions and functions for evaluating predictions made as outcomes of experiments with Single Branch and Dual Branch networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIXLIrAzsJr3"
      },
      "source": [
        "# 1.Data Preparation Steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2HkLSA8eH2e"
      },
      "source": [
        "import matplotlib.pyplot as plt # For plotting\n",
        "import os\n",
        "import cv2\n",
        "import argparse\n",
        "import numpy as np\n",
        "import types\n",
        "import copyreg\n",
        "from multiprocessing import Pool\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = [12, 8]\n",
        "plt.rcParams['figure.dpi'] = 100 # 200 e.g. is really fine, but slower"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jbk7E9B581Nt",
        "outputId": "276f7675-418d-44ee-a566-0a38acb5bf79"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5TU_faqZJc_"
      },
      "source": [
        "#!rm -rf VOCdevkit\n",
        "# open up VOC dataset\n",
        "!tar -xf /content/drive/MyDrive/VOC_Strong.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xb3iJm5c2Ta8"
      },
      "source": [
        "Resize predictions to their original image size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mofkSMm6w7zg"
      },
      "source": [
        "from PIL import Image \n",
        "import PIL\n",
        "\n",
        "def transformPredsToOriginalSize(pred_path, gt_path, image_list):\n",
        "  image_list = [i.strip() for i in open(image_list) if not i.strip() == '']\n",
        "  count =0\n",
        "  for index, img_id in enumerate(image_list):\n",
        "    count+=1       \n",
        "    gt_img_path = os.path.join(gt_path, img_id + '.png')\n",
        "    gt_img = Image.open(gt_img_path)\n",
        "    width, height = gt_img.size\n",
        "    \n",
        "    pred_img_path = os.path.join(pred_path, img_id + '_pred.png')\n",
        "    pred_img = Image.open(pred_img_path)\n",
        "    im_resized = pred_img.resize((width, height))\n",
        "    im_resized.save(pred_img_path)\n",
        "    #print('Saved ', pred_img_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3j8UwktsTSE"
      },
      "source": [
        "#2.Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-Ae7mOcyFXX"
      },
      "source": [
        "##2.1. Confusion Matrix Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0Mw-Y1TyMkW"
      },
      "source": [
        "class ConfusionMatrix(object):\n",
        "\n",
        "    def __init__(self, nclass, classes=None):\n",
        "        self.nclass = nclass\n",
        "        self.classes = classes\n",
        "        self.M = np.zeros((nclass, nclass))\n",
        "\n",
        "    def add(self, gt, pred):\n",
        "        assert (np.max(pred) <= self.nclass)\n",
        "        assert (len(gt) == len(pred))\n",
        "        for i in range(len(gt)):\n",
        "            if not gt[i] == 255:\n",
        "                self.M[gt[i], pred[i]] += 1.0\n",
        "            else:\n",
        "                print(\"what'wrong\", gt[i])\n",
        "\n",
        "    def addM(self, matrix):\n",
        "        assert (matrix.shape == self.M.shape)\n",
        "        self.M += matrix\n",
        "\n",
        "    def __str__(self):\n",
        "        pass\n",
        "\n",
        "    def jaccard(self):\n",
        "        jaccard = 0.0\n",
        "        jaccard_perclass = []\n",
        "        for i in range(self.nclass):\n",
        "            #if not self.M[i, i] == 0:\n",
        "            jaccard_perclass.append(self.M[i, i] / (np.sum(self.M[i, :]) + np.sum(self.M[:, i]) - self.M[i, i]))\n",
        "\n",
        "        return np.sum(jaccard_perclass) / len(jaccard_perclass), jaccard_perclass, self.M\n",
        "\n",
        "    def generateM(self, item):\n",
        "        gt, pred = item\n",
        "        m = np.zeros((self.nclass, self.nclass))\n",
        "        assert (len(gt) == len(pred))\n",
        "        for i in range(len(gt)):\n",
        "            if gt[i] < self.nclass:\n",
        "                m[gt[i], pred[i]] += 1.0\n",
        "        return m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T6PhLjDzB5v"
      },
      "source": [
        "##2.2. Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOdEGHCHyTfs"
      },
      "source": [
        "\n",
        "def _pickle_method(m):\n",
        "    if m.im_self is None:\n",
        "        return getattr, (m.im_class, m.im_func.func_name)\n",
        "    else:\n",
        "        return getattr, (m.im_self, m.im_func.func_name)\n",
        "\n",
        "\n",
        "copyreg.pickle(types.MethodType, _pickle_method)\n",
        "\n",
        "def semantic2mask(img):\n",
        "    colors = np.array([(128, 0, 0), (0, 128,0 ), (128, 128, 0),\n",
        "                  (0, 0, 128), (128, 0, 128), (0, 128, 128), (128, 128, 128),\n",
        "                  (64, 0, 0), (192, 0, 0), (64, 128, 0), (192, 128, 0),\n",
        "                  (64, 0, 128), (192, 0, 128), (64, 128, 128), (192, 128, 128),\n",
        "                  (0, 64, 0), (128, 64, 0), (0, 192, 0), (128, 192, 0),\n",
        "                  (0, 64, 128)]) # using palette for pascal voc\n",
        "                  \n",
        "    result = np.zeros((img.shape[0], img.shape[1]))\n",
        "    for index, color in enumerate(colors):\n",
        "        class_location = [img==color][0]\n",
        "        loc = np.logical_and(np.logical_and(class_location[:,:,0], \\\n",
        "                                            class_location[:,:,1]), \\\n",
        "                             class_location[:,:,2])\n",
        "        result[loc] = index+1\n",
        "    return result.astype(dtype=int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL5LOAO0CGaC"
      },
      "source": [
        "def evaluate_all(pred_path, gt_path, image_list, save_name): \n",
        "  CATEGORY_LIST = ['background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair',\n",
        "            'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant',\n",
        "            'sheep', 'sofa', 'train', 'tvmonitor']\n",
        "  class_num = 21\n",
        "\n",
        "  print('Evaluation is executed.')\n",
        "  iter = 0\n",
        "  m_list = []\n",
        "  data_list = []\n",
        "  image_list = [i.strip() for i in open(image_list) if not i.strip() == '']\n",
        "  count =0\n",
        "  for index, img_id in enumerate(image_list):\n",
        "    count+=1       \n",
        "    gt_img_path = os.path.join(gt_path, img_id + '.png')\n",
        "    gt = cv2.imread(gt_img_path)\n",
        "    gt = cv2.cvtColor(gt, cv2.COLOR_BGR2RGB)\n",
        "    gt = semantic2mask(gt)\n",
        "  \n",
        "    pred_img_path = os.path.join(pred_path, img_id + '_pred.png')\n",
        "    pred = cv2.imread(pred_img_path)\n",
        "    pred = cv2.cvtColor(pred, cv2.COLOR_BGR2RGB)\n",
        "    pred = semantic2mask(pred)\n",
        "               \n",
        "    data_list.append([gt.flatten(), pred.flatten()])\n",
        "        \n",
        "  print('All images are loaded:', count)\n",
        "\n",
        "  ConfM = ConfusionMatrix(class_num)\n",
        "\n",
        "  f = ConfM.generateM\n",
        "  pool = Pool()    \n",
        "  m_list = pool.map(f, data_list)\n",
        "  pool.close()\n",
        "  pool.join()\n",
        "\n",
        "  for m in m_list:\n",
        "    ConfM.addM(m)\n",
        "\n",
        "  aveJ, j_list, M = ConfM.jaccard()\n",
        "  with open(save_name, 'w') as f:\n",
        "    print('{0:12s}: {1:.4f}'.format('meanIOU', aveJ * 100))\n",
        "    print('=' * 21)\n",
        "    f.write('{0:12s}: {1:.4f}\\n'.format('meanIOU', aveJ * 100))\n",
        "    f.write('=' * 21)\n",
        "    f.write('\\n')\n",
        "    for i, j in enumerate(j_list):\n",
        "      print(\"{0:12s}: {1:.4f}\".format(CATEGORY_LIST[i], j * 100))\n",
        "      f.write(\"{0:12s}: {1:.4f}\\n\".format(CATEGORY_LIST[i], j * 100))\n",
        "\n",
        "    f.write('Raw Result:\\n')\n",
        "    f.write('meanIOU: ' + str(aveJ) + '\\n')\n",
        "    f.write(str(j_list) + '\\n')\n",
        "    f.write(str(M) + '\\n')\n",
        "  \n",
        "  return ConfM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTAClv4Q6qku"
      },
      "source": [
        "##2.3.DSRG VOC Strong Dataset Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijAFc7ZSAHeY",
        "outputId": "8589034d-2953-4f93-93b1-8caeea3e430c"
      },
      "source": [
        "!rm -rf VOCWeak\n",
        "!mkdir VOCWeak\n",
        "!cp -r /content/drive/MyDrive/VOCWeak/Results/pred VOCWeak/Results\n",
        "\n",
        "pred_path = './VOCWeak/Results'\n",
        "gt_path = './VOCdevkit/VOC2012/SegmentationClass'\n",
        "image_list = './VOCdevkit/VOC2012/ImageSets/Segmentation/val.txt'\n",
        "save_name = './VOCWeak/evaluation_out.txt'\n",
        "\n",
        "evaluate_all(pred_path, gt_path, image_list, save_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation is executed.\n",
            "All images are loaded: 1449\n",
            "meanIOU     : 42.7052\n",
            "=====================\n",
            "background  : 77.5933\n",
            "aeroplane   : 46.1848\n",
            "bicycle     : 17.2869\n",
            "bird        : 55.4742\n",
            "boat        : 18.7217\n",
            "bottle      : 35.9936\n",
            "bus         : 59.7345\n",
            "car         : 49.6030\n",
            "cat         : 67.8699\n",
            "chair       : 16.7156\n",
            "cow         : 32.8326\n",
            "diningtable : 21.9805\n",
            "dog         : 60.5807\n",
            "horse       : 39.6497\n",
            "motorbike   : 53.1534\n",
            "person      : 53.3878\n",
            "pottedplant : 23.9378\n",
            "sheep       : 57.1422\n",
            "sofa        : 30.7602\n",
            "train       : 38.2171\n",
            "tvmonitor   : 39.9905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux3KccRSOpHe"
      },
      "source": [
        "##2.4.Single Branch VOC Strong Dataset Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVzX8pkXBOOG"
      },
      "source": [
        "# open up prediction archive \n",
        "!tar -xvf /content/drive/MyDrive/prediction_results_strongonly_2407/SingleBranchStrongData_pred.tar SingleBranchStrongData/Results/pred\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZG1Ntmy7AJU",
        "outputId": "3a554017-df1f-4124-8ef5-58ac683518a7"
      },
      "source": [
        "pred_path = './SingleBranchStrongData/Results/pred'\n",
        "gt_path = './VOCdevkit/VOC2012/SegmentationClass'\n",
        "image_list = './VOCdevkit/VOC2012/ImageSets/Segmentation/val.txt'\n",
        "save_name = './SingleBranchStrongData/Results/evaluation_out.txt'\n",
        "\n",
        "transformPredsToOriginalSize(pred_path, gt_path, image_list)\n",
        "evaluate_all(pred_path, gt_path, image_list, save_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation is executed.\n",
            "All images are loaded: 1449\n",
            "meanIOU     : 22.3819\n",
            "=====================\n",
            "background  : 79.4983\n",
            "aeroplane   : 27.9403\n",
            "bicycle     : 0.0000\n",
            "bird        : 15.9210\n",
            "boat        : 1.2362\n",
            "bottle      : 0.1984\n",
            "bus         : 47.0878\n",
            "car         : 33.9691\n",
            "cat         : 40.5687\n",
            "chair       : 0.0000\n",
            "cow         : 10.1947\n",
            "diningtable : 14.6867\n",
            "dog         : 32.6843\n",
            "horse       : 16.2989\n",
            "motorbike   : 30.9792\n",
            "person      : 31.9736\n",
            "pottedplant : 0.0000\n",
            "sheep       : 15.8128\n",
            "sofa        : 2.0187\n",
            "train       : 38.7185\n",
            "tvmonitor   : 30.2321\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuEIP7kRIuph"
      },
      "source": [
        "##2.5.SingleBranch VOC Strong + SBD Weak Dataset Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecl0OVgSIupi"
      },
      "source": [
        "# open up prediction archive \n",
        "!tar -xf /content/drive/MyDrive/prediction_results_strongweak_2407/SingleBranchStrongWeakData_pred.tar SingleBranchStrongWeakData/Results/pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RoS6XL3Iupj",
        "outputId": "46525ece-d99c-4003-9b84-1875b5d6d533"
      },
      "source": [
        "#!rm -rf SingleBranchStrongWeakData\n",
        "\n",
        "# open up prediction archive \n",
        "!tar -xf /content/drive/MyDrive/prediction_results_strongweak_2407/SingleBranchStrongWeakData_pred.tar SingleBranchStrongWeakData/Results/pred\n",
        "\n",
        "pred_path = './SingleBranchStrongWeakData/Results/pred'\n",
        "gt_path = './VOCdevkit/VOC2012/SegmentationClass'\n",
        "image_list = './VOCdevkit/VOC2012/ImageSets/Segmentation/val.txt'\n",
        "save_name = './SingleBranchStrongWeakData/Results/evaluation_out.txt'\n",
        "\n",
        "\n",
        "transformPredsToOriginalSize(pred_path, gt_path, image_list)\n",
        "evaluate_all(pred_path, gt_path, image_list, save_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation is executed.\n",
            "All images are loaded: 1449\n",
            "meanIOU     : 28.0102\n",
            "=====================\n",
            "background  : 79.2818\n",
            "aeroplane   : 36.2533\n",
            "bicycle     : 0.0001\n",
            "bird        : 21.4643\n",
            "boat        : 21.7756\n",
            "bottle      : 27.5242\n",
            "bus         : 44.6864\n",
            "car         : 40.8883\n",
            "cat         : 40.8095\n",
            "chair       : 1.7488\n",
            "cow         : 22.5295\n",
            "diningtable : 21.6110\n",
            "dog         : 32.6826\n",
            "horse       : 22.7688\n",
            "motorbike   : 31.2457\n",
            "person      : 28.2649\n",
            "pottedplant : 9.9624\n",
            "sheep       : 26.1169\n",
            "sofa        : 11.4594\n",
            "train       : 40.6032\n",
            "tvmonitor   : 26.5373\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.ConfusionMatrix at 0x7f434b4ab510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPsxERjB60ua"
      },
      "source": [
        "##2.6.Dual Branch Evaluation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1ELlgnZCSWR",
        "outputId": "bc42837d-4d37-4b9e-dc6f-c5bfb5f2acd1"
      },
      "source": [
        "!rm -rf DualBranch\n",
        "\n",
        "# open up prediction archive \n",
        "!mkdir DualBranch\n",
        "!mkdir DualBranch/Results\n",
        "!mkdir DualBranch/Results/pred\n",
        "\n",
        "!tar -xf /content/drive/MyDrive/DualBranch_pred.tar DualBranch/Results/pred\n",
        "\n",
        "pred_path = './DualBranch/Results/pred'\n",
        "gt_path = './VOCdevkit/VOC2012/SegmentationClass'\n",
        "image_list = './VOCdevkit/VOC2012/ImageSets/Segmentation/val.txt'\n",
        "save_name = './DualBranch/Results/evaluation_out.txt'\n",
        "\n",
        "\n",
        "transformPredsToOriginalSize(pred_path, gt_path, image_list)\n",
        "evaluate_all(pred_path, gt_path, image_list, save_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation is executed.\n",
            "All images are loaded: 1449\n",
            "meanIOU     : 3.3161\n",
            "=====================\n",
            "background  : 69.1397\n",
            "aeroplane   : 0.0105\n",
            "bicycle     : 0.0709\n",
            "bird        : 0.0265\n",
            "boat        : 0.0138\n",
            "bottle      : 0.0016\n",
            "bus         : 0.0096\n",
            "car         : 0.0004\n",
            "cat         : 0.0126\n",
            "chair       : 0.0040\n",
            "cow         : 0.0047\n",
            "diningtable : 0.0006\n",
            "dog         : 0.0041\n",
            "horse       : 0.0028\n",
            "motorbike   : 0.0000\n",
            "person      : 0.0028\n",
            "pottedplant : 0.0235\n",
            "sheep       : 0.0037\n",
            "sofa        : 0.0004\n",
            "train       : 0.3011\n",
            "tvmonitor   : 0.0044\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.ConfusionMatrix at 0x7f09fabc8c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4z2_1lHTLom"
      },
      "source": [
        "!tar -cf Results_single_branch_strong_data.tar SingleBranchStrongData/* \n",
        "!tar -cf Results_single_branch_strong_weak_data.tar SingleBranchStrongWeakData/* "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}